{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "97884471-13cd-4916-8e80-5584443881a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import Tensor\n",
    "import torch.nn as nn\n",
    "import math\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5cee2174-ff24-473b-aa83-305c65683028",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchinfo import summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5f9ff855-2090-484a-8792-cc0b2d5995d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "m:\\disco m\\python\\pythonprojects\\pytorch\\env_pytorch\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from transformers import BertTokenizer\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0b692a64-ff5f-4995-af9d-b708577c8608",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.set_printoptions(precision=3)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "efb608b7-18de-436f-ac13-631e59131155",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configurações de treinamento e do modelo\n",
    "SEQ_LEN = 12\n",
    "D_MODEL = 8\n",
    "N_HEADS = 2\n",
    "VOCAB_SIZE = tokenizer.vocab_size\n",
    "LR = 1e-3\n",
    "LABELS = 3\n",
    "Nx = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5deaa822-617a-4304-9628-6910a055d9f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# textos com os labels 0: irritado, 1: neutro, 2: feliz\n",
    "textos = (\n",
    "    (\"I can't believe you did that Idiot! How dare you!\", 0),\n",
    "    (\"This is unacceptable! I'm furious! idiot\", 0),\n",
    "    (\"The weather today is quite nice.\", 1),\n",
    "    (\"I'm over the moon with joy! Everything is going my way!\", 2),\n",
    "    (\"I'm ecstatic! Life couldn't be better!\", 2)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "277ff6d2-c6fc-4d7c-a062-51db45b669aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "textos_tokens = [(['[CLS]'] + tokenizer.tokenize(text), label) for text, label in textos]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "40039073-1b82-4897-9cfc-756d839031ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = [(tokenizer.convert_tokens_to_ids(tokens), label) for tokens, label in textos_tokens] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "766ec38f-fa90-4bc5-94f4-59c018541b71",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Função que trunca os textos e coloca o PAD token\n",
    "def add_pad_token(list_tokens: list, seq_len: int = SEQ_LEN) -> list:\n",
    "    if len(list_tokens) > seq_len:\n",
    "        return list_tokens[:seq_len]\n",
    "    else:\n",
    "        return list_tokens + (seq_len - len(list_tokens)) * [tokenizer.pad_token_id]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "82dbbc84-ea72-4f15-9400-9f50b7e9d6ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[([101, 1045, 2064, 1005, 1056, 2903, 2017, 2106, 2008, 10041, 999, 2129], 0),\n",
       " ([101, 2023, 2003, 21873, 999, 1045, 1005, 1049, 9943, 999, 10041, 0], 0),\n",
       " ([101, 1996, 4633, 2651, 2003, 3243, 3835, 1012, 0, 0, 0, 0], 1),\n",
       " ([101, 1045, 1005, 1049, 2058, 1996, 4231, 2007, 6569, 999, 2673, 2003], 2),\n",
       " ([101, 1045, 1005, 1049, 14925, 16677, 999, 2166, 2481, 1005, 1056, 2022], 2)]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = [(add_pad_token(token_list), label) for token_list, label in data]\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "92e9bdc6-8d4e-4b6c-9130-b12eaa38ecef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# transformando em tensor para o pytorch\n",
    "data = [(torch.tensor(token_list), torch.tensor(label)) for token_list, label in data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "41440979-0ae0-4da4-bc4e-de608b46d5fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncoderClassifier(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        vocab_size = VOCAB_SIZE,\n",
    "        d_model = D_MODEL,\n",
    "        nx = Nx,\n",
    "        nhead = N_HEADS,\n",
    "        dim_feedforward = D_MODEL * 2,\n",
    "        labels = LABELS\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.embed_layer = nn.Embedding(vocab_size, d_model, padding_idx=tokenizer.pad_token_id)\n",
    "        self.encoder_layer = nn.TransformerEncoderLayer(\n",
    "            d_model=d_model,\n",
    "            nhead=nhead,\n",
    "            dim_feedforward=10,\n",
    "            norm_first=True,\n",
    "            batch_first=True,\n",
    "            activation=\"gelu\",\n",
    "            dropout=0\n",
    "        )\n",
    "        self.encoder_block = nn.TransformerEncoder(self.encoder_layer, num_layers=nx)\n",
    "        self.linear = nn.Sequential(\n",
    "            nn.Linear(d_model, d_model * 2),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(d_model * 2, d_model),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(d_model, d_model)\n",
    "        )\n",
    "        self.output_layer = nn.Linear(d_model, labels)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.embed_layer(x)\n",
    "        x = self.encoder_block(x)\n",
    "        x = x[0, :]\n",
    "        x = self.linear(x)\n",
    "        x = self.output_layer(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0da87c4b-fe91-43ab-9b09-b45be2b235cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = EncoderClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ff929e11-7f85-44b8-a37f-b78139eaf971",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "==========================================================================================\n",
       "Layer (type:depth-idx)                                            Param #\n",
       "==========================================================================================\n",
       "EncoderClassifier                                                 --\n",
       "├─Embedding: 1-1                                                  244,176\n",
       "├─TransformerEncoderLayer: 1-2                                    --\n",
       "│    └─MultiheadAttention: 2-1                                    216\n",
       "│    │    └─NonDynamicallyQuantizableLinear: 3-1                  72\n",
       "│    └─Linear: 2-2                                                90\n",
       "│    └─Dropout: 2-3                                               --\n",
       "│    └─Linear: 2-4                                                88\n",
       "│    └─LayerNorm: 2-5                                             16\n",
       "│    └─LayerNorm: 2-6                                             16\n",
       "│    └─Dropout: 2-7                                               --\n",
       "│    └─Dropout: 2-8                                               --\n",
       "├─TransformerEncoder: 1-3                                         --\n",
       "│    └─ModuleList: 2-9                                            --\n",
       "│    │    └─TransformerEncoderLayer: 3-2                          498\n",
       "├─Sequential: 1-4                                                 --\n",
       "│    └─Linear: 2-10                                               144\n",
       "│    └─ReLU: 2-11                                                 --\n",
       "│    └─Linear: 2-12                                               136\n",
       "│    └─ReLU: 2-13                                                 --\n",
       "│    └─Linear: 2-14                                               72\n",
       "├─Linear: 1-5                                                     27\n",
       "==========================================================================================\n",
       "Total params: 245,551\n",
       "Trainable params: 245,551\n",
       "Non-trainable params: 0\n",
       "=========================================================================================="
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b6ab46a7-457f-4201-8e1f-176bc34175e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(model.parameters(), lr=LR)\n",
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1d89d294-b8a9-46f0-a413-b5241e5e30af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "EncoderClassifier(\n",
       "  (embed_layer): Embedding(30522, 8, padding_idx=0)\n",
       "  (encoder_layer): TransformerEncoderLayer(\n",
       "    (self_attn): MultiheadAttention(\n",
       "      (out_proj): NonDynamicallyQuantizableLinear(in_features=8, out_features=8, bias=True)\n",
       "    )\n",
       "    (linear1): Linear(in_features=8, out_features=10, bias=True)\n",
       "    (dropout): Dropout(p=0, inplace=False)\n",
       "    (linear2): Linear(in_features=10, out_features=8, bias=True)\n",
       "    (norm1): LayerNorm((8,), eps=1e-05, elementwise_affine=True)\n",
       "    (norm2): LayerNorm((8,), eps=1e-05, elementwise_affine=True)\n",
       "    (dropout1): Dropout(p=0, inplace=False)\n",
       "    (dropout2): Dropout(p=0, inplace=False)\n",
       "  )\n",
       "  (encoder_block): TransformerEncoder(\n",
       "    (layers): ModuleList(\n",
       "      (0): TransformerEncoderLayer(\n",
       "        (self_attn): MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=8, out_features=8, bias=True)\n",
       "        )\n",
       "        (linear1): Linear(in_features=8, out_features=10, bias=True)\n",
       "        (dropout): Dropout(p=0, inplace=False)\n",
       "        (linear2): Linear(in_features=10, out_features=8, bias=True)\n",
       "        (norm1): LayerNorm((8,), eps=1e-05, elementwise_affine=True)\n",
       "        (norm2): LayerNorm((8,), eps=1e-05, elementwise_affine=True)\n",
       "        (dropout1): Dropout(p=0, inplace=False)\n",
       "        (dropout2): Dropout(p=0, inplace=False)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (linear): Sequential(\n",
       "    (0): Linear(in_features=8, out_features=16, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): Linear(in_features=16, out_features=8, bias=True)\n",
       "    (3): ReLU()\n",
       "    (4): Linear(in_features=8, out_features=8, bias=True)\n",
       "  )\n",
       "  (output_layer): Linear(in_features=8, out_features=3, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "aa553868-f7ac-41c9-ba9e-ee3ad2f0b5db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-0.000, -0.124, -0.139], device='cuda:0', grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model(data[0][0].to(device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "2a3be576-f1ff-4a64-9d08-8f0e6ed4f383",
   "metadata": {},
   "outputs": [],
   "source": [
    "def acc_metric(label, output):\n",
    "    output = torch.argmax(output, dim=-1)\n",
    "    return (label == output).float().mean().detach().item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "4d995eaa-53f8-454a-bf6a-679aab267d0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 45%|███████████████████████▏                           | 454/1000 [00:13<00:16, 33.86it/s, loss=0.010, accuracy=1.000]\n"
     ]
    }
   ],
   "source": [
    "# realizando o treinamento\n",
    "model.train()\n",
    "ITERACOES = 1_000\n",
    "iterator = tqdm(range(ITERACOES))\n",
    "for _ in iterator:\n",
    "    for X, y in data:\n",
    "        optimizer.zero_grad()\n",
    "        X, y = X.to(device), y.to(device)\n",
    "        y_hat = model(X)\n",
    "        loss = criterion(y_hat, y)\n",
    "        # Backward pass\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        acc = acc_metric(y, y_hat)\n",
    "    iterator.set_postfix({\"loss\": f\"{loss.item():6.3f}\", \"accuracy\": f\"{acc:.3f}\"})\n",
    "    if loss.item() <= 0.01:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "6c0ec76c-0b22-47dc-b364-0466f391307e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Texto passado:\n",
      "I can't believe you did that Idiot! How dare you!\n",
      "label: 0\n",
      "Resultado do modelo: 0\n",
      "Resultado do modelo em probas: \n",
      "tensor([1., 0., 0.], device='cuda:0', grad_fn=<RoundBackward1>)\n",
      "\n",
      "Texto passado:\n",
      "This is unacceptable! I'm furious! idiot\n",
      "label: 0\n",
      "Resultado do modelo: 0\n",
      "Resultado do modelo em probas: \n",
      "tensor([1., 0., 0.], device='cuda:0', grad_fn=<RoundBackward1>)\n",
      "\n",
      "Texto passado:\n",
      "The weather today is quite nice.\n",
      "label: 1\n",
      "Resultado do modelo: 1\n",
      "Resultado do modelo em probas: \n",
      "tensor([2.000e-04, 9.998e-01, 0.000e+00], device='cuda:0',\n",
      "       grad_fn=<RoundBackward1>)\n",
      "\n",
      "Texto passado:\n",
      "I'm over the moon with joy! Everything is going my way!\n",
      "label: 2\n",
      "Resultado do modelo: 2\n",
      "Resultado do modelo em probas: \n",
      "tensor([0.004, 0.005, 0.990], device='cuda:0', grad_fn=<RoundBackward1>)\n",
      "\n",
      "Texto passado:\n",
      "I'm ecstatic! Life couldn't be better!\n",
      "label: 2\n",
      "Resultado do modelo: 2\n",
      "Resultado do modelo em probas: \n",
      "tensor([0.004, 0.005, 0.990], device='cuda:0', grad_fn=<RoundBackward1>)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i, (X, y) in enumerate(data):\n",
    "    X, y = X.to(device), y.to(device)\n",
    "    pred = model(X)\n",
    "    print('Texto passado:')\n",
    "    print(textos[i][0])\n",
    "    print(f'label: {y}')\n",
    "    print(f'Resultado do modelo: {torch.argmax(pred).item()}')\n",
    "    print('Resultado do modelo em probas: ')\n",
    "    pred_prob = torch.softmax(pred, dim=-1)\n",
    "    print(torch.round(pred_prob, decimals=4))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b41f272f-8e5d-4681-84ac-fc151eb8d731",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
