{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c04dda32-15da-48ec-b9dc-ff67b063ef14",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from enum import Enum\n",
    "from tqdm import tqdm\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "478c9f3b-c2b4-4cf4-a96e-ef1ec1d20fc7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "m:\\disco m\\python\\pythonprojects\\pytorch\\env_pytorch\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "from tokenizers import Tokenizer\n",
    "from tokenizers.models import WordLevel\n",
    "from tokenizers.trainers import WordLevelTrainer\n",
    "from tokenizers.pre_tokenizers import Whitespace\n",
    "\n",
    "from tokenizers.models import BPE\n",
    "from tokenizers.trainers import BpeTrainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e53d578f-97b9-4bb2-87a5-a0473131488e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, Dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1a66e5f8-a36a-42bb-88e1-70885ba676e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchinfo import summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "592b6b2b-5613-4a8f-b58f-20ea7eefaadc",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "911d79c8-9761-4edb-9303-8df499f867b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f9028d53-8421-430e-a519-31e14da7fe21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['label', 'text'],\n",
      "        num_rows: 650000\n",
      "    })\n",
      "    test: Dataset({\n",
      "        features: ['label', 'text'],\n",
      "        num_rows: 50000\n",
      "    })\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "dataset = load_dataset(\"yelp_review_full\")\n",
    "\n",
    "# Acessar os dados\n",
    "train_data = dataset[\"train\"]\n",
    "test_data = dataset[\"test\"]\n",
    "\n",
    "# Exibir informações sobre o conjunto de dados\n",
    "print(dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4aeca5dd-f605-4c6b-99bc-898362782f5d",
   "metadata": {},
   "source": [
    "# Configs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "abf4adbe-2413-472c-b4b4-c6affb1842fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SpecialTokens(Enum):\n",
    "    CLS = 2\n",
    "    PAD = 0\n",
    "    UNK = 1\n",
    "\n",
    "special_tokens = SpecialTokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "473df20f-95e3-41cf-90f7-8be64301afb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "SEQ_LEN = 124\n",
    "D_MODEL = 16\n",
    "N_HEADS = 4\n",
    "Nx = 2\n",
    "N_OUTPUT = 5\n",
    "VOCAB_SIZE = 15_000\n",
    "LR = 1e-5\n",
    "BATCH_SIZE_TRAIN = 2\n",
    "BATCH_SIZE_TEST = 32\n",
    "EPOCHS = 15"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e119b0f-9a71-4b8c-972f-dc39a5689905",
   "metadata": {},
   "source": [
    "# Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f50535cd-f54e-4fb0-b324-75f32b03bf03",
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_iterator(data):\n",
    "    for text in data['text']:\n",
    "        yield text.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e31bdd5c-e4b4-49b6-883e-e1b35fca4de5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def word_level_tokenizer(data, path_tokenizer: Path = Path('tokenizer/tokenizer.json')):\n",
    "    if not Path.exists(path_tokenizer):\n",
    "        tokenizer = Tokenizer(BPE(unk_token=\"<UNK>\"))\n",
    "        tokenizer.pre_tokenizer = Whitespace()\n",
    "\n",
    "        # Definindo o PAD token como o primeiro na lista de tokens especiais\n",
    "        special_tokens = [\"<PAD>\", \"<UNK>\", \"<CLS>\"]\n",
    "\n",
    "        trainer = BpeTrainer(special_tokens=special_tokens, min_frequency=5, vocab_size=VOCAB_SIZE)\n",
    "        tokenizer.train_from_iterator(text_iterator(data), trainer=trainer)\n",
    "        tokenizer.save(str(path_tokenizer))\n",
    "    else:\n",
    "        tokenizer = Tokenizer.from_file(str(path_tokenizer))\n",
    "\n",
    "    return tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "51a34a79-72e9-40d5-a7ad-b6e367c9e205",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = word_level_tokenizer(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e230b212-b1e4-420a-83d6-71be5ca729bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VOCAB SIZE: 15000\n"
     ]
    }
   ],
   "source": [
    "print(f'VOCAB SIZE: {tokenizer.get_vocab_size()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f3e42ef7-7a1b-41f7-aaaa-b20993696877",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.encode('<PAD>').ids"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b35adce-dd7d-492e-8bbb-4dfb195b06cb",
   "metadata": {},
   "source": [
    "# Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d5140d17-db9c-44fe-84f7-0711591969d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.encode('<CLS>').ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c4c8ad34-0990-4b80-bd0b-3685b827a899",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Tuple, List\n",
    "\n",
    "class YelpReviewFullDataset(Dataset):\n",
    "    def __init__(self, data, tokenizer: Tokenizer = tokenizer, seq_len: int = SEQ_LEN) -> None:\n",
    "        self.data = data\n",
    "        self.tokenizer = tokenizer\n",
    "        self.CLS_token_id = 2\n",
    "        self.PAD_token_id = 0\n",
    "        self.seq_len = seq_len\n",
    "\n",
    "    def __len__(self) -> int:\n",
    "        return self.data.num_rows\n",
    "        \n",
    "    def __getitem__(self, id_i) -> Tuple[int, List[int]]:\n",
    "        item = self.data[id_i]\n",
    "        label, text = item['label'], item['text'].lower()\n",
    "        tokens_list = [self.CLS_token_id] + self.tokenizer.encode(text).ids\n",
    "        tokens_list = self.truncate_seq(tokens_list)\n",
    "        return {'label': label, 'tokens': torch.tensor(tokens_list), 'text': text}\n",
    "\n",
    "    def truncate_seq(self, tokens_list: List[int]):\n",
    "        len_token_list = len(tokens_list)\n",
    "        if len_token_list > self.seq_len:\n",
    "            return tokens_list[: self.seq_len]\n",
    "        elif len_token_list < self.seq_len:\n",
    "            return tokens_list + [self.PAD_token_id] * (self.seq_len - len_token_list)\n",
    "        return tokens_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "91db676a-2cfe-42af-8759-30652c6ee4d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = YelpReviewFullDataset(train_data)\n",
    "test_dataset = YelpReviewFullDataset(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a1c7ad2a-d99e-41b5-a0b3-8329eddf23d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train_dataset, shuffle=True, batch_size=BATCH_SIZE_TRAIN)\n",
    "test_loader = DataLoader(test_dataset, shuffle=True, batch_size=BATCH_SIZE_TEST)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "177b4371-57e7-4f56-8f08-ac7b76310897",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0bafe789-f9e8-4aa7-b0cd-37f46f00d6c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PositionalEncoding(nn.Module):\n",
    "    def __init__(self, d_model: int, seq_len: int, dropout: float) -> None:\n",
    "        super().__init__()\n",
    "        self.d_model = d_model\n",
    "        self.seq_len = seq_len\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        # Create a matrix of shape (seq_len, d_model)\n",
    "        pe = torch.zeros(seq_len, d_model)\n",
    "        # Create a vector of shape (seq_len)\n",
    "        position = torch.arange(0, seq_len, dtype=torch.float).unsqueeze(1) # (seq_len, 1)\n",
    "        # Create a vector of shape (d_model)\n",
    "        div_term = torch.exp(torch.arange(0, d_model, 2).float() * (-math.log(10000.0) / d_model)) # (d_model / 2)\n",
    "        # Apply sine to even indices\n",
    "        pe[:, 0::2] = torch.sin(position * div_term) # sin(position * (10000 ** (2i / d_model))\n",
    "        # Apply cosine to odd indices\n",
    "        pe[:, 1::2] = torch.cos(position * div_term) # cos(position * (10000 ** (2i / d_model))\n",
    "        # Add a batch dimension to the positional encoding\n",
    "        pe = pe.unsqueeze(0) # (1, seq_len, d_model)\n",
    "        # Register the positional encoding as a buffer\n",
    "        self.register_buffer('pe', pe)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x + (self.pe[:, :x.shape[1], :]).requires_grad_(False) # (batch, seq_len, d_model)\n",
    "        return self.dropout(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a7933c98-257d-422f-bdcb-10eb708e1bca",
   "metadata": {},
   "outputs": [],
   "source": [
    "class YepReviewModel(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        seq_len: int = SEQ_LEN,\n",
    "        d_model: int = D_MODEL,\n",
    "        vocab_size: int = VOCAB_SIZE,\n",
    "        num_heads: int = N_HEADS,\n",
    "        n_x: int = Nx,\n",
    "        dropout: float = 0.05,\n",
    "        n_outputs: int = N_OUTPUT\n",
    "    ):\n",
    "        super().__init__()\n",
    "        # configurações do modelo\n",
    "        self.seq_len = seq_len\n",
    "        self.d_model = d_model\n",
    "        self.vocab_size = vocab_size\n",
    "        self.num_heads = num_heads\n",
    "        self.n_x = n_x\n",
    "        self.dropout = dropout\n",
    "        self.n_outputs = n_outputs\n",
    "\n",
    "        # componentes\n",
    "        self.embedding_layer = nn.Embedding(\n",
    "            num_embeddings=self.vocab_size, \n",
    "            embedding_dim=self.d_model, \n",
    "            padding_idx=SpecialTokens.PAD.value)\n",
    "        self.pos_encodding = PositionalEncoding(self.d_model, self.seq_len, self.dropout)\n",
    "        self.encoder_layer = nn.TransformerEncoderLayer(d_model=self.d_model, nhead=self.num_heads)\n",
    "        self.encoder_block = nn.TransformerEncoder(self.encoder_layer, num_layers=self.n_x, )\n",
    "        self.linear_layer = nn.Sequential(\n",
    "            nn.Linear(self.d_model, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 124),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(124, 32),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(32, 10),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(10, 8)\n",
    "        )\n",
    "        self.output_layer = nn.Linear(8, self.n_outputs)\n",
    "        # self.softmax = nn.Softmax(dim=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.embedding_layer(x)\n",
    "        x = self.pos_encodding(x)\n",
    "        x = self.encoder_layer(x)\n",
    "        # Pegando a representação vetorial do token <CLS>\n",
    "        x = x[:, 0, :]\n",
    "        x = self.linear_layer(x)\n",
    "        x = self.output_layer(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "120e155f-22bb-4117-9b80-289dc640bd67",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = YepReviewModel().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4aa9b01e-1fbb-4dc8-b98f-c3ad1fcb32b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "==========================================================================================\n",
       "Layer (type:depth-idx)                                            Param #\n",
       "==========================================================================================\n",
       "YepReviewModel                                                    --\n",
       "├─Embedding: 1-1                                                  240,000\n",
       "├─PositionalEncoding: 1-2                                         --\n",
       "│    └─Dropout: 2-1                                               --\n",
       "├─TransformerEncoderLayer: 1-3                                    --\n",
       "│    └─MultiheadAttention: 2-2                                    816\n",
       "│    │    └─NonDynamicallyQuantizableLinear: 3-1                  272\n",
       "│    └─Linear: 2-3                                                34,816\n",
       "│    └─Dropout: 2-4                                               --\n",
       "│    └─Linear: 2-5                                                32,784\n",
       "│    └─LayerNorm: 2-6                                             32\n",
       "│    └─LayerNorm: 2-7                                             32\n",
       "│    └─Dropout: 2-8                                               --\n",
       "│    └─Dropout: 2-9                                               --\n",
       "├─TransformerEncoder: 1-4                                         --\n",
       "│    └─ModuleList: 2-10                                           --\n",
       "│    │    └─TransformerEncoderLayer: 3-2                          68,752\n",
       "│    │    └─TransformerEncoderLayer: 3-3                          68,752\n",
       "├─Sequential: 1-5                                                 --\n",
       "│    └─Linear: 2-11                                               8,704\n",
       "│    └─ReLU: 2-12                                                 --\n",
       "│    └─Linear: 2-13                                               63,612\n",
       "│    └─ReLU: 2-14                                                 --\n",
       "│    └─Linear: 2-15                                               4,000\n",
       "│    └─ReLU: 2-16                                                 --\n",
       "│    └─Linear: 2-17                                               330\n",
       "│    └─ReLU: 2-18                                                 --\n",
       "│    └─Linear: 2-19                                               88\n",
       "├─Linear: 1-6                                                     45\n",
       "==========================================================================================\n",
       "Total params: 523,035\n",
       "Trainable params: 523,035\n",
       "Non-trainable params: 0\n",
       "=========================================================================================="
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "629dec2f-8ab8-4608-9821-fa943f858063",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(model.parameters(), lr=LR)\n",
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "18815bbb-4ca2-4ce8-a515-70a18340d5c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def acc_metric(label, output):\n",
    "    output = torch.argmax(output, dim=1)\n",
    "    return (label == output).float().mean().detach().item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "aa3540bb-dee2-4066-b5c8-0898e6f3107e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'label': tensor([3, 2]),\n",
       " 'tokens': tensor([[    2,    70,   496,    93,   244,    14,   402,   230,  1319,   136,\n",
       "           1244,    96,  1000,    16,    70,   298,  3106,   262,    82,   119,\n",
       "            159,   468,    86,   443,   569,   117,  1484,   879,   616,    16,\n",
       "             80,    70,   241,   893,    96,    82,   145,    16,    47,  1191,\n",
       "            180,    93,   293,    79,  2534,   128,   336,    39,  6540,   833,\n",
       "             16,    70,  2695,   159,   621,    14,  1096,    70,  2897,    16,\n",
       "           1082,   123,   135,   159,   668,    16,   304,    70,  1604,  3842,\n",
       "             93,   621,    16,   135,   151,    39,  1341,  1775,  1922,    16,\n",
       "             70,   446,   545,    93,   274,   179,    14,   110,    93,    70,\n",
       "           2080,    16,  1177,   564,    70,   402,   230,   146,   753,  1999,\n",
       "             70,   311,   106,    70,   429,   346,   616,    16,  1115,    70,\n",
       "            242,    93,   244,    14,    70,  1179,  1453,    93,   274,   782,\n",
       "             80,   167,   657,    16],\n",
       "         [    2,   123,  2957,   156,    39, 11093,   106,  1171,   106,   646,\n",
       "             16,    94,   151,   299,   201,    39,   926,    96,   505,    80,\n",
       "             47,   151,    79,   405,    70,   176,    86,   189,   468,  1323,\n",
       "             34,    52,    34,  1139,  2957,     9,    57,   516,  3950,   345,\n",
       "              9,    58,  3062,   743,   132,   693,   537,    16,   116,   724,\n",
       "             70,   572,   329,   151,   299,   424,    16,   116,   338,   438,\n",
       "             70,  1556,     8,   856,   159,  1292,    16,    47,   295,    70,\n",
       "           1567,   602,    16,    82,    93,   179,   128,   329,   868,   560,\n",
       "             79,   670,   293,   537,    79,    82,    76,   361,    16,    34,\n",
       "             52,    34,   327, 11823,   622,    96,    70,   535,    93,    70,\n",
       "           1202,    80,  1448,   155,    52,    34,  1950,    93,   167,   179,\n",
       "            801,    16,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0]]),\n",
       " 'text': ['the experience was great, first time doing this style of eating. the only parts about it that were ok is how fast you received each meat. and the finale of it all. i wish there was more to desert but im a sweets girl. the meats were delicious, especially the steaks. oh my they were amazing. even the grilled pineapple was delicious. they have a serve yourself sides. the chicken salad was really good, so was the salads. although being the first time id probably save the room for the table side meat. overall the service was great, the owner lady was really sweet and very kind. they explained everything well, id definitely recommend this to anyone. what an experience for our one year wedding anniversary. thank you.',\n",
       "  'my hubby had a hankering for mex for dinner. we have been here a couple of times and i have to say the food is \\\\\"ok\\\\\". \\\\n\\\\nmy hubby\\'s cheese enchiladas didn\\'t provide him with enough flavor. he thought the sauce could have been better. he also said the beans & rice were bland. i got the burrito light. it was good but could use something to add more flavor to it as well. \\\\n\\\\nthe tastiest part of the meal was the chips and salsa.\\\\n\\\\nservice was very good tho.']}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(iter(train_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "68cfdcac-e241-45ef-8d07-919adc54f3af",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = next(iter(train_loader))\n",
    "batch_labels, batch_tokens, batch_texts = batch['label'], batch['tokens'], batch['text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b151f1e2-6334-46ca-9b81-bf0f64c9baa6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#### TEXTO ####\n",
      "eh cuz, i like make da kine public service announcement first for all da buggahs stay writin' reviews for anykine hawaiian place. no such thing as kahlua pig. we no put da kine coffee liqueur and shit on da pig, bra. also, no moa kailua pig either, bra. you buy pig or pork in kailua and bring em' back to honolulu and you goin' be takin' pig/pork on da kine, pali highway. first thing goin' happen is yo' car goin' stall right on da highway, bra. next da night marchers goin' carjack your car. then madam pele and da limu lady - two of da baddest tittas on da island goin' take you to morgan's corner and bang yo' head on the 13 steps, bra. by da time they done with you, you goin' forget about evah callin' it kailua pig. it's kalua, bra. ok bruddah. enough of the public service announcements. dis place stay in one mall next to one barnes and nobles. i went come here plenty times. one pake family stay run this place and they do one pretty good job of making island kine plate lunches. fo' me l&l in north phoenix is still da best but when i no like drive too far this stay second best. i usually get one of da combo meals, bra - that's the way to go. this blala gives dis place the big shaka sign. bettah than pig. bettah than poi. i no shit you. best hawaiian food this part of town, bra. one thing - da guy who take da order, bra, he never say nothing. i think he stay da kine - android from kikaida. i no say nothing bumbai he turn into da kine - red mask and blue suit and chase me out of da store with one spear shouting \\\"git 'em! git 'em!\\\"\n",
      "## Label: 3 ##\n"
     ]
    }
   ],
   "source": [
    "print('#### TEXTO ####')\n",
    "print(batch_texts[0])\n",
    "print(f'## Label: {batch_labels[0]} ##')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "8d69f593-1bb5-45b3-bcac-355934335ae7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([    2,  3921,  4511,    14,    47,   199,   460,  1384,    49,   323,\n",
       "         3498,   242, 11257,   374,   402,   106,   145,  1384,   108,   638,\n",
       "         1194,    57,   582,   576,    82,    71,     9,   964,   106,   214,\n",
       "           49,   323,  4131,   183,    16,   182,  1041,   188,    76, 13377,\n",
       "          324,    39,  4226,    16,    94,   182,   715,  1384,    49,   323,\n",
       "          862, 13859,   220,    80,  2607,    78,  1384,  4226,    14,  3859,\n",
       "           16,   338,    14,   182,   154,    39,    49,  1057,  8904,  4226,\n",
       "         1027,    14,  3859,    16,   117,  1088,  4226,    83,  1051,    71,\n",
       "           49,  1057,  8904,    80,  1048,   834,     9,   257,    79,  3260,\n",
       "         3736,  9318,    80,   117,   177,    71,     9,    99,   270,  2924,\n",
       "            9,  4226,    17,  1051,    78,  1384,    49,   323,    14,  1593,\n",
       "           47,  8700,    16,   402,   188,   177,    71,     9,  1134,    86,\n",
       "         1714,     9,   457,   177])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_tokens[0, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "708556f8-3170-4444-922d-82c7db8ee111",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([3])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_labels[0].unsqueeze(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd5aa01b-7c3e-4803-b579-de00fd77cc8d",
   "metadata": {},
   "source": [
    "# Treinando em uma Amostra\n",
    "Isso ajuda a ver se o modelo está convergindo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "2fed80dc-5f2f-4090-9c95-316e311feb6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                             | 1189/1000000 [00:26<6:08:01, 45.23it/s, loss=0.197]\n"
     ]
    }
   ],
   "source": [
    "model.train()\n",
    "ITERACOES = 1_000_000\n",
    "iterator = tqdm(range(ITERACOES))\n",
    "X = batch_tokens[0, :].unsqueeze(0).to(device)\n",
    "y = batch_labels[0].unsqueeze(0).to(device)\n",
    "for _ in iterator:\n",
    "    y_hat = model(X)\n",
    "    loss = criterion(y_hat, y)\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    acc = acc_metric(y, y_hat)\n",
    "    iterator.set_postfix({\"loss\": f\"{loss.item():6.3f}\"})\n",
    "    if loss.item() <= 0.2:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "10a244c6-8a99-4f1d-a93c-818553c418fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LABEL: 3\n",
      "PREDICT: 3\n",
      "PREDICT PROBA: [[0.07483470439910889, 0.0650244951248169, 0.006782560609281063, 0.8213327527046204, 0.0320255346596241]]\n"
     ]
    }
   ],
   "source": [
    "print(f'LABEL: {y.item()}')\n",
    "print(f'PREDICT: {torch.argmax(y_hat)}')\n",
    "print(f'PREDICT PROBA: {F.softmax(y_hat, dim=-1).tolist()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c857f6d4-70d7-4e0f-ac78-bdcbe52ecbe0",
   "metadata": {},
   "source": [
    "# Treinando em um Batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65073d89-c159-42b9-9667-34550d441756",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|█▋                                         | 40080/1000000 [06:15<2:16:01, 117.62it/s, loss=0.697, accuracy=0.000]"
     ]
    }
   ],
   "source": [
    "model.train()\n",
    "ITERACOES = 1_000_000\n",
    "iterator = tqdm(range(ITERACOES))\n",
    "X = batch_tokens.to(device)\n",
    "y = batch_labels.to(device)\n",
    "for _ in iterator:\n",
    "    y_hat = model(X)\n",
    "    loss = criterion(y_hat, y)\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    acc = acc_metric(y, y_hat)\n",
    "    iterator.set_postfix({\"loss\": f\"{loss.item():6.3f}\", \"accuracy\": f\"{acc:.3f}\"})\n",
    "    if loss.item() <= 0.35:\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42f5f1c7-8a83-4ba7-b9bd-c9fd8d067dcb",
   "metadata": {},
   "source": [
    "# Treinando para o conjunto de dados inteiro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "5a359c4a-5487-46b1-80d5-257524a50a94",
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def eval_model(model, data_eval) -> None:\n",
    "    model.eval()\n",
    "    acc_list = []\n",
    "    for i, batch in enumerate(data_eval):\n",
    "        labels, tokens, texts = batch['label'], batch['tokens'], batch['text']\n",
    "        tokens = torch.stack(tokens, dim=1)\n",
    "        labels, tokens = labels.to(device), tokens.to(device)\n",
    "\n",
    "        predict = model(tokens)\n",
    "        predict = torch.argmax(predict, dim=1)\n",
    "        acc = torch.mean((predict == labels).float()).item()\n",
    "        acc_list.append(acc)\n",
    "    acc_tensor = torch.tensor(acc_list)\n",
    "    return round(torch.mean(acc_tensor).item(), 3)\n",
    "\n",
    "\n",
    "def train_model(model, data_train, data_eval, epochs, optimizer, criterion) -> None:\n",
    "    model.train()\n",
    "    optimizer.zero_grad(set_to_none=True)\n",
    "    loss_eval_list: list = []\n",
    "    for epoch in range(epochs):\n",
    "        torch.cuda.empty_cache()\n",
    "        loss_epoch = 0.0\n",
    "        batch_iterator = tqdm(data_train, desc=f\"Processing Epoch {epoch:02d}\")\n",
    "        for batch in batch_iterator:\n",
    "            labels, tokens, texts = batch['label'], batch['tokens'], batch['text']\n",
    "            tokens = torch.stack(tokens, dim=1)\n",
    "            labels, tokens = labels.to(device), tokens.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(tokens)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            batch_iterator.set_postfix({\"loss\": f\"{loss.item():6.3f}\"})\n",
    "            \n",
    "        acc_eval = eval_model(model, data_eval)\n",
    "        loss_eval_list.append(acc_eval)\n",
    "    return loss_eval_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c7d5d21-e188-422d-ab34-7d9f1e6d621d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Epoch 00: 100%|███████████████████████████████████████████| 20313/20313 [11:30<00:00, 29.41it/s, loss=1.615]\n",
      "Processing Epoch 01: 100%|███████████████████████████████████████████| 20313/20313 [10:50<00:00, 31.24it/s, loss=1.610]\n",
      "Processing Epoch 02: 100%|███████████████████████████████████████████| 20313/20313 [10:54<00:00, 31.05it/s, loss=1.610]\n",
      "Processing Epoch 03:  23%|█████████▉                                  | 4578/20313 [02:27<08:29, 30.90it/s, loss=1.612]"
     ]
    }
   ],
   "source": [
    "train_model(model, train_loader, test_loader, epochs=EPOCHS, optimizer=optimizer, criterion=criterion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "id": "5cabb020-b30e-41f3-ac16-b19d3e4d496d",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = 'models/model_v0.pth'\n",
    "\n",
    "# Salvando o modelo\n",
    "torch.save(model.state_dict(), file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77a72c0d-9d3c-4734-beda-4df12fa26458",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env_pytorch",
   "language": "python",
   "name": "env_pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
