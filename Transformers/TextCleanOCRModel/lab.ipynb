{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "85038fdb-d71a-4c49-9238-0f4532304e6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e37fb268-aaa0-4903-8944-a2c8faace1ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9e0f92c-3011-4e1b-8282-1e0e057c6464",
   "metadata": {},
   "source": [
    "# Get Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9917f402-6abd-4ea9-933e-df8318a01810",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.get_data import get_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "32bc15a5-663a-4695-866e-f74c7045548e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "########### INPUT ############\n",
      "Esse é um texto de exemplo\n",
      "4W$^Q~{<p5>{G\n",
      "que eu qu\n",
      "\n",
      "==============================\n",
      "########### TARGET ###########\n",
      "Esse é um texto de exemplo\n",
      "que eu quero testar min\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Pegando os dados\n",
    "\n",
    "data = get_data()\n",
    "print(f'{\" INPUT \":#^30}')\n",
    "print(f\"{data['input'][:50]}\\n\")\n",
    "print('='*30)\n",
    "print(f'{\" TARGET \":#^30}')\n",
    "print(f\"{data['target'][:50]}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a381149e-e547-40a9-ab62-0b5909580b5e",
   "metadata": {},
   "source": [
    "# Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "95d8d305-9f51-4e0d-8b3b-7eed6f230ffe",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "m:\\disco m\\python\\pythonprojects\\pytorch\\env_pytorch\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from transformers_utils.tokenizer import Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "de9ecc02-d90b-4927-9659-d0ae9e7b6540",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1dd9b65a-e040-4767-9f6a-81d8ee38cabc",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_tokens_ids = tokenizer.tokenize_text_to_id(data['input'])\n",
    "target_tokens_ids = tokenizer.tokenize_text_to_id(data['target'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "c463ba0f-fecc-4bb6-be95-d833451c935a",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.LongTensor(input_tokens_ids).unsqueeze(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "e010904d-8b1a-43d1-b4ca-f930c23f9f56",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 233])"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d0576c8-8689-48e5-9d66-99441cb6744e",
   "metadata": {},
   "source": [
    "# Duvida\n",
    "- Descobrir como treinar o modelo por exemplo eu tenho os tokens [1,2, 1001,1005,1008, 3, 4] como input e os tokens [1,2,3,4] como target, como fazer esse treinamento, os tokens 1001, 1005 e 1008 são sujeiras que quero remover?\n",
    "- Talvez modelos de resumo sejam assim"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37db835d-765d-4eb2-a23d-8fa321e2d300",
   "metadata": {},
   "source": [
    "# Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "972e00bf-e04c-4dc0-ac86-922dbf40065f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers_utils.embeddings import EmbeddingLayer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "5d778357-deda-4264-89db-035d63e03761",
   "metadata": {},
   "outputs": [],
   "source": [
    "emb_layer = EmbeddingLayer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "9d16958e-5e2d-43e2-866e-86ab1ef895a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_emb = emb_layer(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "c9eedbf2-7269-45ac-91df-60e04460aa9f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-0.9423,  0.7442, -2.1976,  ...,  1.6943,  0.9442,  0.7200],\n",
       "         [-0.8405, -1.2039,  1.0162,  ...,  0.2667,  0.8093, -2.1871],\n",
       "         [ 2.5269,  2.9937, -1.8652,  ...,  0.2578,  0.3413, -0.8517],\n",
       "         ...,\n",
       "         [-0.6088,  0.2473, -0.0222,  ...,  1.1009, -0.7052, -0.1633],\n",
       "         [ 0.0099, -0.3723, -1.2274,  ...,  0.0547,  0.9658,  0.3342],\n",
       "         [-0.0106, -0.1832,  1.1417,  ..., -1.0159,  1.3411, -2.1699]]],\n",
       "       grad_fn=<EmbeddingBackward0>)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_emb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1adcbfd7-a325-4151-a031-e78aa4e0e43c",
   "metadata": {},
   "source": [
    "# Pos Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "ccb0ee41-9d53-4187-b720-93c9abe7172c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# por que usamos Dropout em pos embedding para ele não ficar muito viessado com esse acréscimo de posição?\n",
    "from transformers_utils.pos_encoding import PositionalEncoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "9912653a-5f93-48b7-a1f2-0e6e890a7254",
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_emb = PositionalEncoding()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "93d152c6-bcad-4868-8522-d999a9da69a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_pos = pos_emb(x_emb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "08161e68-22b2-4d60-a2c1-2414350a815d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-0.9423,  5.7442, -2.1976,  ...,  6.6943,  0.9442,  5.7200],\n",
       "         [ 2.5254,  1.9573,  3.1489,  ...,  5.2667,  0.8100,  2.8129],\n",
       "         [ 6.1641,  2.3291,  1.7434,  ...,  5.2578,  0.3427,  4.1483],\n",
       "         ...,\n",
       "         [-3.0731, -1.9034, -2.0554,  ...,  6.0903, -0.5417,  4.8333],\n",
       "         [-3.9729,  0.9990, -4.7842,  ...,  5.0441,  1.1301,  5.3308],\n",
       "         [-1.8501,  4.3687, -2.8431,  ...,  3.9733,  1.5061,  2.8267]]],\n",
       "       grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_pos"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ac210c7-4e10-4002-bd79-0a97ec525d8a",
   "metadata": {},
   "source": [
    "# MultiHeadAttention\n",
    "- sem mask pois queremos olhar para trás e para frente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "bfb0b24e-57e8-49cf-a507-00480c5a66b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers_utils.attention import MultiHeadAttention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "eb919116-39ac-4f1e-a41c-6c7d8b5f8103",
   "metadata": {},
   "outputs": [],
   "source": [
    "mult_head_att_layer = MultiHeadAttention()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "4f59a173-2067-4ded-b1c9-bb81feeb685e",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_att = mult_head_att_layer(x_pos)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3aee3fbb-51a0-4028-9f2f-7828d682a78f",
   "metadata": {},
   "source": [
    "# Testes aleatorios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "b8faefc8-8ed4-4227-8048-711a92101a92",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8.0"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "32/4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f923b2e-6afe-4dd9-b3d4-ace2864eaa36",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env_pytorch",
   "language": "python",
   "name": "env_pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
