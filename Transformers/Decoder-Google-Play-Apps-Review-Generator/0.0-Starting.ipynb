{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8754901d-c404-49d9-99ef-8fdfde859439",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "M:\\disco M\\Python\\venvs\\env_torch\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from torchtext.vocab import build_vocab_from_iterator\n",
    "from datasets import load_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7c7ec90b-fd8f-4741-a73a-ba4d8079cc2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# baixando a base utilizada\n",
    "dataset = load_dataset(\"AiresPucrs/google-play-apps-review-pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5c667dfb-24d0-4d07-a5ac-c0d202015709",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchtext.data.utils import get_tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "df358a34-de51-41c7-b672-f05cf48dc951",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Olá', 'você', '!']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer = get_tokenizer('spacy', language='pt_core_news_sm')\n",
    "tokenizer('Olá você!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "cb2f9739-5994-4d4e-a333-3cb602ed4dd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Callable, List, Iterable\n",
    "# def yield_tokens(data_iter: Iterable, tokenizer: Callable[str, List[str]]) -> List[str]:\n",
    "def yield_tokens(data_iter: Iterable, tokenizer) -> List[str]:\n",
    "    for data_sample in data_iter['train']['review']:\n",
    "        yield tokenizer(data_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "35edf033-0caf-4915-85c1-5073f490a618",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "o aplicativo e bom disparadamente melhor que o concorrente whatsapp pontos positivos  possibilidade de aplicar temas personalizados para sair da aparencia padrao de acordo com o usuario  a nao utilizacao de um backup local e sem a possibilidade de perder todas as mensagens acidentalmente por ser um servico via nuvem  a possibilidade de usar bots como um diferencial alem de somente usar o aplicativo para conversar ou seja e possivel ampliar o uso do aplicativo para outras coisas interessantes como por exemplo estudar  a possibilidade de se entreter com jogos e se divertir com outros contatosamigos similar ao ponto anterior  a existencia de um chat secreto para autodestruir mensagens que 2 usuarios nao queiram que fiquem armazenadas na nuvem sendo assim uma forma de conversar com privacidade total ainda ha outros pontos positivos mas nao e necessario citar todos eu tenho somente um ponto negativo tal ponto e a instabilidade do sistema em nuvem do telegram que certas vezes dessincroniza as mensagens enviadas e recebidas eu tambem sugiro adicionar a funcao de esconder a foto de perfil para contatosninguem e uma contagem de mensagens\n"
     ]
    }
   ],
   "source": [
    "for text in dataset['train']['review']:\n",
    "    print(text)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "4567d92c-039d-44c4-ac89-a52abc91e2d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "UNK_IDX, PAD_IDX, BOS_IDX, EOS_IDX = 0, 1, 2, 3\n",
    "special_symbols = ['<unk>', '<pad>', '<sos>', '<eos>']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "a96dc7d3-3ced-4c80-af51-7ac7c6f8b567",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_transform = build_vocab_from_iterator(\n",
    "    yield_tokens(dataset, tokenizer),\n",
    "    min_freq=2,\n",
    "    specials=special_symbols,\n",
    "    special_first=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "395ba2fb-7c9a-409c-b064-6002a1615f86",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_transform.set_default_index(UNK_IDX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "4827e005-520a-4d61-a676-dfeb7590c311",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['<unk>', '<pad>', '<sos>', '<eos>', 'e', 'o', 'de', 'que', 'nao', 'a', 'app', 'um', 'do', 'com', 'para', 'eu', 'no', 'mais', 'muito', 'em', 'uma', 'mas', 'tem', 'por', 'os', 'aplicativo', 'se', 'da', 'pra', 'as', 'isso', 'na', 'so', 'ja', 'pedido', 'meu', 'quando', 'esta', 'bom', ' ', 'como', 'me', 'ou', 'minha', 'sem', 'mesmo', 'ele', 'foi', 'vezes', 'ter', 'problema', 'nada', 'fazer', 'opcao', 'ao', 'conta', 'ate', 'esse', 'pelo', 'ser', 'nem', 'videos', 'pois', 'estou', 'sempre', 'q', 'entrega', 'tenho', 'bem', 'fica', 'consigo', 'voce', 'agora', 'sao', 'video', 'tempo', 'dos', 'tudo', 'pessoas', 'porem', 'melhor', 'depois', 'vez', 'usar', 'ainda', 'porque', 'uber', 'tambem', 'tive', 'ver', 'cartao', 'vc', 'valor', 'assim', 'ta', 'nos', 'nunca', 'fiz', 'pagamento', 'hora', 'restaurante', 'eles', 'era', 'acho', 'problemas', 'aparece', 'coisa', 'essa', 'pq', 'otimo', 'vou', 'outro', 'compra', 'suporte', 'dia', 'todos', 'das', 'estao', 'vai', 'ai', 'dinheiro', 'celular', 'atualizacao', 'pagar', 'pode', 'estava', 'tinha', 'uso', 'contato', 'quem', 'sendo', 'alem', 'entao', 'alguns', 'forma', 'outra', 'pessimo', 'simplesmente', 'fui', 'entregador', 'erro', 'gosto', 'ruim', 'instagram', 'dar', 'faz', 'mensagem', 'outros', '5', 'gente', 'restaurantes', 'antes', 'facebook', 'ifood', 'cupom', 'cada', 'motorista', '2', 'estrelas', 'voces', 'cliente', 'pessoa', 'coisas', 'favor', 'nenhum', 'cancelar', 'ha', 'pedidos', 'entrar', 'falta', 'melhorar', 'muitas', 'cupons', 'seria', 'experiencia', 'menos', 'apenas', 'hoje', 'deveria', 'varias', 'n', 'sei', 'tentei', 'ficar', 'colocar', 'horrivel', 'funciona', 'youtube', 'fora', 'meus', 'pedir', 'poderia', 'desconto', 'servico', 'mim', 'toda', 'opcoes', 'dias', 'algo', 'boa', 'corrida', 'algumas', 'plataforma', 'fotos', 'seja', 'recomendo', 'algum', '1', 'tela', 'todo', 'muitos', 'motoristas', 'novamente', 'consegui', 'onde', 'tipo', 'varios', 'seu', 'quase', 'telegram', 'novo', 'pouco', 'la', 'quero', 'mensagens', 'pior', 'endereco', '3', 'ajuda', 'atendimento', 'aqui', 'precisa', 'email', 'outras', 'duas', 'minutos', 'numero', 'pela', 'todas', 'anuncios', 'exemplo', 'perfil', 'falar', 'espero', 'resolver', 'poder', 'bastante', 'disso', 'facil', 'nas', 'credito', 'comprar', 'vcs', 'parte', 'promocoes', 'primeira', 'qualidade', 'sobre', 'super', 'foto', 'possivel', 'te', 'taxa', 'bugs', 'muita', 'vem', 'qualquer', 'tik', 'apos', 'usuario', 'desde', 'quer', 'tok', 'nenhuma', 'gostaria', 'deu', 'sua', 'viagem', 'excelente', 'ficou', 'sou', 'reais', 'deixa', 'recebi', 'fiquei', 'queria', 'demais', 'rapido', 'produto', '4', 'produtos', 'caso', 'mesma', 'errado', 'ninguem', 'usuarios', 'loja', 'whatsapp', '10', 'gostei', 'volta', 'ultima', 'postar', 'trava', 'saber', 'codigo', 'estabelecimento', 'alguma', 'comida', 'tinder', 'infelizmente', 'dando', 'legal', 'demora', 'diz', 'anos', 'dois', 'uns', 'bug', 'horas', 'pro', 'dificil', 'tanto', 'realmente', 'telefone', 'chega', 'conseguir', 'momento', 'tao', 'acontece', 'ela', 'tiktok', 'sistema', 'tendo', 'quanto', 'casa', 'promocao', 'nova', 'aos', 'certo', 'este', 'etc', 'pedi', 'amigos', 'tbm', 'cancelamento', 'twitter', 'amo', 'meio', 'unica', 'existe', 'preciso', 'consegue', 'deixar', 'motivo', 'perfeito', 'parabens', 'qual', 'feito', 'desse', 'alguem', 'contas', 'logo', 'minhas', 'rappi', 'atualizacoes', 'jeito', 'assistir', 'preco', 'abrir', 'eats', 'esses', 'to', 'chato', 'primeiro', 'compras', 'mudar', 'posso', 'sim', 'pessima', 'conteudo', 'veio', 'chegou', 'empresa', 'poderiam', 'voltar', 'internet', 'achei', 'chat', 'local', 'tento', 'ir', 'tentar', 'acesso', 'entregadores', 'receber', 'rede', 'obrigado', 'resposta', 'nota', 'seus', 'apps', 'esperando', 'tivesse', 'lugar', 'anuncio', 'musica', 'desinstalei', 'ficam', 'pena', 'for', 'grande', 'mercado', 'tentando', 'aconteceu', 'atualizar', 'proprio', 'paguei', 'fazendo', 'vi', 'criar', 'parece', 'tirando', 'reclamacao', 'enviar', 'unico', 'dados', 'adicionar', 'causa', 'dou', 'itens', 'escolher', 'maioria', 'comentarios', 'senha', 'trabalho', 'utilizar', 'chegar', 'entre', 'reembolso', 'somente', 'notificacoes', 'simples', 'reclamar', 'deveriam', 'perdi', 'continua', 'delivery', 'nesse', 'entregas', 'maior', 'absurdo', 'estar', 'foram', 'fato', 'feed', 'funcao', 'usando', 'pagina', 'desinstalar', 'principalmente', 'fosse', 'havia', 'sair', 'estrela', 'fazem', 'mal', 'questao', 'ponto', 'pago', 'normal', 'ultimamente', 'essas', 'versao', 'acessar', 'faco', 'incrivel', 'lanche', 'aceita', 'clientes', 'si', 'acaba', 'aplicativos', '30', 'mostra', 'baixar', 'tirar', 'enfim', 'passar', 'peco', 'troco', 'aparecem', 'status', 'meses', 'dele', 'sido', 'dessa', 'instalei', 'mes', 'avaliacao', 'entrei', 'usei', 'opiniao', 'pede', 'audio', 'pratico', 'sai', 'nome', 'precos', 'dentro', 'debito', 'localizacao', 'modo', '99', 'final', 'acontecendo', 'desejar', 'entregue', 'vao', 'grupos', 'dizer', 'enquanto', 'entra', 'cancelam', 'seguranca', 'dizendo', 'fala', 'maravilhoso', 'cancelado', 'direto', 'finalizar', 'impossivel', 'vida', 'descontos', 'podem', 'stories', 'cara', 'abre', 'contar', 'mundo', 'social', 'pix', 'carro', 'concorrente', 'erros', 'instalar', 'ne', 'disponivel', 'vale', 'fico', 'encontrar', 'melhores', 'relacao', 'geral', 'inicio', 'semana', 'via', 'propaganda', 'caro', 'aparecer', 'canal', 'frete', 'cobrado', 'acredito', 'funcoes', 'notificacao', 'totalmente', 'aparecendo', 'deles', 'esperar', 'mandar', 'temos', 'apareceu', 'musicas', 'umas', 'atras', 'lixo', 'carrega', 'comigo', 'ontem', 'otima', 'quantidade', 'vejo', 'obrigada', 'resolvam', 'total', 'diferente', 'arrumem', 'interessante', 'entro', 'conseguindo', 'informacoes', 'respeito', 'cadastro', 'botao', 'p', 'tenha', 'sugestao', 'dao', 'pontos', 'ajudar', 'comunicacao', 'cobranca', 'atencao', 'direito', 'ligar', 'pegar', 'cidade', 'entregar', 'fez', 'perder', 'trocar', 'deixando', 'funcionar', 'gratis', 'quiser', 'estabelecimentos', 'querem', 'funcionando', 'mt', 'nele', 'ideia', 'igual', 'lado', 'acabei', 'adoro', 'certeza', 'disse', 'util', 'aceitam', 'interface', 'recebo', 'teve', 'cima', 'consumidor', 'editar', 'limite', 'cerveja', 'cheio', 'continuar', 'situacao', 'carregar', 'horario', 'minimo', 'olha', 'amei', 'diferentes', 'item', 'passa', 'site', 'viagens', 'boas', 'canais', 'paga', 'valores', 'cancelou', 'dai', 'cancela', 'falha', 'ficando', 'normalmente', 'realizar', 'reels', 'resto', 'apesar', 'publicacoes', 'travando', '20', 'aparelho', 'sinceramente', 'faltando', 'segunda', 'achar', 'dei', 'novas', 'comprei', 'tal', 'real', 'retorno', 'seguir', 'falando', 'login', 'podia', 'motoboy', 'seguidores', 'sera', 'automaticamente', 'cartoes', 'lista', 'bons', 'imagem', 'ok', 'precisam', 'sabe', 'fim', 'deve', 'diversas', 'match', 'segundo', 'claro', 'cadastrar', 'melhorem', 'extremamente', 'apagar', 'informacao', 'tarde', 'coloquei', 'hj', 'pedindo', 'verdade', 'recuperar', 'ganhar', 'ia', 'isto', 'like', 'corridas', 'permite', 'responder', 'taxas', 'conteudos', 'espera', 'ler', 'excluir', 'aceitar', 'nossa', 'coloca', 'espaco', 'sentido', 'estorno', 'recursos', 'android', 'distancia', 'noite', 'num', 'querer', 'baixo', 'durante', 'fechar', 'online', 'equipe', 'possibilidade', 'rapida', 'tava', 'tiver', 'curtir', 'dificuldade', 'sms', 'ano', 'insta', 'resolve', 'resolvido', 'acompanhar', 'conversar', 'sozinho', 'atraves', 'devido', 'servicos', 'solucao', '15', 'usa', 'busca', 'premium', 'regiao', 'salvar', 'bugado', 'coloco', 'contatos', 'dava', 'google', 'grupo', 'mostrar', 'triste', 'perfis', 'comentario', 'ferramenta', 'manda', 'aba', 'pessoal', 'imagens', 'inclusive', 'conversas', 'propagandas', 'creditos', 'disponiveis', 'serio', 'clicar', 'gravar', 'story', 'baixei', 'complicado', 'memoria', 'nessa', 'teria', 'diversos', 'retirar', 'desenvolvedores', 'lento', 'selecionar', 'vamos', 'agradeco', 'entendo', 'mandei', 'msg', 'segundos', 'tres', 'vendo', 'comeco', 'compartilhar', 'concorrencia', 'parou', 'pesquisa', 'conversa', 'legais', 'mto', 'suas', 'alterar', 'apresenta', 'configuracoes', 'lojas', 'precisar', 'publicacao', 'deus', 'efeitos', 'sinto', 'elas', 'estamos', 'intuitivo', 'muda', 'podemos', 'filtros', 'maneira', 'ridiculo', 'avaliar', 'ca', 'perde', 'proximo', 'carrinho', 'deixou', 'deram', 'oq', 'prazo', 'proxima', 'oferece', 'perto', 'passageiro', 'existem', 'tempos', 'zero', 'adianta', 'aplicacao', 'atualizei', 'falhas', 'frequencia', 'longe', 'min', 'responde', 'ola', 'prejuizo', 'atualiza', 'decepcionada', 'parar', 'atendente', 'escuro', 'funcionam', 'houve', 'pelos', 'praticamente', 'cobrar', 'conhecer', 'face', 'mexer', 'formas', 'msm', 'refeicao', 'ze', '6', 'bebidas', 'buscar', 'central', 'confirmacao', 'entender', 'comer', 'inves', 'nosso', 'possa', 'clico', 'culpa', 'fizeram', 'necessario', 'oque', 'poucos', 'top', 'anterior', 'informar', 'carregando', 'completamente', 'perdendo', 'r', '100', 'fecha', 'novos', 'possui', 'sequer', 'comecou', 'cuidado', 'reclamacoes', 'confirmar', 'moro', 'chegam', 'concorrentes', 'numa', 'seguro', 'verificacao', 'aberto', 'filtro', 'recentemente', 'rua', 'ultimos', 'importante', 'precisei', 'talvez', 'postagens', 'texto', 'amor', 'gold', 'haver', 'arquivos', 'bk', 'vontade', 'cabeca', 'data', 'verificar', 'atende', 'fome', 'iria', 'km', 'menor', 'passou', 'atraso', 'caminho', 'destino', 'inicial', 'raiva', '0', 'atualizado', 'brasil', 'completo', 'procurar', 'semanas', 'ultimo', 'assinatura', 'cadastrado', 'interesse', 'plano', 'passo', 'antigo', 'assistindo', 'caixa', 'gosta', 'storys', 'abro', 'recurso', 'troca', 'area', 'd', 'escolha', 'lamentavel', 'mil', 'principal', 'sucesso', '50', 'likes', 'volto', '40', 'gps', 'meia', 'metade', 'prime', 'bebida', 'colocam', 'historico', 'mao', 'posta', 'utilizo', 'dica', 'mulheres', 'baixa', 'confuso', 'demorou', 'saldo', 'aviso', 'chamada', 'comeca', 'curtidas', 'idade', 'ocorreu', 'usado', 'arrumar', 'atualmente', 'conexao', 'ganhei', 'liguei', 'passei', 'qdo', 'comentar', 'dado', 'indo', 'pudesse', 've', 'barra', 'noticias', 'pagando', 'supermercado', 'variedade', 'envio', 'poucas', 'seguinte', 'descaso', 'mapa', 'processo', 'saiu', 'serve', 'ticket', 'acontecer', 'embora', 'aguardando', 'cancelando', 'devia', 'experiencias', 'mesmos', 'monte', 'necessidade', 'prefiro', 'cancelamentos', 'desinstalando', 'dizem', 'lanches', 'privacidade', 'respondem', 'agr', 'bloquear', 'efetuar', 'ex', 'ligacao', 'solicitar', 'disseram', 'envia', 'resolveu', 'vir', 'aquela', 'banida', 'cobram', 'pega', 'respostas', 'tb', 'visto', 'atrapalha', 'entanto', 'feita', 'food', 'nisso', 'passando', 'wifi', 'aparecia', 'correto', 'facilidade', 'fechado', 'melhora', 'som', 'acima', 'agente', 'gostando', 'informa', 'mandam', 'otimos', 'tenta', 'trabalhar', 'usava', 'barato', 'cancelaram', 'comecar', 'encontrei', 'estavam', 'manter', 'recebe', 'shorts', 'sigo', 'cancelei', 'cobrando', 'compro', 'frente', 'funcionalidades', 'link', 'lugares', 'maximo', 'pesquisar', 'sumiu', 'deste', 'diferenca', 'distribuidor', 'solicitei', 'acabou', 'banco', 'demoram', 'enganosa', 'indico', 'neste', 'tentativas', 'tira', 'ultimas', 'contrario', 'corretamente', 'daria', 'some', 'sorte', 'audios', 'camera', 'certa', 'cinco', 'logar', 'publico', 'regras', 'resolvem', 'serem', 'atender', 'celulares', 'contra', 'detalhe', 'pagamentos', 'paginas', 'pandemia', 'passado', '7', 'corrigir', 'incomoda', 'live', 'mc', 'nn', 'estiver', 'solicitacao', 'torna', 'aquele', 'gelada', 'mostrando', 'ofertas', 'postagem', 'alta', 'antiga', 'campo', 'eficiente', 'falam', 'ficaria', 'funcional', 'ganha', 'geralmente', 'ingles', 'posto', 'redes', 'percebi', 'quente', 'seguida', 'tema', 'trajeto', 'chegando', 'escrever', 'graca', 'visualizacao', 'deixam', 'funcionou', 'gostava', 'publicar', 'usam', 'viu', 'x', '8', 'alto', 'consertem', 'dor', 'enviei', 'gorjeta', 'layout', 'ma', 'negocio', 'ocorre', 'tipos', 'avaliacoes', 'chamar', 'dispositivo', 'levar', 'pequeno', 'perfeitamente', 'salvos', 'aumentar', 'cai', 'cobra', 'lives', 'mudou', 'ouvir', 'relacionamento', 'rever', 'tweets', 'aceito', 'cache', 'colocando', 'curtiu', 'descricao', 'legenda', 'lite', 'parceiros', 'pesado', 'politica', 'resolucao', 'coloquem', 'decepcionado', 'feedback', 'grandes', 'propria', 'pular', 'salva', 'venho', 'visualizar', 'abri', 'adorei', 'cobraram', 'configuracao', 'criadores', 'facilitar', 'king', 'procurando', 'querendo', 'sacola', 'aplicar', 'bairro', 'criancas', 'duvida', 'justo', 'termos', 'travar', 'acabar', 'errada', 'galeria', 'golpe', 'motivos', 'tamanho', 'tanta', 'aceitou', 'amigo', 'atualizando', 'cheguei', 'critica', 'favoritos', 'figurinhas', 'reclamando', 'reclamei', 'aguardo', 'algoritmo', 'bloqueada', 'divertido', 'facam', 'funcionalidade', 'gastar', 'indisponivel', 'vergonha', 'you', 'conseguia', 'duvidas', 'informado', 'irei', 'junto', 'menu', 'realizei', 'dela', 'feliz', 'otimas', 'play', 'ruins', 'acha', 'decepcao', 'deixo', 'frustrante', 'leve', 'palavras', 'piorar', 'precisava', 'troquei', 'efeito', 'faca', 'fatura', 'fornecedor', 'nossas', 'nossos', 'obtive', 'pizza', 'pronto', 'apresentando', 'cardapio', 'chance', 'criei', 'diretamente', 'edit', 'habibs', 'mcdonalds', 'pensei', 'porta', 'sugiro', 'estranho', 'inumeras', 'irritante', 'mano', 'obs', 'pedem', 'resolvi', 'tido', '99food', 'conseguem', 'defeito', 'eh', 'familia', 'maiores', 'recebendo', 'automatica', 'creio', 'desisti', 'mercados', 'ocorrido', 'olhar', 'tantos', 'terrivel', 'vim', 'avisar', 'chateada', 'conheco', 'continuo', 'deixei', 'dificulta', 'falaram', 'fila', 'legendas', 'leva', 'marcar', 'melhorou', 'mudanca', 'podiam', 'tente', 'tv', 'absolutamente', 'atendido', 'cobrou', 'cor', 'desativar', 'esteja', 'ferramentas', 'minuto', 'moto', 'nivel', 'padrao', 'pais', 'permitir', 'previsao', 'reiniciar', 'somos', 'sugestoes', '1000', 'abaixo', 'ah', 'ajudem', 'cancelada', 'certinho', 'entrou', 'portugues', 'queremos', 'tantas', 'transporte', 'atrasado', 'atual', 'branco', 'concluir', 'condicoes', 'explicacao', 'facilita', 'inserir', 'sinal', 'sociais', 'utilizando', 'voltei', '12', 'bloqueado', 'cobrancas', 'enorme', 'entretanto', 'melhorias', 'pratica', 'resolveram', 'sabem', 'sensacional', 'senti', 'acabo', 'aqueles', 'comunicar', 'interacao', 'oportunidade', 'preta', 'saindo', 'surpresa', 'vindo', 'acordo', 'conseguimos', 'custo', 'dps', 'encontro', 'estando', 'filmes', 'liberdade', 'passageiros', 'casos', 'conheci', 'controle', 'dependendo', 'encontra', 'interagir', 'inutil', 'marca', 'negativo', 'resumindo', 'rota', 'tu', 'computador', 'delas', 'detalhes', 'estornado', 'mandando', 'pouca', '18', 'antigos', 'consta', 'cpf', 'desta', 'ficava', 'locais', 'oferecer', 'pediu', 'praticidade', 'precisamos', 'proximos', 'reinstalei', 'atendeu', 'c', 'descontado', 'distribuidora', 'eram', 'gratuito', 'inteiro', 'pensando', 'pude', 'terem', 'voltou', 'antigamente', 'bacana', 'carregam', 'carros', 'clica', 'curto', 'decepcionante', 'download', 'entregou', 'enviado', 'falei', 'falou', 'interessantes', 'livre', 'manha', 'melhoria', 'merece', 'paciencia', 'palhacada', 'proposta', 'quais', 'tinham', 'achando', 'constantemente', 'jogos', 'navegacao', 'pastas', 'sejam', 'tentativa', 'amizades', 'ativar', 'dessas', 'enviam', 'melhore', 'partir', 'print', 'segue', 'tornou', '1h', 'atualizou', 'automatico', 'fundo', 'piorou', 'quesito', 'saco', 'salvo', 'travado', 'vivo', 'buga', 'desses', 'esperei', 'evitar', 'funcionamento', 'mesmas', 'momentos', 'oi', 'previsto', 'resultado', 'retirada', 'sac', 'superior', 'voz', 'entregam', 'fe', 'relatar', 'transtorno', 'usabilidade', 'usem', 'visual', 'banir', 'caros', 'corrijam', 'devolver', 'direct', 'entrando', 'funcionava', 'pc', 'puderem', 'terceira', 'utilizacao', 'valido', '25', 'ambos', 'cervejas', 'chamadas', 'conectar', 'confiavel', 'deviam', 'dizia', 'emails', 'icone', 'informando', 'instalado', 'jogo', 'matches', 'oferecem', 'posts', 'rapidamente', 'recebido', 'traduzir', 'utilizei', 'acabam', 'cobrada', 'crianca', 'demorando', 'devem', 'empresas', 'escrito', 'fake', 'mudei', 'pelas', 'periodo', 'prato', 'venda', 'ali', 'armazenamento', 'arquivo', 'assinar', 'bots', 'formato', 'mandaram', 'mandou', 'mulher', 'seguindo', 'tweet', 'aguardar', 'assisto', 'compromisso', 'conforme', 'determinado', 'estado', 'incluir', 'numeros', 'plataformas', 'possam', 'resolverem', 'respondeu', 'botar', 'branca', 'clube', 'daqui', 'descobrir', 'especifico', 'estivesse', 'ganho', 'independente', 'insuportavel', 'liga', 'ligacoes', 'linha', 'quis', 'shopping', 'carteira', 'cheia', 'colocou', 'comunidade', 'continuam', 'correta', 'demorar', 'iphone', 'mae', 'pensar', 'pequena', 'post', 'pratos', 'precisando', 'quatro', 'saio', 'satisfacao', 'textos', 'timeline', 'tras', 'vieram', 'virou', '60', '9', 'assuntos', 'basta', 'conseguiu', 'digitar', 'entregaram', 'exatamente', 'exclui', 'provavelmente', 'sabendo', 'usalo', 'uteis', 'vantagem', 'velocidade', 'aprender', 'caiu', 'comidas', 'entendi', 'excluida', 'ficamos', 'informou', 'meios', 'messenger', 'observacao', 'pos', 'qnd', 'recebeu', 'remover', 'sabia', 'situacoes', 'solucionar', 'vista', 'breve', 'cadastrados', 'chata', 'colocaram', 'comum', 'entregues', 'literalmente', 'mudando', 'odio', 'perco', 'perdeu', 'perdido', 'playlist', 'restante', 'tals', '24', 'acessivel', 'banido', 'cash', 'combo', 'descobri', 'dificuldades', 'enviando', 'excesso', 'homens', 'importa', 'incriveis', 'piora', 'realizado', 'resolva', 'responderam', 'samsung', 'teste', 'alias', 'comecei', 'comercial', 'debitado', 'edicao', 'finalmente', 'idioma', 'objetivo', 'programa', 'refazer', 'risco', 'tiraram', 'acontecido', 'bonus', 'botoes', 'desagradavel', 'pequenas', 'preferencia', 'reproducao', 'temas', 'tomar', 'andamento', 'colocado', 'compensa', 'darei', 'devolveram', 'educados', 'emojis', 'facilmente', 'limpar', 'matchs', 'probleminha', 'reinstalar', 'satisfeito', 'tenham', 'traducao', 'aproveitar', 'atendida', 'aumenta', 'confianca', 'contudo', 'denunciar', 'devolucao', 'disponibilizar', 'enviaram', 'errados', 'explicar', 'fique', 'injusto', 'irrita', 'pacote', 'palavra', 'parceiro', 'partes', 'repente', 'satisfeita', 'selecao', 'shopper', 'tchau', 'traz', 'trazer', 'utilizado', 'abrindo', 'aonde', 'apoio', 'assunto', 'cadastrei', 'cade', 'cumpre', 'curti', 'farmacia', 'gera', 'imediatamente', 'importantes', 'navegador', 'nesses', 'original', 'peca', 'pediram', 'pequenos', 'reiniciei', 'smartphone', 'testei', 'ubereats', 'alteracao', 'ativo', 'baixem', 'codigos', 'comprando', 'continuem', 'defeitos', 'denovo', 'direitos', 'dobro', 'g', 'invalido', 'kkk', 'limpei', 'midias', 'procura', 'profissionais', 'residencia', 'responsabilidade', 'somem', 'tube', 'vantagens', 'vender', '  ', 'afinal', 'ajudaria', 'ar', 'burger', 'caras', 'chegaram', 'consideracao', 'demorado', 'escolhe', 'escolhendo', 'fazia', 'inferior', 'informaram', 'kkkk', 'lendo', 'liberar', 'mando', 'nuvem', 'obriga', 'oferta', 'postei', 'profissional', 'recente', 'tempao', '2022', 'amiga', 'beneficio', 'certos', 'copiar', 'der', 'diminuir', 'engracado', 'faltou', 'favorito', 'feitas', 'impressao', 'longo', 'm', 'mensageiro', 'obg', 'pasta', 'penso', 'poxa', 'solicitado', 'suficiente', 'trabalha', '2h', 'anda', 'atendentes', 'bloqueio', 'categoria', 'chamado', 'depende', 'escolho', 'galera', 'gerar', 'grata', 'integral', 'ira', 'mudancas', 'perguntas', 'presta', 'raramente', 'referente', 'refrigerante', 'rodando', 'taxi', 'testar', 'tornar', 'use', 'voltando', 'almoco', 'balcao', 'certas', 'completa', 'conectado', 'esqueci', 'faltam', 'finalizacao', 'i', 'pessoais', 'podendo', 'portanto', 'postam', 'postando', 'rapidas', 'rapidez', 'roda', 'td', 'tornando', '13', '2020', 'ajudou', 'aparelhos', 'bateria', 'bonito', 'bugando', 'capa', 'cep', 'desistir', 'digital', 'dnv', 'dono', 'metodo', 'show', 'urgente', 'visualizacoes', 'web', '200', 'acompanhamento', 'atendem', 'avisa', 'consertar', 'diretrizes', 'entretenimento', 'epoca', 'excelentes', 'limitado', 'maravilhosa', 'menores', 'midia', 'mudo', 'parada', 'parado', 'piores', 'promocional', 'pros', 'terei', 'virtual', 'vr', 'yt', 'acao', 'acrescentar', 'agradecer', 'amizade', 'assistencia', 'batata', 'concluido', 'enviou', 'estresse', 'existir', 'famosos', 'ficaram', 'fornecedores', 'gentileza', 'imediato', 'justificativa', 'mau', 'obter', 'ordem', 'parem', 'participar', 'passam', 'permissao', 'pfv', 'possuem', 'realidade', 'recentes', 'travamentos', 'vive', 'abaixar', 'assinei', 'atrasa', 'bloqueia', 'cancelados', 'chama', 'considero', 'design', 'disponibiliza', 'divertir', 'gb', 'organizar', 'pedimos', 'postado', 'proximas', 'queira', 'reportar', 'seleciono', 'stickers', 'travou', 'absurda', 'agradavel', 'aparentemente', 'aumento', 'beneficios', 'burguer', 'comecando', 'conseguiram', 'constantes', 'contatar', 'cores', 'custa', 'deem', 'deixaram', 'divulgar', 'documento', 'escolhi', 'extra', 'fakes', 'falo', 'fiscal', 'horarios', 'inuteis', 'ligado', 'melhorando', 'peguei', 'plus', 'promocionais', 'razao', 'selecionado', 'supermercados', 'tocar', 'topo', 'aceitando', 'adicionem', 'alegando', 'bate', 'denuncia', 'desaparece', 'descer', 'drive', 'encomenda', 'engano', 'estes', 'filtrar', 'frequentemente', 'genero', 'grato', 'historia', 'intuitiva', 'levou', 'nd', 'ocorrendo', 'organizacao', 'organizado', 'perguntando', 'senao', 'store', 'subir', 'urgencia', 'voltem', 'alimentacao', 'ativa', 'carne', 'comodidade', 'conferir', 'confusa', 'criador', 'deseja', 'distribuidores', 'donalds', 'enderecos', 'fidelidade', 'finalizado', 'fossem', 'gastei', 'infinitamente', 'jogar', 'lentidao', 'medo', 'motoqueiro', 'navegar', 'nesta', 'perda', 'pfvr', 'privado', 'reproduzir', 'tiveram', 'viajem', '2x', '90', 'absurdamente', 'acessibilidade', 'aspectos', 'basico', 'cansativo', 'chats', 'cliquei', 'confiar', 'desenvolvimento', 'desnecessario', 'eou', 'gratuita', 'iniciar', 'letras', 'nascimento', 'novidades', 'preto', 'puder', 'reclame', 'sacanagem', 'tirem', 'validade', 'vendedor', 'aplicado', 'arrumarem', 'caracteres', 'carregamento', 'chateado', 'coloque', 'completar', 'devo', 'domingo', 'feitos', 'filme', 'fiquem', 'frio', 'gracas', 'hamburguer', 'homem', 'horriveis', 'insatisfeito', 'milhares', 'negativa', 'nela', 'olhando', 'papo', 'passada', 'pendente', 'primeiros', 'proprios', 'sabemos', 'series', 'servidor', 'sumiram', 'trata', 'visao', 'volte', '1deg', 'denuncias', 'desculpa', 'desempenho', 'dispositivos', 'educacao', 'esposa', 'facilitaria', 'faturas', 'gostar', 'ideal', 'incomodo', 'indevida', 'justamente', 'lhe', 'melhorado', 'mudem', 'nocao', 'noturno', 'pre', 'pretendo', 'proposito', 'rastreamento', 'restricao', 'terminar', '500', 'acontecem', 'alternativa', 'antigas', 'ato', 'canceladas', 'colocarem', 'continue', 'cria', 'deixem', 'dificultando', 'dinamica', 'direciona', 'funcionarios', 'fy', 'iriam', 'maos', 'ocorrer', 'oferecido', 'pagamos', 'partida', 'promete', 'questoes', 'rastrear', 'resenha', 'sugerir', 'tecnico', 'ttk', 'valeu', 'veja', 'agilidade', 'aguento', 'amando', 'atrapalhando', 'automaticas', 'cel', 'comparado', 'curtos', 'decidi', 'desrespeito', 'destaques', 'distante', 'documentos', 'estornar', 'estressante', 'exato', 'expressao', 'gasto', 'geladas', 'instabilidade', 'permitem', 'pessimos', 'quantas', 'robo', 'sabor', 'segura', 'simplismente', 'time', 'toxico', 'validar', 'vejam', 'verifiquei', '2000', 'acham', 'adiantou', 'amava', 'aperto', 'atrasos', 'cerca', 'concertem', 'conclusao', 'demanda', 'deposito', 'desistindo', 'enganacao', 'especial', 'etapas', 'expectativas', 'fazerem', 'fechando', 'gostos', 'haja', 'indicar', 'indisponiveis', 'insatisfeita', 'maquina', 'migrar', 'msgs', 'posicao', 'procon', 'resultados', 'resumo', 'retornar', 'solicita', 'trocado', 'unidade', 'vira', '11', 'adicionado', 'altos', 'andar', 'aquelas', 'centro', 'contem', 'desativada', 'enviadas', 'experimentar', 'famoso', 'fizer', 'houvesse', 'indicacao', 'leitura', 'links', 'marketing', 'moveis', 'obrigatorio', 'optar', 'parecido', 'particularmente', 'perderam', 'presente', 'resgatar', 'sentindo', 'tivemos', 'tranquilo', 'zona', '1080p', 'adicionei', 'bloquearam', 'bot', 'caindo', 'curtida', 'diariamente', 'diferencial', 'fechados', 'fornece', 'grave', 'lucro', 'modelo', 'mudaram', 'naquele', 'obviamente', 'otimizado', 'perca', 'perceber', 'pergunta', 'piorando', 'positivo', 'possiveis', 'predio', 'preparado', 'publicidade', 'reclama', 'regra', 'rosto', 'sozinha', 'validacao', 'whats', 'ajudam', 'alelo', 'analise', 'anteriores', 'anteriormente', 'atrasou', 'aumentou', 'baixado', 'burocracia', 'caramba', 'cidades', 'combos', 'compartilhamento', 'conhecimento', 'crescer', 'essencial', 'fatores', 'feio', 'ficarem', 'fraude', 'free', 'incompleto', 'indicado', 'interessa', 'manualmente', 'marcado', 'marketplace', 'mentira', 'odiei', 'operadora', 'pedia', 'prestado', 'pudessem', 'recuperacao', 'republicar', 'responsavel', 'sanduiche', 'sentir', 'spam', 'tomem', 'venha', 'zap', '14', 'aberta', 'acoes', 'aniversario', 'apertar', 'apresentado', 'aprovado', 'atualizo', 'baixe', 'chegada', 'chego', 'chip', 'comprado', 'concordo', 'conhece', 'costumo', 'criticas', 'curte', 'dentre', 'desnecessarias', 'digo', 'editando', 'falsos', 'identificar', 'intencao', 'lanchonete', 'mantem', 'motoboys', 'observacoes', 'obvio', 'pague', 'passaram', 'perfeita', 'pessoalmente', 'prejudica', 'procedimento', 'quarentena', 'recorrente', 'rodar', 'roubo', 'sequencia', 'serie', 'sessao', 'sodexo', 'tera', 'tirei', '24h', 'aceite', 'achava', 'agua', 'apaga', 'bagunca', 'bloqueou', 'comparacao', 'constante', 'consumo', 'criando', 'demorei', 'desejo', 'desenvolvedor', 'embarque', 'ent', 'entram', 'espanhol', 'fantastico', 'finalizei', 'golpes', 'humano', 'insatisfacao', 'instalo', 'instavel', 'ligou', 'media', 'mostram', 'multa', 'obrigando', 'parecem', 'persiste', 'personalizacao', 'pesquiso', 'playlists', 'politicas', 'pontuacao', 'possibilidades', 'povo', 'procurei', 'procuro', 'recorrer', 'relacionado', 's', 'saido', 'seguidos', 'seleciona', 'selecionando', 'servem', 'suspensa', 'telas', 'tmb', 'va', 'veiculo', 'vendas', 'youtubers', '35', '45', '80', 'aceitava', 'add', 'altas', 'apaguei', 'aumentando', 'autenticacao', 'bani', 'bota', 'clara', 'comerciais', 'confesso', 'correcao', 'desinstalado', 'direitinho', 'esperado', 'estoque', 'fast', 'filho', 'forte', 'fretes', 'iguais', 'informam', 'irao', 'maravilha', 'mudam', 'negativos', 'ngm', 'normais', 'notifica', 'olho', 'olhos', 'param', 'participantes', 'pego', 'percebo', 'podermos', 'quantos', 'razoavel', 'recebimento', 'reconhece', 'selecionei', 'separar', 'solicito', 'trabalhando', 'trouxe', '16', '2021', '3x', 'abertos', 'abraco', 'apresentar', 'barata', 'cair', 'confirmado', 'conversando', 'diante', 'eficaz', 'esfihas', 'eternamente', 'eternidade', 'filha', 'finaliza', 'forcar', 'joga', 'maxima', 'mostrava', 'mostrou', 'notei', 'pagos', 'pe', 'pensa', 'pizzaria', 'poderem', 'quisesse', 'recomendar', 'rolar', 'sp', 'telemovel', 'toque', 'transparencia', 'variedades', 'vergonhoso', 'virar', '300', 'aconselho', 'ajeitem', 'altura', 'aquilo', 'basicamente', 'compativel', 'configurar', 'deixado', 'desinstalo', 'destaque', 'digitando', 'divulgacao', 'dm', 'efetuei', 'engajamento', 'especialmente', 'excluindo', 'explorar', 'familiares', 'fraco', 'frequentes', 'fria', 'icones', 'imagina', 'inscritos', 'interesses', 'li', 'mb', 'papel', 'pesquisas', 'porfavor', 'potencial', 'prestar', 'ps', 'recomendacoes', 'relatei', 'tirou', 'toca', 'tou', 'upload', 'zoom', 'adiciona', 'aguardei', 'ajude', 'alcance', 'assinante', 'att', 'bio', 'cansei', 'chatos', 'conceito', 'consumir', 'coracao', 'desanima', 'desistalei', 'especie', 'estimado', 'gravo', 'ligando', 'ligo', 'limita', 'memes', 'mente', 'ocupa', 'odeio', 'pay', 'pegam', 'perdemos', 'pesso', 'pouquinho', 'preso', 'qndo', 'recebem', 'reclamam', 'reinicia', 'retirado', 'salvas', 'terceiro', 'ux', 'vdd', 'verde', 'vinculado', 'vinha', 'vzs', '2019', 'amigas', 'autorizacao', 'cancelarem', 'clicando', 'comprovante', 'condominio', 'criacao', 'criado', 'criterio', 'desisto', 'devolvido', 'divertidos', 'encontrado', 'entrada', 'escolhido', 'estafeta', 'estaria', 'fa', 'fazemos', 'forcando', 'frequente', 'frustracao', 'galaxy', 'impede', 'indevidas', 'justica', 'lembro', 'lesado', 'longos', 'madrugada', 'mascara', 'mega', 'notas', 'pagas', 'pegou', 'pessimas', 'rappicreditos', 'reembolsado', 'registrado', 'repetindo', 'responsaveis', 'retorna', 'ridicula', 'rolando', 'roubada', 'rs', 'rsrs', 'saem', 'sexo', 'solucionado', 'termina', 'urgentemente', 'usarei', 'verdadeiro', 'verificado', 'versoes', 'viajar', '0800', '70', 'abusivo', 'assisti', 'atrapalham', 'atualizada', 'avisando', 'base', 'canto', 'causando', 'chegado', 'cobrados', 'confusao', 'definitivamente', 'dinamico', 'droga', 'enganar', 'esforco', 'especifica', 'exceto', 'extorno', 'fleets', 'forca', 'frase', 'ganhando', 'gerando', 'grava', 'ideias', 'importancia', 'informada', 'instalando', 'inteira', 'jamais', 'levando', 'limpo', 'localizar', 'minima', 'moedas', 'mude', 'necessidades', 'negocios', 'nessas', 'nomes', 'obrigar', 'olhei', 'onibus', 'pagou', 'pai', 'paypal', 'ponta', 'popular', 'pudessemos', 'secreto', 'seguem', 'semelhante', 'substituir', 'veem', '\\n', 'abas', 'acabando', 'adicionando', 'apk', 'atenciosos', 'atrasar', 'autorais', 'carrefour', 'cashback', 'categorias', 'chamei', 'claramente', 'classificacao', 'cobertura', 'conforto', 'corrigido', 'dedo', 'desculpas', 'desligar', 'disponibilidade', 'eficiencia', 'entregando', 'esperava', 'estas', 'estraga', 'excluido', 'falava', 'falso', 'gasta', 'houver', 'hr', 'hrs', 'impossibilitando', 'inacreditavel', 'incluindo', 'incorreta', 'indiquei', 'lanchonetes', 'lembrar', 'lindo', 'manutencao', 'maravilhosos', 'marco', 'mequi', 'pass', 'perdem', 'perguntar', 'pesquisei', 'poe', 'providencias', 'rio', 'secao', 'serei', 'solucoes', 'terceiros', 'termo', 'trabalham', 'verifiquem', 'visivel', 'voltam', '099', 'abaixa', 'aceitarem', 'ajudando', 'altera', 'ansiedade', 'atualizem', 'avancar', 'azul', 'baniu', 'bater', 'beleza', 'bloqueando', 'bommas', 'cedo', 'concertar', 'conectando', 'constrangimento', 'costuma', 'curtindo', 'des', 'desativado', 'desbloquear', 'dito', 'economia', 'educado', 'estarem', 'estilo', 'excelencia', 'excepcional', 'falho', 'falsas', 'farmacias', 'finalizou', 'fisica', 'fixar', 'fonte', 'garantir', 'gerente', 'instala', 'ios', 'janela', 'kkkkk', 'massa', 'merecem', 'mexe', 'mora', 'namoro', 'pacotes', 'pausa', 'pensem', 'po', 'preparo', 'primeiras', 'qr', 'queixa', 'rapidos', 'rastreio', 'reembolsar', 'referencia', 'registrar', 'resolvidos', 'surge', 'tiro', 'usuaria', 'utiliza', 'visualizou', 'vivem', '480p', 'aff', 'aleatorio', 'alerta', 'bla', 'capacidade', 'cll', 'cm', 'comecam', 'comecaram', 'compromissos', 'consiga', 'constava', 'criou', 'definir', 'depender', 'desenvolver', 'dez', 'dificilmente', 'disposicao', 'entende', 'entrava', 'erradas', 'escutar', 'esquece', 'esquecer', 'estornaram', 'exclusao', 'exige', 'faixa', 'futuro', 'horror', 'horrores', 'inicialmente', 'jantar', 'kwai', 'limitacao', 'melhorada', 'mundial', 'net', 'oferecendo', 'parados', 'parecer', 'pausar', 'pegando', 'peso', 'planos', 'player', 'postados', 'prejudicando', 'prints', 'prioridade', 'prontas', 'pura', 'quiserem', 'recomenda', 'recusou', 'repetir', 'rolagem', 'roubado', 'ruas', 'seguidas', 'solicitacoes', 'travam', 'tt', 'valendo', 'variados', 'virus', 'abrem', 'absurdos', 'aceitos', 'aconteca', 'administradores', 'afins', 'ajustes', 'alimentos', 'alteracoes', 'ambas', 'analisar', 'atitude', 'atividades', 'atoa', 'atrasada', 'auto', 'bairros', 'banidas', 'botei', 'burocratico', 'chave', 'compre', 'confirmei', 'cumprir', 'decidir', 'deixe', 'desativei', 'desatualizado', 'determinados', 'dura', 'enfrentando', 'engracados', 'esquerda', 'exibicao', 'fechou', 'ficado', 'gifs', 'gostamos', 'horroroso', 'identidade', 'indica', 'investir', 'latas', 'levei', 'ligaram', 'limitados', 'limitar', 'mac', 'marcas', 'marido', 'mi', 'milhoes', 'ora', 'parando', 'piada', 'poderiamos', 'portaria', 'pressa', 'qualidades', 'ramo', 'rapaz', 'recebemos', 'reembolsaram', 'refeicoes', 'revejam', 'rotas', 'saida', 'satisfatoria', 'sensacao', 'serao', 'teclado', 'tedio', 'temporariamente', 'tentamos', 'teu', 'tiram', 'toma', 'transito', 'trocando', 'unicos', 'usamos', 'utilidade', 'valer', 'viavel', 'voltarei', 'agil', 'arrepender', 'banimento', 'banindo', 'baniram', 'bicicleta', 'black', 'boleto', 'boost', 'bugada', 'comuns', 'controlar', 'downloads', 'efetuado', 'encerrar', 'enganado', 'esperanca', 'estragando', 'expectativa', 'falsa', 'fechamento', 'fecho', 'feira', 'figurinha', 'foryou', 'franquia', 'gmail', 'inicia', 'intuito', 'inumeros', 'inviavel', 'le', 'libera', 'membros', 'ocultar', 'oportunidades', 'padroes', 'parceria', 'paulo', 'percurso', 'permanece', 'popup', 'possamos', 'possuo', 'pras', 'processar', 'programacao', 'queijo', 'recompensa', 'reconhecimento', 'relato', 'ressalva', 'saia', 'separacao', 'stress', 'tablet', 'temperatura', 'tentaram', 'trans', 'transferir', 'utilizam', 'velho', 'ajustar', 'apagado', 'arrastar', 'aspecto', 'assiste', 'ativado', 'avaliando', 'baguncado', 'basicas', 'bloqueiam', 'bonita', 'card', 'carinho', 'chegue', 'cmg', 'comprem', 'consumidores', 'contactar', 'copia', 'cortar', 'crescimento', 'dancinhas', 'desapareceu', 'desconfortavel', 'descrever', 'desenhos', 'desktop', 'embalagem', 'enganosas', 'enviada', 'escrevendo', 'estipulado', 'eventos', 'exigir', 'favorita', 'ficasse', 'filhos', 'gasolina', 'gratidao', 'historias', 'incorreto', 'juntos', 'ligada', 'line', 'logica', 'manusear', 'maravilhosas', 'mecanismo', 'melhoras', 'mostrado', 'news', 'obrigados', 'ocasioes', 'ouvi', 'ouvindo', 'parei', 'permitindo', 'pop', 'portao', 'propoe', 'proprias', 'recomendado', 'restricoes', 'satisfatorio', 'segui', 'selecionados', 'sentidos', 'sites', 'storie', 'transparente', 'transtornos', 'travamento', 'unidades', 'verdadeira', 'violacao', 'vizinho', 'voucher', '3000', 'acabamos', 'adicional', 'ajudado', 'ambiente', 'aparencia', 'aprendendo', 'apresentou', 'baixando', 'baixarem', 'big', 'blz', 'cadastra', 'cansada', 'chamo', 'chegava', 'clique', 'coisinhas', 'colocamos', 'compreensao', 'condicao', 'daquele', 'demoraram', 'devolvem', 'digito', 'distantes', 'distribuidoras', 'encontros', 'enviados', 'excluiram', 'existia', 'explicacoes', 'facilitando', 'fone', 'forem', 'gelo', 'gnt', 'gostam', 'gostou', 'havendo', 'impressionante', 'incomodando', 'indignada', 'instalem', 'inteligente', 'lenta', 'lesada', 'levam', 'lidar', 'ligam', 'mecher', 'metros', 'modalidade', 'morada', 'orientacao', 'otimizacao', 'patinete', 'platinum', 'poluido', 'precise', 'prometido', 'publica', 'puro', 'quentes', 'raro', 'recomendacao', 'recompensas', 'resolvessem', 'sabado', 'seriam', 'seriamente', 'serios', 'tomei', 'tradutor', 'violei', 'visibilidade', 'volume', 'wpp', 'abracos', 'abria', 'acabaram', 'acessiveis', 'acontecia', 'adultos', 'alimento', 'ando', 'antecedencia', 'aplica', 'apresentacao', 'aproximadamente', 'areas', 'atencioso', 'atendia', 'atrasando', 'avaliei', 'banem', 'banner', 'bugou', 'cell', 'cllr', 'conclui', 'consigam', 'correr', 'costume', 'danca', 'decepcionei', 'deletar', 'desenvolvido', 'dicas', 'diversao', 'economizar', 'elegivel', 'elo', 'elogios', 'encontrou', 'escola', 'escolhas', 'escura', 'estavel', 'excluidos', 'favoritar', 'funcione', 'graficos', 'gravacao', 'identificacao', 'ineficiente', 'infinito', 'integracao', 'justos', 'limitada', 'limpa', 'logistica', 'mensal', 'mercadoria', 'mobile', 'moca', 'mts', 'namorada', 'negativas', 'olhe', 'paises', 'percebe', 'perigoso', 'playstore', 'porq', 'precisaria', 'preferido', 'profissionalismo', 'promo', 'realizada', 'registro', 'relacionamentos', 'reportei', 'senso', 'solicitando', 'suco', 'tais', 'tentam', 'tentava', 'titulo', 'tomara', 'transmissao', 'trends', 'valem', 'valida', 'vantajoso', 'vendem', 'vidas', '1500', '17', '2018', '400', 'acabado', 'adulto', 'agendar', 'ajeitar', 'apartamento', 'apresentam', 'arrependo', 'atento', 'ativei', 'atualizam', 'bola', 'bolso', 'cancelo', 'centavos', 'chatas', 'code', 'comparar', 'confirma', 'confortavel', 'conhecido', 'conhecidos', 'credibilidade', 'cumprem', 'dancando', 'decente', 'decisao', 'desculpe', 'deslocamento', 'desonesto', 'dezenas', 'diario', 'diminui', 'disponibilizam', 'diversidade', 'divirto', 'embaixo', 'encher', 'entendimento', 'expirado', 'faceis', 'fase', 'foco', 'fontes', 'frustrada', 'ganham', 'gorjetas', 'haviam', 'hein', 'ignorar', 'imensa', 'inconveniente', 'indignacao', 'inesperado', 'inexistente', 'insiste', 'interativo', 'inutilizavel', 'irritada', 'irritantes', 'kk', 'lata', 'letra', 'localidade', 'longas', 'menus', 'nojo', 'olhada', 'opinioes', 'optei', 'paz', 'perdida', 'prejudicado', 'preparar', 'primeiramente', 'pula', 'qd', 'quebra', 'ram', 'rapidinho', 'reacoes', 'recebia', 'receio', 'recibo', 'resolvida', 'ressarcimento', 'roubar', 'semelhantes', 'sexual', 'silenciar', 'sorvete', 'tds', 'telefones', 'toxica', 'toxicas', 'transferencia', 'validos', 'vemos', 'verem', 'vermelho', 'xiaomi', '2deg', '5000', '600', 'aceitaram', 'acionar', 'adorava', 'aleatorios', 'animais', 'anunciado', 'apagando', 'apareca', 'apena', 'aperta', 'atividade', 'atrasados', 'atrasam', 'atualizaram', 'auxilio', 'avalio', 'bandeiras', 'baratos', 'bastasse', 'brasileiro', 'buscando', 'certamente', 'chrome', 'colocassem', 'colocava', 'compartilho', 'concluida', 'congela', 'constrangedor', 'crime', 'curta', 'denunciei', 'desfazer', 'desnecessaria', 'devendo', 'devolveu', 'direta', 'dms', 'donos', 'duracao', 'escondido', 'estejam', 'estive', 'estudos', 'etapa', 'expor', 'extrema', 'feia', 'frustante', 'funcionario', 'honesto', 'idiota', 'impedindo', 'incrivelmente', 'indicando', 'ingredientes', 'interna', 'jogando', 'lamento', 'liberado', 'limites', 'lindas', 'melhorarem', 'missoes', 'monetizacao', 'necessarias', 'noticia', 'notificado', 'ocorrem', 'orrivel', 'pao', 'parecendo', 'parede', 'populacao', 'positiva', 'precisao', 'preencher', 'prestam', 'punicao', 'quesitos', 'rascunhos', 'reagir', 'recusado', 'relacionados', 'relatando', 'relativamente', 'removido', 'resolvesse', 'saiba', 'sexta', 'substituicao', 'sul', 'superlikes', 'tarefas', 'tecnologia', 'tentem', 'tentou', 'ti', 'tirado', 'trouxa', 'utilizalo', 'viciante', 'abriu', 'acompanho', 'acreditar', 'alterado', 'ampliar', 'ap', 'apareceram', 'aprendi', 'arrume', 'atendendo', 'atrativo', 'backup', 'bandeira', 'bloqueados', 'brincadeira', 'capaz', 'carater', 'censura', 'chances', 'chuva', 'combustivel', 'comenta', 'comprador', 'comprava', 'confirmou', 'considerando', 'consome', 'contagem', 'contestar', 'continuou', 'corpo', 'curso', 'curtiram', 'deficiencia', 'desaparecem', 'desconta', 'deslizar', 'desrespeitoso', 'determinada', 'disponibilizado', 'escrevi', 'escrevo', 'especificos', 'esquecendo', 'estragou', 'evolucao', 'exelente', 'expressar', 'faltava', 'felizmente', 'fisico', 'fixo', 'fraca', 'gravando', 'iam', 'idiomas', 'inadmissivel', 'indevidamente', 'informei', 'inseguranca', 'instante', 'janeiro', 'lados', 'lancar', 'luz', 'maquininha', 'medidas', 'meta', 'movel', 'netflix', 'notificar', 'ocupar', 'pagto', 'passos', 'pau', 'personalizar', 'pgto', 'placa', 'pornografia', 'porto', 'possibilita', 'preguica', 'preparando', 'principais', 'providencia', 'quao', 'queriam', 'quinta', 'raio', 'reclamo', 'reembolsam', 'retirando', 'rj', 'seguidor', 'servir', 'short', 'sombra', 'soube', 'tratar', 'trazendo', 'usada', 'usarem', 'usufruir', 'vei', 'vende', 'vendedores', 'vincular', 'virando', '144p', '150', 'abril', 'aceitavel', 'achou', 'adequado', 'adm', 'adquirir', 'ae', 'ajuste', 'alternativas', 'aparente', 'artistas', 'assistido', 'atenderam', 'ativos', 'aumentaram', 'ausencia', 'baixou', 'bando', 'banidos', 'beber', 'besta', 'bugar', 'cabe', 'caixinha', 'cancele', 'catalogo', 'chromecast', 'conselho', 'consultar', 'consumindo', 'correndo', 'criarem', 'dada', 'dancar', 'dancas', 'defesa', 'desconhecido', 'descontar', 'desinstala', 'desnecessarios', 'desorganizado', 'devolve', 'dificeis', 'direcionado', 'dormir', 'entraram', 'erram', 'errar', 'escolhem', 'estrelinhas', 'evoluir', 'expirou', 'fale', 'faria', 'fornecer', 'funcionado', 'guardar', 'implementar', 'irma', 'janta', 'lingua', 'listas', 'logado', 'marcando', 'mexendo', 'motorola', 'music', 'necessita', 'ocupando', 'offline', 'on', 'ouvido', 'pagava', 'pendencia', 'perguntam', 'prazos', 'procedimentos', 'producao', 'recusa', 'refiz', 'relatos', 'repetitivos', 'respeita', 'ressarcido', 'retira', 'rola', 'sabores', 'seguido', 'seis', 'selecionada', 'setor', 'similar', 'simpaticos', 'spotify', 'sumindo', 'sumir', 'superlike', 'testes', 'usados', 'verdinho', 'vo', 'voltasse', '1990', '1a', 'abertas', 'acaso', 'aceitacao', 'acompanha', 'acompanhando', 'acostumado', 'adicionais', 'administracao', 'adorando', 'agrada', 'agradeceria', 'alegre', 'animados', 'apagou', 'aparecerem', 'arruma', 'atalho', 'atuais', 'atualidade', 'avisado', 'bane', 'basica', 'batatas', 'bjs', 'buscas', 'cancelasse', 'colar', 'compativeis', 'compramos', 'comprometimento', 'contando', 'corre', 'corta', 'criem', 'dagua', 'desagradaveis', 'determinadas', 'direcao', 'edits', 'elevado', 'esperamos', 'estetica', 'estressar', 'exibir', 'exito', 'famosas', 'fas', 'ficara', 'ficarei', 'fluidez', 'frases', 'frustrado', 'ganhou', 'garanto', 'gelado', 'gestao', 'gorgeta', 'grana', 'hetero', 'imagino', 'impedir', 'impossibilitado', 'incentivo', 'incompetencia', 'inscrito', 'instrucoes', 'irmao', 'localizador', 'mandado', 'manuseio', 'marcou', 'medida', 'merce', 'moda', 'namorado', 'nois', 'note', 'ocorrencia', 'opcional', 'otimomas', 'pagam', 'parecia', 'particular', 'pensam', 'pense', 'perguntei', 'pesa', 'pleno', 'possuir', 'preconceito', 'preferencias', 'prejudicar', 'presentes', 'processamento', 'promover', 'prontamente', 'protecao', 'proteger', 'quarta', 'reavaliar', 'recorrentes', 'reduzir', 'reiniciando', 'renda', 'repete', 'repetidas', 'respondendo', 'restrita', 'simpatico', 'software', 'stores', 'surgiu', 'surpreendeu', 'tentado', 'terao', 'teriam', 'torno', 'trabalhos', 'tratam', 'tremenda', 'turbo', 'unicas', 'up', 'violado', 'visa', 'youtuber', 'abuso', 'aceitei', 'acessa', 'agilizar', 'alegria', 'almocar', 'amigavel', 'apertei', 'atenciosamente', 'atentos', 'atrapalhar', 'atualizados', 'atualizava', 'avisam', 'beijo', 'bizarro', 'bolinha', 'boto', 'cansado', 'capital', 'caracteristicas', 'citar', 'claras', 'club', 'cobre', 'coca', 'colaboradores', 'come', 'compensacao', 'comprou', 'confiaveis', 'conhecia', 'constou', 'contexto', 'cornershop', 'customizacao', 'damos', 'decorrer', 'deficiente', 'desconecta', 'deslike', 'deslocar', 'devemos', 'diarias', 'digitais', 'direita', 'editado', 'eliminar', 'emoji', 'enche', 'enganoso', 'entendendo', 'erra', 'especiais', 'especificas', 'esposo', 'esquina', 'estara', 'estragar', 'estranha', 'estrategia', 'excessiva', 'execucao', 'explica', 'fama', 'famosa', 'farei', 'fizesse', 'fizessem', 'flopa', 'geladinha', 'gerenciador', 'gerou', 'gigante', 'gostoso', 'hd', 'ignoram', 'iniciativa', 'instalacao', 'interessado', 'justa', 'lancado', 'limitadas', 'lo', 'maio', 'malte', 'marcada', 'metodos', 'misturado', 'mostrei', 'motoqueiros', 'mudarem', 'novidade', 'oferecidos', 'off', 'operacao', 'palavrao', 'par', 'passe', 'perfeicao', 'perfeitos', 'poblema', 'podera', 'porcentagem', 'preferia', 'principio', 'privadas', 'prontos', 'quantidades', 'qui', 'reacao', 'realizadas', 'recomendados', 'redefinir', 'refem', 'relacionar', 'requisitos', 'responsabiliza', 'retiraram', 'revisar', 'roubou', 'significa', 'sobe', 'sobremesa', 'subway', 'suma', 'suposto', 'tarifa', 'tecnicos', 'tel', 'trafego', 'tranquilamente', 'user', 'usou', 'variadas', 'vazio', 'voltava', '23', '3h', 'aceitem', 'acessando', 'adequadamente', 'adicionados', 'adicionassem', 'adicione', 'adoraria', 'afim', 'agradou', 'aleatoria', 'apago', 'apareciam', 'aplicados', 'aq', 'atrair', 'azar', 'bacanas', 'bar', 'baratas', 'belo', 'biquini', 'bora', 'brasileiros', 'brilho', 'bugadas', 'cafe', 'cesta', 'cinza', 'clareza', 'classificar', 'clean', 'clicava', 'comando', 'combinado', 'compreensivel', 'confirmando', 'conseguirem', 'conserte', 'considerado', 'considerar', 'constar', 'contacto', 'conter', 'contratar', 'corresponde', 'corrigirem', 'costumava', 'criterios', 'criticar', 'curitiba', 'darem', 'decepcionou', 'deixava', 'denunciando', 'descricoes', 'descrito', 'desejado', 'devolvam', 'direcionar', 'diretas', 'discord', 'disto', 'dividir', 'edito', 'editor', 'encerra', 'encerrado', 'entregarem', 'escolheu', 'escolhida', 'escrita', 'esperam', 'estados', 'estrutura', 'exemplos', 'existencia', 'existente', 'expirada', 'facilitou', 'faltantes', 'faltar', 'fechada', 'fiel', 'finalizada', 'finalizando', 'fizemos', 'fizerem', 'fogo', 'ganhe', 'garotas', 'golpistas', 'gostado', 'hackers', 'home', 'idades', 'identifica', 'imenso', 'inaceitavel', 'inacessivel', 'inapropriados', 'indignado', 'inseguro', 'inseri', 'interacoes', 'interessam', 'irritado', 'jesus', 'juro', 'k', 'lei', 'lembra', 'lerdo', 'limitando', 'livros', 'luta', 'marquei', 'melhoraria', 'melhorasse', 'mn', 'modificar', 'moral', 'mta', 'mtas', 'navegando', 'oposto', 'organizada', 'paguem', 'percam', 'pergunto', 'permissoes', 'permitiu', 'pesados', 'pobre', 'podre', 'populares', 'positivos', 'pouquissimas', 'preocupacao', 'privada', 'privados', 'provar', 'r20', 'raros', 'realiza', 'realizou', 'receberam', 'refil', 'reinicio', 'removi', 'resenhas', 'respondam', 'retirou', 'salvou', 'sanduiches', 'separado', 'sincronizacao', 'subindo', 'subiu', 't', 'termino', 'thru', 'tkk', 'tratamento', 'trazem', 'upgrade', 'valia', 'vendendo', 'vinho', '2500', '4k', 'abaixei', 'absurdas', 'acumular', 'aderir', 'ajudaram', 'album', 'alegam', 'apagada', 'aplicacoes', 'aplicam', 'arrependi', 'assitir', 'avaliado', 'baita', 'bolo', 'boomerang', 'boy', 'cancelamos', 'clipes', 'comendo', 'comentando', 'compartilha', 'comprovar', 'comunidades', 'condiz', 'conecta', 'conectada', 'confunde', 'conhecendo', 'consequentemente', 'construtiva', 'consulta', 'contado', 'continuei', 'convite', 'corretos', 'creditado', 'crise', 'curtas', 'datas', 'deixaria', 'depressao', 'desejada', 'desenho', 'desistalar', 'deslizando', 'dificultar', 'diria', 'dislike', 'doido', 'enormes', 'enquetes', 'entendem', 'entrado', 'entramos', 'envolvidos', 'esclarecer', 'escreve', 'esfiha', 'especificamente', 'esquecem', 'essencia', 'estalar', 'estavamos', 'estornam', 'estudar', 'excecao', 'experimentei', 'fantastica', 'fb', 'fins', 'fiscalizacao', 'flash', 'focar', 'fujam', 'futebol', 'ganancia', 'gastando', 'go', 'gratuitos', 'habilitado', 'haha', 'hashtags', 'idiotas', 'ido', 'imediata', 'impecavel', 'improprio', 'indispensavel', 'inteligencia', 'interno', 'irrelevantes', 'lancamento', 'lembrancas', 'levado', 'lida', 'limitacoes', 'livro', 'mantendo', 'marcados', 'margem', 'mencionar', 'mistura', 'mo', 'moderno', 'montar', 'mudado', 'musk', 'muuuito', 'naquela', 'nudez', 'ocasiao', 'ordenar', 'pararam', 'pare', 'parecidos', 'parentes', 'participo', 'parto', 'patinetes', 'perguntou', 'petiscos', 'politicos', 'poluicao', 'porte', 'postou', 'programar', 'pronta', 'proporciona', 'prova', 'questionar', 'receberia', 'recomecar', 'recomendando', 'reembolsada', 'removeram', 'reparei', 'resolvendo', 'respondida', 'retirei', 'sacar', 'salvei', 'saudades', 'serviu', 'sistemas', 'smart', 'sociedade', 'sonho', 'sons', 'souber', 'sugere', 'supera', 'superou', 'supostamente', 'sushi', 'tecnica', 'tendencia', 'terminei', 'tl', 'tomando', 'tornado', 'tradicional', 'transacao', 'travada', 'tristeza', 'trocas', 'vazia', 'veiculos', 'verifique', 'viciada', 'vinte', 'viver', '1080', '10min', '19', '30min', '5x', 'abusivos', 'acai', 'acessei', 'acesso20', 'acessos', 'acidente', 'acusa', 'adicao', 'adicionarem', 'adiciono', 'adivinha', 'ads', 'aleatorias', 'alega', 'alterei', 'ama', 'ambev', 'anunciar', 'aplicando', 'apliquei', 'appe', 'aprovacao', 'arquivados', 'arrumando', 'assina', 'badoo', 'ban', 'bancos', 'bh', 'biografia', 'boca', 'bugue', 'carregava', 'centavo', 'chinelo', 'cobrarem', 'comi', 'compara', 'complemento', 'comportamento', 'concluiu', 'concorda', 'confusas', 'conosco', 'conseguido', 'conseguiria', 'constam', 'constando', 'continuava', 'converso', 'convidar', 'criada', 'deparei', 'desativando', 'desconheco', 'descontam', 'descontou', 'desista', 'desliguei', 'deslikes', 'devolverem', 'distancias', 'distrair', 'edita', 'educada', 'ei', 'elogio', 'emergencia', 'encontrando', 'enganada', 'enrolando', 'entendeu', 'estimativa', 'estranhas', 'exata', 'exibe', 'expirar', 'explicito', 'exposicao', 'extras', 'extrato', 'faltante', 'fastfood', 'fazermos', 'fechei', 'finalidade', 'fire', 'fixa', 'flopando', 'fluxo', 'fomos', 'fornecido', 'furadas', 'garantia', 'gerenciar', 'gif', 'gratuitamente', 'h', 'horrorosa', 'humor', 'ilusao', 'inapropriado', 'inclui', 'incluido', 'incomodam', 'induz', 'ineficaz', 'infinita', 'internacional', 'jogado', 'ladrao', 'leem', 'lembrando', 'liberou', 'linda', 'longa', 'loop', 'looping', 'mail', 'maneiras', 'maus', 'melhoram', 'mobilidade', 'monitoramento', 'neh', 'nervoso', 'objeto', 'obrigacao', 'observei', 'ocorra', 'ofereceram', 'oh', 'orientacoes', 'pagaria', 'passamos', 'passava', 'permanecer', 'permitido', 'pesadas', 'poluida', 'postadas', 'postal', 'postamos', 'preferem', 'premios', 'preocupar', 'pretende', 'produzir', 'programado', 'programas', 'proporcao', 'proporcionar', 'publicidades', 'qm', 'quantia', 'queda', 'rascunho', 'recarrega', 'reconhecer', 'reembolsos', 'regioes', 'registra', 'registrou', 'relevante', 'repensar', 'repito', 'resgate', 'respondido', 'ressaltar', 'ressarcida', 'restantes', 'retirem', 'retornaram', 'reverter', 'rival', 'rotina', 'roubaram', 'roupa', 'rt', 'ruin', 'seg', 'seguintes', 'similares', 'skol', 'sofre', 'sugerido', 'superar', 'tamanha', 'tele', 'telegran', 'tempinho', 'tratando', 'trocou', 'tutoriais', 'utilizadores', 'utilizava', 'utilizem', 'versa', 'vier', 'vip', 'viram', '05', '26', '29', '3deg', 'aceitado', 'acionei', 'adequada', 'adicionada', 'agem', 'agenda', 'agir', 'aguentando', 'albuns', 'alertar', 'alterando', 'amanha', 'andam', 'animacao', 'animes', 'anunciam', 'aparecido', 'apartir', 'aplicada', 'apple', 'appmas', 'aprendizado', 'aproveitando', 'atingir', 'atingiu', 'ativada', 'atualizarem', 'aumentem', 'autorizado', 'avatar', 'b', 'baixados', 'bancaria', 'bebe', 'beta', 'bobo', 'buscam', 'cadastrada', 'caixas', 'cansa', 'carona', 'causou', 'chatice', 'claros', 'cod', 'coisinha', 'cola', 'colega', 'colegas', 'colocada', 'colocasse', 'comento', 'comercio', 'comercios', 'comparando', 'complexo', 'complica', 'configurei', 'contador', 'conveniente', 'cultura', 'dating', 'decepcionando', 'decide', 'deixasse', 'delay', 'delicia', 'democratico', 'derrepente', 'desabilitar', 'descente', 'desgastante', 'desgraca', 'desistencia', 'desliga', 'detestei', 'dificultam', 'digitacao', 'divida', 'elegante', 'eletronico', 'elon', 'encaminhar', 'encomoda', 'encontram', 'encontramos', 'entrem', 'eo', 'esclarecimento', 'escolhemos', 'esgotado', 'espere', 'esqueca', 'esqueceu', 'esquema', 'esquisito', 'estafetas', 'estarei', 'estivessem', 'exagero', 'excluem', 'excluiu', 'exclusivamente', 'exclusivos', 'explicando', 'fasso', 'feedbacks', 'filtra', 'fluido', 'formulario', 'fracos', 'fraudes', 'friday', 'frios', 'ft', 'fulano', 'funcionasse', 'gama', 'ganhamos', 'gentis', 'gerado', 'gerencia', 'grade', 'gravado', 'habilitar', 'hackeada', 'hackeado', 'hamburgueres', 'heineken', 'help', 'impossiveis', 'imprevisto', 'incentivar', 'inconvenientes', 'indevido', 'infeliz', 'inferno', 'infinidade', 'informados', 'injusta', 'injustamente', 'instale', 'inventaram', 'irritando', 'itau', 'j7', 'juntamente', 'kkkkkkk', 'ladroes', 'lance', 'lancou', 'leite', 'levaram', 'liberam', 'linguagem', 'linguas', 'mandava', 'mantenho', 'marcacao', 'maria', 'melhoraram', 'melhorassem', 'menina', 'menssagem', 'minimamente', 'minimizar', 'mudasse', 'muuuuito', 'navegabilidade', 'neles', 'nestes', 'normas', 'notebook', 'nuas', 'oficial', 'ouve', 'pagado', 'parabenizar', 'pareca', 'pareceu', 'paro', 'pioram', 'piscando', 'plmds', 'podesse', 'ponho', 'positivas', 'possibilitar', 'praticas', 'prazer', 'prefere', 'prejudicam', 'presa', 'prestando', 'probleminhas', 'programadores', 'projeto', 'prometem', 'prosseguir', 'proximidade', 'prq', 'qualificacao', 'quisermos', 'radio', 'reativar', 'recado', 'recarga', 'recarregar', 'recusam', 'relatou', 'relevantes', 'repostar', 'reproduz', 'reproduzido', 'reproduzindo', 'restaurar', 'restringir', 'ridiculos', 'rir', 'robos', 'roubando', 'salgado', 'saude', 'seculo', 'senhores', 'simultaneamente', 'sincera', 'sofrer', 'sofri', 'solicitamos', 'soubesse', 'statusstories', 'suficientes', 'sugerindo', 'tarifas', 'taxis', 'televisao', 'terra', 'tia', 'tirarem', 'todavia', 'tom', 'topicos', 'tornaram', 'trabalhadores', 'travadas', 'treinamento', 'trocaram', 'trouxeram', 'tua', 'turbinar', 'tutorial', 'utilizados', 'vencimento', 'verdadeiros', 'verificando', 'vice', 'vicio', 'videose', 'views', 'violar', 'virem', 'virtuais', 'vistos', 'visualiza', 'visualmente', 'voltas', '1k', '2016', '2017', '22', '700', 'abaixem', 'abandonar', 'adicionaram', 'admirador', 'afirmar', 'agendada', 'agendamento', 'alertas', 'alma', 'altero', 'amplo', 'andando', 'animadas', 'anime', 'antecipadamente', 'apresentados', 'aprova', 'aproveitem', 'armazenar', 'arrumassem', 'assidua', 'atalhos', 'atitudes', 'atrasadas', 'av', 'avisou', 'bank', 'beijos', 'bommais', 'bomporem', 'brasileira', 'briga', 'bugados', 'caem', 'caia', 'campanha', 'campos', 'cancelava', 'centenas', 'chamados', 'circulo', 'clipe', 'cobradas', 'compensando', 'competir', 'complicada', 'comprados', 'confiabilidade', 'configurado', 'consciencia', 'consertarem', 'consideravel', 'conversei', 'cortada', 'cortando', 'covid', 'creditodebito', 'crescendo', 'criatividade', 'criptografia', 'cuidados', 'cursos', 'curtido', 'daqueles', 'debitar', 'decepciona', 'decidem', 'decisoes', 'defender', 'demorada', 'depositos', 'desanimador', 'desconhecidos', 'descubro', 'desfrutar', 'desistalando', 'desiste', 'desligado', 'destas', 'destinatario', 'desvantagem', 'devida', 'diferencas', 'digita', 'diminuindo', 'discurso', 'dislikes', 'divertida', 'duplicado', 'efetuada', 'eficientes', 'encontrava', 'enfrentar', 'engana', 'enrolacao', 'entregadora', 'enviamos', 'enviarem', 'esforcam', 'esperou', 'espetacular', 'esquecam', 'estabilidade', 'esteve', 'estudo', 'exclusivas', 'expandir', 'explicado', 'facto', 'falado', 'fator', 'favoritas', 'fevereiro', 'filas', 'fluida', 'formatar', 'formatei', 'francamente', 'frango', 'frutas', 'fundamental', 'furada', 'garante', 'garrafa', 'golpista', 'governo', 'gratuitas', 'hamburgueria', 'hospital', 'humilde', 'ignorado', 'igualmente', 'imaginando', 'imaginar', 'importam', 'impossibilidade', 'impossibilita', 'inclusao', 'incompletos', 'indicacoes', 'individual', 'infantil', 'informativo', 'injustica', 'insisti', 'interior', 'invasao', 'irritar', 'juntar', 'lanca', 'leiam', 'lidas', 'lixos', 'logico', 'lotado', 'louca', 'lucrar', 'maps', 'maquiagem', 'mediante', 'meninas', 'migrando', 'misericordia', 'missao', 'mover', 'movimento', 'necessaria', 'necessarios', 'negar', 'negativamente', 'obrigam', 'observar', 'ocupado', 'orientar', 'originais', 'originalidade', 'ouro', 'parcerias', 'parecida', 'pasmem', 'pedirei', 'penalizado', 'perdidos', 'perdir', 'perfeitas', 'permanentemente', 'permita', 'perna', 'personalizado', 'personalizavel', 'pes', 'pesquisando', 'poco', 'pontinhos', 'pontuar', 'popularidade', 'portugal', 'possivelmente', 'pow', 'pqp', 'preferi', 'preocupado', 'presidente', 'proposital', 'propositalmente', 'publicado', 'publicos', 'push', 'qe', 'qq', 'quebrou', 'quiseram', 'r1000', 'razoes', 'realizando', 'reaver', 'receitas', 'recomendaria', 'recusar', 'recusei', 'redireciona', 'refri', 'refrigerantes', 'reinstalando', 'remedio', 'repetidos', 'respeitam', 'restrito', 'retiram', 'retiro', 'retornou', 'revisao', 'revoltante', 'sacrificio', 'salgados', 'saudavel', 'segmento', 'seguimento', 'senhas', 'senhor', 'senhora', 'separadas', 'separados', 'servidores', 'sincronizar', 'sla', 'sofrivel', 'solicitados', 'solicitou', 'streaming', 'sujo', 'sumido', 'surgir', 'surpreendido', 'tarefa', 'tbem', 'terca', 'testando', 'tivessemos', 'tocando', 'tornam', 'tratava', 'triplo', 'trocados', 'ue', 'ultilizar', 'usaria', 'vencido', 'venham', 'verificada', 'verificados', 'vermelha', 'vermos', 'veses', 'vidio', 'vinculada', 'visiveis', 'visualizado', 'viva', 'watch', '2012', '2014', '21', '27', '31', '48', 'abertura', 'abusiva', 'acabe', 'acharem', 'actualizacao', 'adivinhar', 'adora', 'adquiri', 'agendado', 'agiliza', 'agrado', 'aguarde', 'alegaram', 'antecipado', 'apagam', 'apaixonada', 'aprende', 'aprimorar', 'artificial', 'artista', 'assinantes', 'assistia', 'atendidos', 'atrapalhou', 'atualize', 'autorizar', 'autorizei', 'auxiliar', 'avaliados', 'avisaram', 'baixos', 'banda', 'batem', 'batepapo', 'biblioteca', 'block', 'bloqueios', 'bomba', 'brincando', 'brinquedo', 'bye', 'cabelo', 'caido', 'cardapios', 'carrossel', 'casais', 'casal', 'casas', 'casual', 'causar', 'chegara', 'chocolate', 'churrasco', 'ciente', 'clonado', 'co', 'comandos', 'comentou', 'compartilhados', 'competencia', 'compram', 'concorrer', 'condutor', 'confort', 'confusos', 'conhecem', 'conhecemos', 'conhecermos', 'consumi', 'contatei', 'continuidade', 'conto', 'convites', 'corrigem', 'costumam', 'criam', 'criaram', 'criativo', 'crio', 'cumprido', 'cupon', 'curioso', 'curtidos', 'dedicacao', 'descontente', 'desculpem', 'designer', 'destinos', 'devidamente', 'devs', 'dezembro', 'diamante', 'digitei', 'disponibilizada', 'disponibilizarem', 'dispostos', 'divergencia', 'doi', 'dores', 'duplo', 'embacada', 'embalado', 'enganosos', 'enquete', 'entregado', 'errando', 'es', 'escolhia', 'esconder', 'escutando', 'especificar', 'espectadores', 'espertos', 'estabelecido', 'estiverem', 'estorna', 'estornada', 'estragada', 'etaria', 'evento', 'evitando', 'exibido', 'exigem', 'exorbitantes', 'facilidades', 'felizes', 'fi', 'forcado', 'fornecem', 'frita', 'funcionaram', 'funcionaria', 'funk', 'futuramente', 'futuras', 'fzr', 'gacha', 'gays', 'genial', 'gerenciamento', 'global', 'gota', 'gravei', 'hashtag', 'ilimitadas', 'ilimitado', 'imprevistos', 'incomodado', 'infinitas', 'iniciou', 'insistindo', 'instagran', 'instantanea', 'interrompe', 'japones', 'joao', 'jogam', 'jovens', 'junho', 'juntas', 'ladeira', 'lazer', 'leu', 'lhes', 'liberados', 'lido', 'limpando', 'linhas', 'loguei', 'mandarem', 'mandem', 'mascaras', 'melhoradas', 'mensalidade', 'mexi', 'mini', 'minimos', 'monitorar', 'morre', 'muinto', 'muitissimo', 'nasci', 'niveis', 'objetivos', 'obrigatoriedade', 'obtenho', 'oculta', 'orkut', 'padaria', 'parceiras', 'participante', 'passem', 'pecam', 'pecando', 'performance', 'pico', 'platina', 'plena', 'posicionamento', 'postava', 'pouquissimos', 'precario', 'prejudicada', 'premio', 'preparacao', 'prestacao', 'prestadores', 'previo', 'problematico', 'procuram', 'proibido', 'proposto', 'proprietario', 'proximidades', 'puxar', 'qto', 'quadras', 'quebrar', 'queiram', 'quentinha', 'questionei', 'reavaliando', 'receberem', 'recebida', 'recusando', 'reias', 'relacionada', 'relatado', 'relatorio', 'relatorios', 'relogio', 'reparar', 'repetem', 'repetitivo', 'repleto', 'reserva', 'resolvia', 'responderem', 'respondi', 'rica', 'rico', 'ridiculas', 'rodam', 'saibam', 'sairem', 'saque', 'seculos', 'sensivel', 'serias', 'shoppers', 'silenciado', 'sincero', 'sob', 'solicitada', 'sugeridas', 'sujos', 'surgem', 'suspeito', 'suspensao', 'tags', 'tecla', 'temporario', 'tenhamos', 'teoria', 'terror', 'the', 'tinhamos', 'tio', 'tomam', 'trabalhoso', 'transicao', 'tremendo', 'tuites', 'usadas', 'utilizador', 'vazias', 'vegetariano', 'velha', 'verifica', 'vidios', 'viesse', 'visando', 'vizinha', 'vizinhos', 'vlw', 'voltaram', 'wue', '   ', '199', '1h30', '20min', '24hrs', '34', '40min', '55', '85', '99pay', 'abusivas', 'aceder', 'acelerar', 'achamos', 'acordei', 'adaptar', 'adega', 'adiantado', 'adms', 'agradam', 'agradece', 'agradecemos', 'aleatoriamente', 'alegou', 'algoritmos', 'algums', 'amar', 'animacoes', 'anucios', 'apagadas', 'apontar', 'aprovar', 'arranjar', 'arrumaram', 'arrumei', 'assinado', 'assistiu', 'atrelado', 'autoriza', 'avalia', 'avenida', 'avisei', 'avisos', 'banho', 'barrinha', 'bateu', 'belem', 'beneficia', 'bike', 'blackpink', 'bloco', 'bluetooth', 'bobs', 'boosts', 'botando', 'brindes', 'bugam', 'busco', 'busquei', 'cadastros', 'cadeira', 'campainha', 'caos', 'causas', 'ceu', 'chamam', 'chateia', 'chegarem', 'chegaria', 'cheios', 'choca', 'ciencia', 'cigarro', 'citado', 'coitado', 'combinacoes', 'comecarem', 'cometi', 'complementar', 'concreta', 'conferencia', 'conferi', 'confio', 'confirmam', 'confirmo', 'conseguirmos', 'contente', 'continuarei', 'conveniencia', 'convidados', 'copiando', 'coragem', 'correria', 'corretas', 'correu', 'corrigidos', 'cortadas', 'corte', 'cozinhar', 'crie', 'cuidar', 'curtem', 'custava', 'dancinha', 'danos', 'dark', 'debitaram', 'decadente', 'definitivo', 'deixarem', 'desapontado', 'desativa', 'desativou', 'descobre', 'desconectada', 'desconectar', 'descontada', 'descontentamento', 'desembarque', 'desgaste', 'desgosto', 'desinstale', 'desligo', 'despercebido', 'despreparados', 'destacar', 'devagar', 'dialogo', 'diarios', 'diferenciado', 'direcionada', 'dirigindo', 'dirigir', 'disponibilizados', 'distribuicao', 'doente', 'doque', 'durar', 'duvido', 'elementos', 'elogiar', 'empenho', 'empurrando', 'encerrou', 'encima', 'engracadas', 'ensina', 'envie', 'escolhidos', 'escondida', 'espacos', 'esquecido', 'estornou', 'estragado', 'estranhos', 'estrelinha', 'eventuais', 'evitaria', 'exageradas', 'exclusivo', 'exigente', 'exigindo', 'exorbitante', 'explicam', 'explicita', 'exposto', 'falir', 'fecharam', 'ficavam', 'finais', 'finalizo', 'financeiro', 'flop', 'fracasso', 'franquias', 'frescura', 'ganhado', 'ganhava', 'garota', 'gastos', 'geladeira', 'generos', 'gentil', 'gerais', 'gigantesca', 'gostariamos', 'goste', 'hacker', 'honestidade', 'hs', 'ignorada', 'imail', 'impedido', 'importo', 'improprios', 'inapropriadas', 'incluso', 'indicou', 'individualmente', 'indole', 'informava', 'ingrediente', 'inscrever', 'inserido', 'insistencia', 'inteligentes', 'interagindo', 'interrompido', 'invadiram', 'invalida', 'investimento', 'joguei', 'larga', 'largar', 'lastima', 'lateral', 'legivel', 'lentos', 'lgl', 'lindos', 'lixeira', 'localiza', 'logada', 'lupa', 'man', 'marcam', 'master', 'mds', 'mensalmente', 'mentir', 'mercenario', 'merecendo', 'milhao', 'modificado', 'molho', 'moments', 'mostre', 'ms', 'muitoooo', 'necessito', 'negado', 'notificada', 'notificando', 'nu', 'nubank', 'obrigatoriamente', 'ofereceu', 'one', 'operacional', 'opinar', 'otimizar', 'pa', 'paciente', 'paquera', 'parcela', 'pause', 'percebido', 'perigo', 'persistem', 'pesadelo', 'pf', 'picpay', 'planeta', 'please', 'policia', 'pontuais', 'porco', 'positivamente', 'possuia', 'posteriormente', 'poupe', 'pr', 'preenche', 'prestador', 'prestativo', 'prestativos', 'prevista', 'primo', 'priorizar', 'proceder', 'prometeram', 'provas', 'puxa', 'qlqr', 'quadra', 'quebrada', 'quebrado', 'queixas', 'quentinho', 'r100', 'r2000', 'rappibank', 'raras', 'reabrir', 'receba', 'redmi', 'regularmente', 'relacoes', 'relevancia', 'remocao', 'reparado', 'repassar', 'resetar', 'resolvo', 'respaldo', 'respondia', 'reuniao', 'rewards', 'rsrsrs', 'saimos', 'salada', 'salario', 'salgadinhos', 'salvador', 'salvando', 'santo', 'santos', 'sd', 'secundaria', 'segurar', 'sentimos', 'seta', 'simbolo', 'sininho', 'sitio', 'smartphones', 'substituido', 'sugerem', 'sundae', 'surpresas', 'teremos', 'tirassem', 'tml', 'toques', 'tornase', 'tragam', 'tratado', 'travava', 'trem', 'update', 'variacao', 'variar', 'vencer', 'versatil', 'ves', 'viajo', 'vila', 'vinculados', 'vinculo', 'vinhos', 'vivemos', 'vossa', 'vosso', 'vouchers', '01', '1900', '2013', '2015', '32', '360p', '42', '43', '720p', '900', '990', '999', '99pop', 'acertar', 'acostumada', 'acrescentando', 'adicionou', 'administrar', 'adquirido', 'agradaveis', 'aguenta', 'alcancar', 'alo', 'altamente', 'alterados', 'amador', 'andei', 'animado', 'aniversarios', 'aparenta', 'apertando', 'aplicativomas', 'aplicou', 'aproveita', 'aprovou', 'aproxima', 'apto', 'arcar', 'arquivar', 'arrasta', 'arrependimento', 'arrisco', 'artigo', 'assinando', 'assistidos', 'associados', 'atenderem', 'ativadas', 'ativando', 'ativas', 'atores', 'atraente', 'atualizassem', 'aulas', 'aumentam', 'autorizada', 'avancado', 'avia', 'back', 'baixas', 'bastantes', 'bestas', 'besteira', 'bolsa', 'bomo', 'bonitas', 'br', 'bradesco', 'brahma', 'brasilia', 'burra', 'burro', 'cabo', 'cadastrando', 'calculo', 'cameras', 'captura', 'caracteristica', 'carvao', 'chegasse', 'cheias', 'chicken', 'cigarros', 'clicado', 'clicamos', 'coincidencia', 'colocaria', 'compartilhadas', 'compartilhando', 'compensar', 'competente', 'completos', 'complicacoes', 'compromete', 'comunicado', 'condicionado', 'conduta', 'conectados', 'conexoes', 'confiei', 'consecutivos', 'conserta', 'considerada', 'consideravelmente', 'continuamente', 'contratei', 'contratem', 'contratempo', 'controles', 'convencer', 'copo', 'corrige', 'corrigiram', 'cortado', 'cortes', 'cotidiano', 'cresceu', 'ctz', 'cuida', 'custar', 'dadas', 'daquela', 'decidiu', 'deis', 'demore', 'dependem', 'desapontada', 'desastre', 'desce', 'desejam', 'desesperado', 'desing', 'desistido', 'desligada', 'desligou', 'deslogar', 'detalhado', 'deveras', 'digamos', 'diretriz', 'disponibilizadas', 'disponibilizou', 'diziam', 'drogas', 'duram', 'durou', 'duzia', 'efetivamente', 'elevados', 'embacado', 'emitir', 'enchendo', 'encomendas', 'enfrentei', 'entraga', 'entrarem', 'entrasse', 'entreter', 'entt', 'envios', 'esconde', 'escondem', 'escreveu', 'esfirras', 'esperto', 'esqueco', 'estacionamento', 'estam', 'estariam', 'estragados', 'evidente', 'evita', 'evito', 'excluidas', 'excluo', 'existisse', 'externo', 'f', 'faculdade', 'falencia', 'falhar', 'fara', 'fazelo', 'faziam', 'fechava', 'festa', 'fidelizar', 'figuras', 'filtragem', 'fofocas', 'frequentar', 'frontal', 'full', 'funcionais', 'ganharam', 'ganharia', 'garrafas', 'geracao', 'geram', 'gesto', 'gravados', 'guia', 'habilitada', 'hahaha', 'haveria', 'horizontal', 'ignora', 'ilegal', 'imaginei', 'inativos', 'inconsistencias', 'indicados', 'induzindo', 'inexistentes', 'inferiores', 'influencia', 'inscricoes', 'instabilidades', 'integrado', 'interrompendo', 'intimas', 'inventar', 'irrelevante', 'irresponsavel', 'isolamento', 'jeitinho', 'kkkkkk', 'leis', 'leitor', 'liberando', 'limitam', 'livrar', 'localizacoes', 'mande', 'maravilhas', 'matar', 'mec', 'mecanica', 'melhorados', 'meme', 'mencoes', 'mensseger', 'mercenarios', 'merecia', 'meter', 'microfone', 'milkshake', 'minusculo', 'moderacao', 'moderna', 'modos', 'moram', 'morava', 'morto', 'movimentacao', 'mtos', 'mudaria', 'muitooo', 'nda', 'ndeg', 'negou', 'nelas', 'norte', 'obedece', 'olham', 'opta', 'ordenacao', 'organizadas', 'organizados', 'osso', 'ovos', 'pagarem', 'pagasse', 'pararem', 'parava', 'parcial', 'participa', 'participando', 'particulares', 'pegadinhas', 'percebendo', 'perderem', 'permanecem', 'permitia', 'permitisse', 'personalizada', 'personalizadas', 'personalizados', 'pesada', 'pft', 'plausivel', 'podiamos', 'pontual', 'porno', 'postada', 'praia', 'preferidos', 'prejudicados', 'prejuizos', 'preocupam', 'prepara', 'preparados', 'presenca', 'presencialmente', 'preste', 'principios', 'procuramos', 'procurava', 'progresso', 'promessa', 'publicados', 'pulando', 'pv', 'quaisquer', 'quiz', 'rastreaveis', 'recebidas', 'receita', 'recem', 'reclameaqui', 'recomendavel', 'recusaram', 'redor', 'reembolsou', 'reenviar', 'refere', 'regular', 'removam', 'removendo', 'repassado', 'repensem', 'repetitivas', 'representa', 'reproduzem', 'ressarcir', 'restituicao', 'retornam', 'revisto', 'rg', 'ricos', 'roubados', 'roupas', 'rumo', 'sairam', 'santa', 'screen', 'secretos', 'segurando', 'selecionamos', 'selecione', 'sensacionais', 'separada', 'seriedade', 'servindo', 'sexualidade', 'significativa', 'simplicidade', 'simplificar', 'sinalizar', 'sincronia', 'smp', 'sobra', 'sobrando', 'sobremesas', 'socorro', 'sofrendo', 'soft', 'solucionados', 'ss', 'stranger', 'sujestao', 'surgindo', 'surpreende', 'surreal', 'tablets', 'tag', 'talkback', 'telefonica', 'telefonico', 'teriamos', 'terminando', 'things', 'tire', 'tiverem', 'tivessem', 'topics', 'torne', 'toxicos', 'transmitir', 'ultra', 'un', 'usalos', 'utilizalos', 'vacuo', 'vagas', 'vales', 'valha', 'validas', 'velhos', 'verdadeiras', 'vertical', 'vimos', 'violando', 'violencia', 'visitou', 'visualizada', 'visualizadas', 'visualizei', 'vitima', 'voltado', 'waze', '06', '10000', '10x', '120', '15min', '19h', '1hora', '1o', '1x', '2030', '2200', '22h', '2300', '24hs', '250', '28', '2a', '3500', '399', '48h', '4x', '5estrelas', '5min', '60fps', '65', '72h', 'aa', 'abandonei', 'aborrecimentos', 'acompanhamentos', 'aconteceram', 'acredita', 'acrescenta', 'acrescimo', 'actualizacoes', 'acumulando', 'adesao', 'adicionam', 'adolescentes', 'aeroporto', 'afeta', 'afirmou', 'agencia', 'agindo', 'agosto', 'agradecido', 'ajeita', 'ajudarem', 'ajustem', 'aki', 'algoritimo', 'alho', 'alimentar', 'alteram', 'alternar', 'alterou', 'altissimos', 'amamos', 'amoo', 'amooooo', 'analista', 'anexar', 'apaixonado', 'apaixonei', 'apelo', 'aplicadas', 'apo', 'aprovada', 'aproveitam', 'aproximar', 'assaltado', 'assiduo', 'assinaturas', 'assista', 'atenda', 'atendimentos', 'ativacao', 'atraentes', 'atrasei', 'atrativas', 'aumentarem', 'aumentava', 'autenticador', 'autonomia', 'avancadas', 'baguncada', 'bares', 'basicos', 'batendo', 'bloqueadas', 'bloqueei', 'bo', 'bobos', 'bolha', 'bomeu', 'bomm', 'bomso', 'bonificacao', 'bonitos', 'botam', 'brava', 'brilhante', 'buscado', 'buscou', 'cadastre', 'caiam', 'calendario', 'call', 'cancelarmos', 'cancelavam', 'capcut', 'carga', 'carinha', 'carissima', 'cego', 'cenas', 'chamando', 'chamava', 'classe', 'colecoes', 'coleta', 'comedia', 'comentam', 'comentei', 'comodo', 'compartilhado', 'completas', 'compreendo', 'comunicam', 'concertado', 'concerteza', 'concordar', 'condizem', 'confirmada', 'conflito', 'congelada', 'congelados', 'consentimento', 'contribui', 'convencional', 'convidado', 'convidei', 'corona', 'corredor', 'corrija', 'cortados', 'cozinha', 'cresce', 'criadas', 'cronologica', 'cujo', 'davam', 'debitou', 'decadencia', 'decaindo', 'decaiu', 'definido', 'deixamos', 'deletei', 'demonstrar', 'demoras', 'dependo', 'deploravel', 'deprimente', 'desaparecer', 'desativaram', 'desatualizar', 'desconectado', 'descreve', 'desinstalalo', 'desinteressante', 'desistem', 'desistiram', 'desnecessariamente', 'destaco', 'detalhada', 'detesto', 'dever', 'devidas', 'digitos', 'digno', 'diminuiram', 'direcionam', 'dispoe', 'disponibilizaram', 'disposto', 'diverte', 'divisao', 'divulga', 'doce', 'donald', 'doq', 'duplicados', 'duplicidade', 'eda', 'edicoes', 'efetivado', 'eficacia', 'eis', 'emprego', 'empregos', 'empresarios', 'empurra', 'encarecidamente', 'encerramento', 'encerrando', 'encomendar', 'encontrados', 'encontraram', 'enrolam', 'entregava', 'enxergar', 'episodio', 'equipa', 'errei', 'escala', 'escanear', 'escrevia', 'escuta', 'escuto', 'esforcar', 'especificado', 'esporadicamente', 'esquerdo', 'estornos', 'estourada', 'estrangeiro', 'estressa', 'estressando', 'etica', 'excecoes', 'excessivo', 'exista', 'existentes', 'expandida', 'expira', 'expliquei', 'expliquem', 'expoe', 'express', 'extensao', 'facilitado', 'facilitam', 'falem', 'falhou', 'familias', 'fantasmas', 'feminino', 'ferra', 'ficarmos', 'fieis', 'filhas', 'finalizaram', 'financeiramente', 'fisicamente', 'fisicas', 'focado', 'fofo', 'formar', 'formos', 'fortuna', 'fps', 'fred', 'futil', 'futura', 'fyp', 'gelar', 'geolocalizacao', 'glovo', 'gostem', 'gravacoes', 'graves', 'grosseiros', 'habibers', 'header', 'higiene', 'humanos', 'icon', 'iffod', 'ignorando', 'imagine', 'imitar', 'implorar', 'improprias', 'inadequados', 'incapaz', 'incentiva', 'incomodada', 'incorretos', 'independentemente', 'indicava', 'indique', 'individuais', 'individuo', 'informo', 'inovador', 'inovar', 'insistir', 'insisto', 'instantaneamente', 'instantaneas', 'interativa', 'invadida', 'inventa', 'inviabiliza', 'irresponsabilidade', 'irritam', 'jogou', 'julho', 'laranja', 'largado', 'lembrava', 'lembrei', 'levo', 'lg', 'liberem', 'limpeza', 'liquido', 'liso', 'livres', 'localizado', 'locomocao', 'locomover', 'lucros', 'magnifico', 'maldade', 'maldito', 'manual', 'mastercard', 'material', 'mbway', 'mcdelivery', 'menseger', 'mentiras', 'mentirosa', 'mercadorias', 'migrarem', 'migrei', 'milagre', 'misteriosamente', 'modelos', 'morando', 'morrer', 'mostrados', 'mudarei', 'muuuuuuito', 'nadae', 'natal', 'navega', 'necessariamente', 'nexo', 'nf', 'niguem', 'norma', 'objetos', 'obrigatoria', 'obsoleto', 'ocorreram', 'ocorria', 'oculto', 'ofender', 'ofensas', 'ofensivo', 'oferecida', 'oferecidas', 'olhem', 'opa', 'opera', 'operar', 'ouvidoria', 'parabenizo', 'parceira', 'passagem', 'passarem', 'pdf', 'pedida', 'pediria', 'pendentes', 'pensamento', 'pensamentos', 'penultima', 'percepcao', 'permanente', 'personal', 'pesar', 'picks', 'pingo', 'pinterest', 'piorado', 'pizzarias', 'pizzas', 'planejado', 'pobres', 'podes', 'podese', 'ponte', 'pontualidade', 'postarem', 'postura', 'preenchido', 'preferida', 'preferir', 'pressionar', 'prestados', 'pretendia', 'previa', 'prezados', 'prima', 'processa', 'processado', 'procurem', 'profissao', 'programada', 'programador', 'prostituicao', 'provando', 'publicas', 'publiquei', 'puto', 'qie', 'r200', 'r3000', 'r5', 'racismo', 'rackeado', 'rappicard', 'rappy', 'reage', 'realizacao', 'recebidos', 'recheado', 'recheio', 'reconheceu', 'recordo', 'reembolsa', 'relacionadas', 'rells', 'removerem', 'repassa', 'repetido', 'reproduzidos', 'requisito', 'resido', 'respeitar', 'restringe', 'retornei', 'retweetar', 'rigor', 'rindo', 'rodas', 'rolo', 'rouba', 'roubam', 'sacolas', 'salvam', 'salve', 'sangue', 'secoes', 'seguimos', 'seguras', 'seguros', 'seletivo', 'sentem', 'sentimento', 'seres', 'simplificado', 'simulacao', 'sincronizados', 'sozinhos', 'stella', 'sticker', 'stts', 'superiores', 'suporto', 'suposta', 'surpreendente', 'surpreendi', 'surpreendo', 'suspenso', 'tam', 'tamanhos', 'telo', 'tempero', 'tende', 'tentarem', 'toa', 'tocam', 'toco', 'tome', 'tornaria', 'tornouse', 'trabalhei', 'traduz', 'trajetoria', 'tranquila', 'tranquilidade', 'transportes', 'tratada', 'tratem', 'tuite', 'twiter', 'u', 'unir', 'universo', 'utilizacoes', 'utilizada', 'utilize', 'validado', 'valorizar', 'varia', 'variacoes', 'verificacoes', 'viciado', 'viralizar', 'vire', 'virei', 'viria', 'visita', 'vistas', 'visualizando', 'xiomi', 'y', '0300', '10k', '128', '130', '1300', '1800', '2007', '2010', '2011', '23h', '2hrs', '4deg', '800', '890', '95', 'abandonado', 'abandonando', 'abencoe', 'aborrece', 'abrangencia', 'absoluta', 'acessava', 'achado', 'acidentalmente', 'acompanhado', 'aconteceria', 'acontecesse', 'acostumar', 'acumula', 'acumulados', 'adeus', 'adiantar', 'administrador', 'administro', 'adolescente', 'afetando', 'agonia', 'agradecia', 'ajudas', 'ajudava', 'alcool', 'alcoolicas', 'altissimo', 'amassadas', 'ame', 'ameii', 'amoooo', 'androids', 'anotacoes', 'anti', 'anual', 'anunciados', 'anunciantes', 'apagados', 'aparecera', 'apareceria', 'aperfeicoar', 'aplicativoe', 'aposto', 'aprece', 'aprendo', 'apresentadas', 'apresentava', 'aproveite', 'aproximacao', 'assinem', 'assistem', 'associada', 'atentar', 'atrapalhe', 'atuacao', 'atuar', 'aula', 'aumentado', 'autoestima', 'automatizado', 'auxilia', 'avanca', 'avancada', 'averiguar', 'baixada', 'baixadas', 'baixam', 'banners', 'barulho', 'baseado', 'bendito', 'boba', 'bocado', 'bonzinho', 'borda', 'box', 'brecha', 'browser', 'buzinando', 'cadastram', 'cadastramento', 'caio', 'caixinhas', 'caminhos', 'cancelem', 'cansaco', 'cantores', 'capacete', 'carissimo', 'casada', 'casamento', 'casuais', 'causado', 'cdc', 'ce', 'cem', 'cento', 'checkout', 'cheddar', 'chegamos', 'cheiro', 'chequei', 'chovendo', 'cilada', 'circunstancias', 'citei', 'cobrava', 'cobrem', 'cocacola', 'colabora', 'colaboracao', 'colaborador', 'colaborar', 'colorido', 'combinar', 'comeback', 'comecem', 'comerciantes', 'compartilhamentos', 'compartilhei', 'compatibilidade', 'complicacao', 'comprometer', 'comprovantes', 'computadores', 'comunico', 'condizente', 'conducao', 'confirme', 'confundindo', 'conhecida', 'conhecidas', 'considera', 'constatei', 'constrangido', 'construido', 'consumido', 'consumidora', 'contactos', 'continuando', 'contras', 'contratacao', 'contratos', 'copiado', 'cordial', 'core', 'correcoes', 'correspondente', 'costas', 'crer', 'criassem', 'crimes', 'cuidadosos', 'culinaria', 'culturas', 'cumulo', 'curiosidade', 'curtia', 'curtimos', 'customizavel', 'cx', 'dali', 'daquilo', 'debitocredito', 'decepcoes', 'default', 'deficientes', 'define', 'demonstrando', 'demorados', 'demorava', 'demoro', 'denunciado', 'deparo', 'depositar', 'derrubam', 'desanimado', 'desanimando', 'desatualizada', 'desbloqueia', 'desbloqueio', 'descartar', 'descartavel', 'desconectou', 'desconforto', 'desconhecidas', 'descontando', 'descontaram', 'desejamos', 'desfaz', 'desistala', 'desloguei', 'desonestidade', 'despois', 'desprazer', 'dessem', 'destes', 'destruiu', 'desvincular', 'deveriamos', 'diaria', 'didatico', 'diferenciados', 'digam', 'direcionados', 'divulgado', 'divulgando', 'dmais', 'dobrado', 'dona', 'dormindo', 'drasticamente', 'duro', 'duvidoso', 'economizando', 'efetivo', 'empresarial', 'emprestado', 'empurrar', 'encaixa', 'encerrada', 'encerram', 'enchem', 'encontrada', 'encontre', 'energia', 'entediado', 'entenda', 'entreterimento', 'enviavam', 'envolvendo', 'erraram', 'errou', 'escolherem', 'escritas', 'esforcos', 'esporte', 'esquecemos', 'essenciais', 'estimada', 'estragaram', 'estrangeiros', 'estressada', 'eterna', 'eterno', 'eua', 'evoluindo', 'evoluiu', 'exaustivo', 'excede', 'explicativo', 'explico', 'expostos', 'facebooke', 'falarem', 'falhando', 'falhos', 'faltaram', 'fantasma', 'faq', 'fardo', 'fatos', 'favoravel', 'faze', 'fdp', 'fecebook', 'fecham', 'feeds', 'fere', 'ferrado', 'fibra', 'fidelizacao', 'filosofia', 'fiscalizar', 'fixos', 'flopar', 'fornecedora', 'fotovideo', 'fritas', 'frustado', 'funcionavam', 'fundamentais', 'furto', 'futuros', 'game', 'garrafinhas', 'gas', 'gato', 'genericas', 'good', 'gostaram', 'governos', 'gratos', 'grosseiro', 'grosso', 'grupocanal', 'habil', 'habitantes', 'habito', 'hackearam', 'havera', 'heterossexual', 'honesta', 'icons', 'identifiquei', 'ignorantes', 'imensamente', 'impedem', 'impedida', 'implementada', 'impor', 'importando', 'imprescindivel', 'inadequadas', 'inadequado', 'incomodar', 'incomodou', 'incompetente', 'incompetentes', 'incompleta', 'indesejadas', 'indicam', 'indisponibilidade', 'induzir', 'infinitos', 'iniciando', 'iniciei', 'inovacao', 'inscricao', 'inserindo', 'insiro', 'instalados', 'instantaneo', 'instituicoes', 'instrucao', 'inteiramente', 'intencionados', 'interatividade', 'interfone', 'internacionais', 'intervalo', 'invadem', 'invisivel', 'irem', 'istagram', 'j2', 'j4', 'jogada', 'jornais', 'judicial', 'julgam', 'junta', 'justificar', 'kg', 'l', 'lacre', 'largo', 'legumes', 'leio', 'lesa', 'lesar', 'leves', 'liberaram', 'ligados', 'ligue', 'liguem', 'limitamos', 'limpos', 'mach', 'mala', 'marcadas', 'market', 'marktplace', 'marmita', 'masculino', 'massas', 'materias', 'meche', 'medicamento', 'mediocre', 'mensais', 'mental', 'mentindo', 'mentiroso', 'metro', 'metropolitana', 'mexem', 'mina', 'mochila', 'modernos', 'modificacao', 'modificacoes', 'motoca', 'motos', 'msc', 'msn', 'muiiito', 'musically', 'musicaly', 'muuito', 'necessitar', 'negacao', 'negrito', 'nehuma', 'nicho', 'niteroi', 'nitido', 'nojento', 'notificadas', 'notificou', 'novelas', 'numeracao', 'oara', 'oculos', 'of', 'ofertam', 'okay', 'onda', 'opniao', 'out', 'ouviu', 'pack', 'pag', 'pagarmos', 'palavroes', 'panela', 'parace', 'parcialmente', 'participacao', 'passaria', 'passatempo', 'patetico', 'paulista', 'pausado', 'pegava', 'pelada', 'pensava', 'pensou', 'perdidas', 'periodos', 'permitam', 'persistir', 'personagens', 'personalidade', 'pertence', 'pertinentes', 'piadas', 'pilantra', 'poderei', 'poluindo', 'popups', 'poste', 'precisasse', 'preocupa', 'presencial', 'presos', 'prestem', 'prezunic', 'prft', 'printei', 'processando', 'processos', 'proibe', 'proibir', 'proporcionando', 'protege', 'pub', 'publicando', 'pulo', 'punir', 'qrcode', 'qria', 'qro', 'qse', 'quadro', 'querido', 'qur', 'r10', 'r150', 'r40', 'racista', 'rappicredito', 'razoaveis', 'realizo', 'reaparece', 'reavalio', 'recife', 'reclamou', 'recomendam', 'reconhecido', 'recuperala', 'recuperei', 'redirecionando', 'redondo', 'reduzindo', 'reflete', 'registrados', 'regulamento', 'reinstalado', 'relata', 'rels', 'remedios', 'removem', 'removidos', 'repassam', 'repasse', 'repetidamente', 'reposta', 'resgatei', 'resolvermos', 'respeitada', 'responda', 'respondo', 'ressalvas', 'resta', 'restringida', 'retiradas', 'retornem', 'retweets', 'reveja', 'review', 'revisem', 'revista', 'revoltado', 'risadas', 'riscos', 'rolou', 'rudes', 'ruinzinho', 's21', 'saberem', 'sabese', 'sabiam', 'saboroso', 'sal', 'salvava', 'sanar', 'seguia', 'seguidamente', 'selecionadas', 'selfie', 'semanais', 'semi', 'sente', 'separadamente', 'separando', 'sermos', 'setembro', 'shop', 'shoppings', 'siga', 'sigilo', 'signal', 'simpatia', 'simular', 'sinalizacao', 'sobem', 'sofrem', 'sol', 'soma', 'somando', 'somar', 'spoiler', 'substituiu', 'sujeito', 'suport', 'suporta', 'suportado', 'suportar', 'suspender', 'telegrama', 'ten', 'terriveis', 'thumb', 'tmj', 'tomare', 'tomarem', 'topico', 'torca', 'torco', 'totem', 'trago', 'transacoes', 'transformar', 'traria', 'travados', 'trave', 'travestis', 'trecho', 'tristes', 'tweetar', 'twt', 'ultrapassar', 'url', 'usaram', 'users', 'utilidades', 'valoriza', 'vdo', 'velhas', 'vera', 'verdadeiramente', 'videochamadas', 'violacoes', 'violam', 'vivendo', 'vivia', 'voltassem', 'voto', 'vozes', 'wallpaper', '04', '1010', '110', '1290', '12h', '140', '18h', '2040', '20h', '20hs', '2230', '2330', '2min', '33', '350', '37', '3a', '3d', '4000', '50min', '51', '68', '72', '98', 'abra', 'abrangente', 'abrilo', 'acarreta', 'aceitaria', 'aceitas', 'aceitavam', 'acessada', 'acessado', 'acharia', 'acordar', 'acucar', 'acusou', 'ad', 'adaptavel', 'adiante', 'adicionadas', 'adicionasse', 'adorar', 'afastando', 'afff', 'affs', 'afinidade', 'agendei', 'agiu', 'agradar', 'agradecida', 'agradecimento', 'agregar', 'aguardava', 'aguentar', 'ain', 'aiqfome', 'alegrar', 'alertando', 'alfabetica', 'alterada', 'alteraram', 'ameaca', 'ameacas', 'ampla', 'anonima', 'ansiosamente', 'ansioso', 'antivirus', 'anuncia', 'apague', 'apanhar', 'aparecam', 'aplicalo', 'aplicatico', 'aplicativoele', 'aplicativosite', 'aplique', 'apoia', 'appmais', 'appnao', 'appso', 'aprecio', 'aprendam', 'apresentaram', 'aprimoramento', 'aproveitei', 'aproveito', 'aprovo', 'armazenadas', 'arrancar', 'arrumam', 'arte', 'aspas', 'assinarem', 'assino', 'assistimos', 'associado', 'atendam', 'atendi', 'atingem', 'atualizadas', 'aumentei', 'autodestruicao', 'autor', 'avalicao', 'ave', 'avisem', 'bag', 'baguncados', 'baixaria', 'baixava', 'baixissima', 'balao', 'bancarios', 'barreiras', 'bau', 'bb', 'bbb', 'beneficiar', 'bilhao', 'biscoitos', 'bloquearem', 'bobas', 'boicote', 'boletim', 'bolinhas', 'bombar', 'boom', 'boots', 'bost', 'botem', 'brasileiras', 'bravo', 'brigar', 'brinde', 'bugava', 'burrice', 'by', 'caca', 'cachaca', 'cairam', 'calculado', 'calcular', 'calma', 'calote', 'campanhas', 'campinas', 'cansar', 'cantor', 'capas', 'capazes', 'carlos', 'carregado', 'carregarem', 'casados', 'casinha', 'cegas', 'celula', 'center', 'cerebro', 'chamou', 'chateando', 'checar', 'cheguem', 'choro', 'ci', 'ciclo', 'classico', 'classificado', 'click', 'cliques', 'cnh', 'codico', 'colecao', 'colocadas', 'comecado', 'comece', 'comentado', 'cometer', 'companheiro', 'companhia', 'comparados', 'compartilhada', 'compartilham', 'compartilhe', 'competitivo', 'complexa', 'comporta', 'compreender', 'comprometidos', 'comprovacao', 'computado', 'comunicacoes', 'con', 'concerte', 'concluindo', 'concordei', 'condutores', 'confere', 'confia', 'confirmacoes', 'confirmaram', 'confiro', 'conformes', 'congeladas', 'conheca', 'conhecerem', 'conhecimentos', 'conjunto', 'consequencia', 'consertado', 'consertassem', 'conservacao', 'consideraveis', 'constrangedora', 'construir', 'contabiliza', 'contabilizando', 'conte', 'contrapartida', 'contratam', 'contratempos', 'contrato', 'convenhamos', 'convenio', 'converter', 'convidando', 'convivio', 'coracoes', 'correspondem', 'corretor', 'cortam', 'cortesia', 'cota', 'crash', 'crasha', 'crashando', 'criados', 'critico', 'criticos', 'cuando', 'cuja', 'cumprida', 'cumprindo', 'cumpriu', 'cupoes', 'custobeneficio', 'dariam', 'debita', 'debitos', 'decepcionar', 'decido', 'dedos', 'deixalo', 'deletado', 'deliverys', 'demonstra', 'denuncio', 'derramado', 'derretido', 'derruba', 'derrubar', 'desabafo', 'desafios', 'desaforo', 'desaparecendo', 'desaparecido', 'desativo', 'desatualizados', 'desci', 'descobrimos', 'descobrindo', 'desconfiado', 'desconhecida', 'dese', 'desistalo', 'desliza', 'desloga', 'deslogou', 'desonestos', 'desrespeita', 'destaca', 'destacado', 'destilado', 'destruindo', 'desvia', 'detalhamento', 'dev', 'deva', 'devolva', 'devolvi', 'devolvida', 'devolvidos', 'diferenciadas', 'diferentemente', 'dificultou', 'diga', 'diminua', 'diminuam', 'diretos', 'dirigem', 'dirigi', 'dis', 'discussao', 'disparado', 'disponibilizando', 'distintos', 'distracao', 'distrai', 'distribuir', 'divergencias', 'diversificadas', 'diversificado', 'divertindo', 'doces', 'donada', 'drivetru', 'dublagens', 'dueto', 'duplica', 'duplicou', 'east', 'economiza', 'ecra', 'efetivar', 'efetuou', 'embalados', 'embalagens', 'empatia', 'encerraram', 'encontrarmos', 'enfrento', 'enganam', 'enganem', 'engrenagem', 'enquando', 'ensinar', 'entenderam', 'entendia', 'entendido', 'entregasse', 'entristece', 'enviem', 'envolve', 'ep', 'epp', 'equivalente', 'erroneamente', 'esclarecimentos', 'escondidos', 'escrevem', 'escrevemos', 'esfirra', 'esforca', 'especialistas', 'especializado', 'especificam', 'esperiencia', 'esqueceram', 'esquecidos', 'estabelecer', 'estacao', 'estagiario', 'estala', 'estalei', 'estarao', 'estelionato', 'estimula', 'estra', 'estressado', 'estruturado', 'esvaziar', 'etico', 'evitem', 'exagerando', 'excepcionalmente', 'excessivamente', 'exclua', 'exemplar', 'exibia', 'exibidas', 'exibidos', 'exigencia', 'exigencias', 'exijo', 'expiracao', 'expiram', 'explicou', 'expostas', 'exterior', 'externos', 'facebok', 'facial', 'facilitada', 'falham', 'familiar', 'fastfoods', 'feature', 'feche', 'feios', 'felicidade', 'ff', 'ficaadica', 'ficariam', 'ficassem', 'figura', 'filial', 'financeira', 'financeiros', 'flexiveis', 'foca', 'forcei', 'formatos', 'fortaleza', 'fortes', 'fragil', 'frequento', 'funcionarem', 'fundos', 'furioso', 'furtado', 'g8', 'galho', 'gameplay', 'gamer', 'games', 'gastam', 'gastaria', 'gay', 'geito', 'geladinhas', 'gift', 'giga', 'gigantes', 'girar', 'goela', 'goiania', 'gp', 'grafico', 'gravada', 'gravadas', 'gravida', 'grosseria', 'guarda', 'habitual', 'hahahaha', 'happy', 'hate', 'heim', 'hiper', 'honestamente', 'humana', 'humanidade', 'humilhacao', 'ida', 'idealizadores', 'ignorou', 'ih', 'ilha', 'ilimitados', 'iludir', 'imoral', 'impacto', 'impasse', 'impedimento', 'imperio', 'implementado', 'impossibilitada', 'impostos', 'impressos', 'impulsionar', 'incentivos', 'incidente', 'incluam', 'incoerencia', 'incompatibilidade', 'incomum', 'inconsistente', 'incovenientes', 'indeterminado', 'indriver', 'induzido', 'infernal', 'influenciar', 'info', 'infringindo', 'iniciais', 'insegura', 'insercao', 'inseriu', 'insira', 'instantes', 'instragam', 'instrumento', 'insuficiente', 'insuportaveis', 'intagram', 'intencoes', 'inter', 'interage', 'interessada', 'interessou', 'intuitivos', 'invadindo', 'invasoes', 'iriamos', 'irresponsaveis', 'iso', 'issoe', 'issoeu', 'j', 'janelas', 'japonesa', 'joguinhos', 'jovem', 'juntando', 'justas', 'justifica', 'kkkkkkkkk', 'labirinto', 'lags', 'lamentar', 'lancaram', 'lasque', 'lastimavel', 'latoes', 'leia', 'leitores', 'lembranca', 'lentamente', 'levem', 'liberacao', 'ligamos', 'limbo', 'linguica', 'litoral', 'litro', 'livremente', 'localidades', 'loga', 'logins', 'logoff', 'lojista', 'lopes', 'lucra', 'lucram', 'luis', 'maca', 'maise', 'malas', 'manaus', 'mandamos', 'mandavam', 'manipular', 'mar', 'massagem', 'materiais', 'maturidade', 'medio', 'meditacao', 'melhorava', 'membro', 'mencionei', 'mensageiros', 'mentirosos', 'merd', 'mete', 'miniatura', 'minuscula', 'miseravel', 'mix', 'modifiquem', 'montagem', 'morais', 'morrendo', 'mostrada', 'mostraram', 'mostrem', 'msgns', 'mudamos', 'mudassem', 'mudava', 'muitoo', 'multiplos', 'my', 'nacional', 'naqueles', 'natural', 'navios', 'nega', 'negam', 'negaram', 'nego', 'nisto', 'nitida', 'noivo', 'nojentos', 'notinha', 'novela', 'novembro', 'nudes', 'oa', 'obgd', 'objetiva', 'observado', 'observando', 'ocultas', 'ocupados', 'odiando', 'oeste', 'ofendi', 'ofereca', 'oferecia', 'ofertados', 'oii', 'operadoras', 'optando', 'orientado', 'orientou', 'origem', 'orivel', 'otario', 'otimomais', 'ovo', 'pagaram', 'pagarei', 'paia', 'paisagem', 'paisagens', 'palhaco', 'pane', 'papeis', 'paras', 'parecidas', 'participei', 'pasme', 'passageira', 'password', 'pasteis', 'pastel', 'pata', 'patrocinados', 'pd', 'pedaco', 'pedirem', 'pegadinha', 'pegue', 'penalizar', 'pensado', 'percebem', 'perdera', 'perderia', 'perigosa', 'permiti', 'pesquisem', 'phone', 'picanha', 'picture', 'piloto', 'pixels', 'pk', 'planejamento', 'plastico', 'plenamente', 'plis', 'podessem', 'poem', 'politicamente', 'politico', 'pondo', 'pornografico', 'possibilitando', 'posterior', 'poupa', 'pouquissimo', 'power', 'ppr', 'praca', 'praticado', 'praticados', 'precisarem', 'precisas', 'precisou', 'preenchimento', 'preferindo', 'prefira', 'prefiram', 'prejudicial', 'prejudicou', 'preocupada', 'presenciei', 'prestou', 'pretas', 'previsoes', 'prioritaria', 'prioritario', 'priorizando', 'privilegio', 'probabilidade', 'problemao', 'problematicas', 'processou', 'professora', 'programadas', 'prometo', 'promissor', 'promove', 'prontificou', 'propagando', 'provavel', 'providenciar', 'prox', 'publicou', 'punido', 'qqr', 'qquer', 'quadrado', 'qualifica', 'quarteirao', 'quarteiroes', 'quarto', 'quebrando', 'queixar', 'queridos', 'questionavel', 'quilometros', 'quinze', 'r30', 'rackeada', 'rappis', 'rastreadas', 're', 'realizados', 'recepcao', 'recolha', 'recolher', 'reconhecia', 'recorrendo', 'recusados', 'redirecionado', 'redirecionar', 'reducao', 'reduz', 'reduzida', 'registrada', 'reiniciado', 'reinicie', 'rejeicao', 'relatam', 'relataram', 'remuneracao', 'reparem', 'repita', 'repor', 'reprodutor', 'requer', 'resgata', 'resolveria', 'respectivas', 'respondidas', 'responsabilizar', 'respostar', 'rest', 'restritas', 'resumir', 'retirarem', 'retirassem', 'reto', 'retornaveis', 'retuitar', 'revoltada', 'revolucionario', 'reza', 'roblox', 'robotizado', 'rude', 's8', 'sabera', 'sabermos', 'saga', 'salvacao', 'santander', 'satisfatorias', 'satisfazer', 'scroll', 'seguram', 'selecoes', 'selo', 'sena', 'sentimentos', 'servia', 'sessoes', 'sete', 'setores', 'sexualizando', 'simpatica', 'sinaliza', 'sobrecarregado', 'sobrenome', 'sofro', 'solicitam', 'solteiros', 'soluciona', 'solucionaram', 'solucionem', 'soque', 'sorteio', 'sorvetes', 'storiesstatus', 'storyes', 'suicidio', 'suja', 'superam', 'superando', 'superficiais', 'superficial', 'supre', 'surpreender', 'suspeita', 'suspenderam', 'suspensoes', 'tampouco', 'tarja', 'tecnologico', 'teem', 'telefonar', 'telespectadores', 'temporizador', 'tendencias', 'tenso', 'teoricamente', 'terminam', 'terminou', 'thumbnail', 'tirada', 'tirava', 'titulos', 'tmbm', 'tocava', 'tocou', 'tolerancia', 'tomou', 'tornarem', 'tornarse', 'trabalhe', 'tracos', 'tradicionais', 'traducoes', 'traduzindo', 'tranca', 'transferencias', 'transforma', 'transformando', 'transmissoes', 'transportar', 'travas', 'trend', 'trinta', 'trocadas', 'trocam', 'troque', 'turma', 'uau', 'ubercash', 'uberpass', 'ubers', 'ultrapassado', 'ums', 'unicamente', 'uploads', 'usasse', 'usual', 'valeria', 'vazou', 'vds', 'veganos', 'vencidos', 'vendidos', 'veracidade', 'verao', 'verificarem', 'verificou', 'vezez', 'viceversa', 'videosfotos', 'vindas', 'viola', 'viralizam', 'virtude', 'visitar', 'visitas', 'visse', 'visuais', 'vitrine', 'vizualizacao', 'watts', 'whopper', 'win', 'yotube', 'ytb', 'yutube', 'zenfone', 'zera', 'zerar', '000', '0000', '010', '049', '1080p60fps', '1200', '130h', '169', '1890', '190eur', '1hr', '2009', '2023', '240', '2700', '299', '2990', '2k', '321', '36', '360', '38', '44', '4500', '46', '480', '499', '53', '54', '540', '5k', '600ml', '64', '790', '799', '810', '910', 'abandonem', 'abc', 'aborrecimento', 'abrange', 'abranger', 'abrimos', 'acabem', 'aceitasse', 'aceitassem', 'acertaram', 'acessam', 'acesse', 'acharam', 'ache', 'acompanhada', 'acompanhei', 'acontecimentos', 'acostuma', 'acostumados', 'acostumando', 'acostumei', 'acougue', 'acrecentar', 'acrescentem', 'acumulado', 'adaptacao', 'adc', 'adegas', 'ademais', 'aderem', 'adianto', 'adicionalmente', 'adicionamos', 'administra', 'administrado', 'adoram', 'adquiridos', 'afazeres', 'afirma', 'afirmando', 'age', 'ageitem', 'agendadas', 'agira', 'agradando', 'agradecimentos', 'agregado', 'aguarda', 'aguardamos', 'ajudo', 'alegacao', 'alternativo', 'alunos', 'amadores', 'amarelo', 'amargo', 'ameiii', 'amendoim', 'amenizar', 'america', 'amores', 'and', 'andre', 'anexo', 'animada', 'aniversariantes', 'anonimato', 'ansiosa', 'antartica', 'antecipada', 'anucio', 'anunciaram', 'aparecesse', 'apareci', 'apelar', 'aperece', 'apertado', 'apertamos', 'aperte', 'aplicalixo', 'aplicava', 'aplicaveis', 'aplico', 'apoiar', 'apontando', 'appja', 'appporem', 'apptem', 'apresente', 'apropriacao', 'aprox', 'arco', 'argumento', 'arrumado', 'artesanais', 'artigos', 'asmr', 'assiduos', 'assine', 'assustada', 'atadas', 'atenciosa', 'atendidas', 'atenta', 'atingi', 'atingido', 'atrase', 'atrativos', 'atravessar', 'atravez', 'atraz', 'atualizalo', 'atualizamos', 'aumentaria', 'aumente', 'auxiliam', 'avaliem', 'avaliou', 'avanco', 'aviao', 'avisados', 'avisava', 'avo', 'azedo', 'baixalo', 'baixamos', 'balanca', 'balela', 'banana', 'bania', 'banirem', 'barras', 'barulhentos', 'bati', 'bauru', 'bebado', 'beira', 'beirute', 'bendita', 'best', 'bios', 'blablabla', 'blog', 'bloquea', 'bm', 'bobeira', 'bolacha', 'booster', 'borrada', 'brancas', 'brazil', 'brigas', 'brusca', 'buraco', 'burocratica', 'buscamos', 'business', 'busque', 'caber', 'cabimento', 'cachorro', 'cadastradas', 'cadastrais', 'cadeado', 'calcada', 'calmo', 'calor', 'caminhao', 'camisa', 'cancer', 'canso', 'cap', 'cards', 'carece', 'carencia', 'carinhas', 'carregada', 'carreira', 'carteiras', 'cast', 'causam', 'cautela', 'cebola', 'cena', 'cenario', 'cervejinha', 'chamamos', 'chegavam', 'chora', 'chorando', 'churrascaria', 'churros', 'cinema', 'claridade', 'classes', 'classifiquei', 'clientela', 'clima', 'cobravam', 'coerente', 'colocacao', 'colocados', 'combinacao', 'combinada', 'combustiveis', 'comemorar', 'comentados', 'comerciante', 'comercias', 'comodismo', 'comora', 'competentes', 'completei', 'comprarei', 'comprarem', 'comprovando', 'comunicarmos', 'concerta', 'concertarem', 'condominios', 'conecto', 'confie', 'confiem', 'configurando', 'confira', 'confirmarem', 'confirmava', 'confundem', 'confusoes', 'congelado', 'conquistar', 'consecutivamente', 'conseguiamos', 'conseguira', 'conseguisse', 'consequencias', 'conservadores', 'consideram', 'considerem', 'consomem', 'constatar', 'consume', 'contabilizados', 'contabilizou', 'contactei', 'contaja', 'contamos', 'contapor', 'contestacao', 'continuacao', 'continuarem', 'continuos', 'contraria', 'contribuir', 'controla', 'convencionais', 'conversam', 'convida', 'convido', 'copos', 'corporativo', 'corpos', 'correm', 'corrente', 'corrido', 'corrigidas', 'corrigindo', 'corrigissem', 'covid19', 'criadora', 'criminosas', 'criminosos', 'cru', 'culpado', 'cultural', 'custam', 'custando', 'custaria', 'custos', 'cvv', 'dane', 'danificada', 'daquelas', 'dara', 'debitam', 'decentes', 'decepciono', 'decida', 'decimo', 'dedicada', 'dedicado', 'dedicar', 'definicao', 'definidas', 'deixarei', 'deleta', 'deletada', 'deletando', 'delicioso', 'demasiado', 'denunciam', 'denunciaram', 'dependia', 'depos', 'derem', 'desabilitado', 'desagrada', 'desanimada', 'desanimei', 'desastroso', 'desativados', 'desativam', 'descanso', 'descarrega', 'descarta', 'descartaveis', 'descendo', 'descobrem', 'desconfianca', 'desconhecem', 'descontados', 'descritas', 'desejarem', 'desejavel', 'desencontros', 'desesperador', 'desespero', 'desestimulando', 'desfiz', 'desinformacao', 'desinstalacao', 'desinstalarei', 'desisntalar', 'desisntalei', 'desistam', 'desistencias', 'desligam', 'desligando', 'deslize', 'desmarcar', 'desmonetizacao', 'desperdicio', 'destroem', 'destruido', 'desvalorizando', 'detalhadas', 'detalhar', 'detectar', 'detectou', 'devidos', 'deviria', 'devolveriam', 'di', 'diae', 'dialogar', 'dialogos', 'diferencia', 'diferenciada', 'diferenciar', 'digitado', 'digitalizar', 'diminuem', 'diminuicao', 'diminuido', 'disponibilizem', 'disposta', 'disputa', 'disseminacao', 'distorcida', 'distorcidas', 'dita', 'divertidas', 'divide', 'dividida', 'divido', 'divulgam', 'divulgo', 'doacao', 'dobra', 'dobrar', 'domicilio', 'doramas', 'dowload', 'doze', 'dr', 'driblar', 'drivethru', 'dupla', 'duplicada', 'duplicando', 'duvidar', 'ea', 'eat', 'economica', 'economico', 'edite', 'editei', 'edt', 'educadas', 'efetivacao', 'efetivada', 'efetua', 'efetuando', 'elaborado', 'elea', 'eletronica', 'elevada', 'embarcar', 'embutido', 'eme', 'emfim', 'emogi', 'empecilhos', 'empenhado', 'encaminham', 'encomodando', 'enfiar', 'enganando', 'enganei', 'engessado', 'enqto', 'enrola', 'ensinam', 'ensinando', 'entraria', 'entregara', 'enves', 'enviava', 'enxurrada', 'equipamento', 'equipamentos', 'equivoco', 'er', 'erroe', 'error', 'escolaridade', 'escolheram', 'escritos', 'escrota', 'escutem', 'ese', 'esfria', 'espalhadas', 'especialista', 'especificando', 'esperada', 'esperaria', 'esperteza', 'espontanea', 'espuma', 'estagnado', 'estatisticas', 'estatus', 'estilos', 'estimular', 'estornarem', 'estrada', 'estranhamente', 'estressei', 'estudando', 'eventual', 'evolui', 'exagerada', 'exageradamente', 'exagerado', 'exagerados', 'exagerar', 'exatos', 'excedi', 'excedido', 'excessivos', 'excessoes', 'executados', 'executar', 'experimentando', 'explicitos', 'explique', 'exploracao', 'explorando', 'externa', 'externar', 'extorna', 'extraordinario', 'facilitava', 'faicebook', 'faixas', 'fakenews', 'falamos', 'faltavam', 'farsa', 'farto', 'faser', 'favorece', 'fds', 'fechadas', 'federal', 'feias', 'felicidades', 'feriados', 'fernando', 'fiasco', 'file', 'finalizados', 'finalizava', 'financeiras', 'fisicos', 'fixada', 'fixas', 'flexivel', 'flopado', 'florianopolis', 'foge', 'foods', 'foquem', 'forcada', 'formacao', 'fotosvideos', 'fraudador', 'freed', 'frescuras', 'friendly', 'frustra', 'frustrantes', 'fts', 'fugir', 'futeis', 'fzer', 'g6', 'galerinha', 'ganharao', 'ganhariam', 'ganhos', 'gaste', 'gastem', 'geladinho', 'gelados', 'gemea', 'generalizar', 'genio', 'gigantescas', 'girando', 'giro', 'gluten', 'gostosas', 'gratificacao', 'gratificante', 'grau', 'gravissimo', 'grin', 'grossa', 'guando', 'guarana', 'guardados', 'guardo', 'habbibs', 'habbis', 'hajam', 'hater', 'hehe', 'historicos', 'honestos', 'horizonte', 'horrivelnao', 'humilhante', 'identificado', 'ideologia', 'idosa', 'idosos', 'ignorados', 'ignoraram', 'igualzinho', 'iludem', 'imaginava', 'imbativel', 'imbecis', 'implementou', 'imploro', 'importar', 'imposta', 'impressionado', 'impropria', 'in', 'inativas', 'inatividade', 'inativo', 'incentivam', 'incluem', 'incluida', 'incluidas', 'incluiram', 'incluissem', 'incompletas', 'inconformada', 'inconsistencia', 'incontaveis', 'incorretamente', 'incrementar', 'indebita', 'indecentes', 'indefinidamente', 'indentidade', 'indentificar', 'independentes', 'indesejaveis', 'induzem', 'inexplicavel', 'infantis', 'infelicidade', 'influencer', 'influenciando', 'informal', 'informativos', 'informe', 'iniciado', 'iniciante', 'inocentes', 'inoperante', 'insatisfatoria', 'insistentemente', 'insistentes', 'instalou', 'instaveis', 'instragram', 'integralmente', 'inteiros', 'intender', 'interativos', 'intercorrencia', 'interessados', 'interessar', 'interesso', 'interfere', 'intermediacao', 'intermediario', 'interminaveis', 'internos', 'interpretacao', 'interromper', 'interrompida', 'interrupcao', 'interrupcoes', 'intrusivo', 'intuitivas', 'intuitividade', 'invalidos', 'invasivo', 'invencao', 'inventou', 'inverso', 'investe', 'investido', 'investigar', 'investindo', 'invez', 'invistam', 'iremos', 'ironia', 'irrisorio', 'isolado', 'issonao', 'jeitos', 'jente', 'jornada', 'jose', 'julgar', 'junior', 'justificando', 'justificativas', 'ketchup', 'kfc', 'kid', 'kids', 'kilometragem', 'kkkkkkkkkk', 'kpop', 'lactose', 'lagos', 'lamentavelmente', 'lancamentos', 'lancarem', 'larguei', 'lasca', 'latao', 'latinha', 'lavada', 'lavagem', 'leiga', 'leigo', 'leituras', 'lembre', 'leque', 'lesados', 'levaria', 'lgbt', 'liberada', 'liberadas', 'liberarem', 'liberasse', 'libere', 'licenca', 'lider', 'lideranca', 'life', 'ligadas', 'ligarem', 'light', 'limitante', 'limitou', 'limpas', 'listadas', 'listagem', 'listar', 'loading', 'log', 'logradouro', 'lojinha', 'lojistas', 'longes', 'lote', 'louco', 'love', 'm3rd', 'macarrao', 'macht', 'magicamente', 'maia', 'maiorias', 'maldosos', 'malucos', 'manchete', 'mandasse', 'maneiro', 'manipulacao', 'manteve', 'maozinha', 'marcava', 'mark', 'marmitex', 'marque', 'massiva', 'matando', 'mate', 'mato', 'max', 'mcdonald', 'mecanicas', 'mecanismos', 'mediacao', 'medicamentos', 'medico', 'mem', 'mencionado', 'menino', 'mensagen', 'mensager', 'menssagens', 'meramente', 'mero', 'messes', 'metch', 'meto', 'mexo', 'migo', 'migraram', 'mimo', 'mimos', 'minimizado', 'minoria', 'minutinhos', 'misero', 'misturados', 'miudas', 'mlhr', 'mnh', 'mnsg', 'mode', 'moderadores', 'modificando', 'moeda', 'moedinha', 'mole', 'molhos', 'money', 'monitora', 'montando', 'montao', 'morao', 'morar', 'morte', 'mortes', 'motiva', 'motivacao', 'motivoeu', 'motor', 'movimentos', 'msmo', 'mudada', 'mui', 'multiplas', 'mundiais', 'mundialmente', 'municipio', 'nadaeu', 'namorar', 'naquilo', 'nativo', 'naturalmente', 'navegadores', 'nazistas', 'nei', 'nescessario', 'nif', 'nobre', 'normalidade', 'normalizar', 'notado', 'notar', 'notificaram', 'notification', 'now', 'nr', 'obgda', 'ocorrencias', 'ofertado', 'oficiais', 'oito', 'olhou', 'olimpia', 'oneplus', 'oposta', 'optam', 'optamos', 'opto', 'orgulho', 'originalmente', 'oscilacao', 'outubro', 'pacientemente', 'packs', 'pagantes', 'pagara', 'painel', 'paixao', 'palma', 'palmas', 'parametros', 'parcelado', 'parcelas', 'parente', 'participam', 'particularidades', 'partilha', 'partilhar', 'passadas', 'passados', 'pato', 'pausam', 'pedacos', 'pedidomas', 'pegada', 'pegaram', 'peixe', 'penalidade', 'penalizados', 'pendencias', 'pensarem', 'perante', 'perceba', 'percebeu', 'perdas', 'perdesse', 'perguntarem', 'permitida', 'perseguicao', 'persistente', 'persistiu', 'personagem', 'pertinho', 'pertos', 'pesquise', 'pessoase', 'pet', 'pilantras', 'pioneiro', 'plagio', 'plicativo', 'polui', 'ponha', 'ponham', 'porcoes', 'porteiro', 'posicionar', 'possiblidade', 'postaram', 'precisarmos', 'predios', 'preferencial', 'preferidas', 'prendem', 'preocupados', 'preocupem', 'preparada', 'prepare', 'presas', 'preservar', 'pressao', 'pressionando', 'prestes', 'previamente', 'privar', 'privativo', 'problemae', 'problemapois', 'procurou', 'professores', 'proibida', 'proibidas', 'projetado', 'prometendo', 'proporcionam', 'proporcionou', 'propostas', 'propriedade', 'prossegue', 'protocolo', 'protocolos', 'proveito', 'proveitoso', 'pt', 'publi', 'publicadas', 'publicam', 'pus', 'puseram', 'qnt', 'qu', 'quado', 'qualificada', 'quebrados', 'queimando', 'quentinhas', 'queriamos', 'r10000', 'r15', 'r2500', 'r28', 'r4000', 'r5000', 'racistas', 'radical', 'rapaziada', 'rappiprime', 'rastreavel', 'razoavelmente', 'reabri', 'reagiu', 'realistas', 'realize', 'rebolando', 'recadastrar', 'reciclagem', 'reclamamos', 'recomendadas', 'recompensar', 'reconfigurar', 'reconhecendo', 'reconheco', 'recortar', 'recupera', 'recusarem', 'recuso', 'redefini', 'reduzi', 'reduzido', 'reduziu', 'refens', 'referentes', 'referida', 'reforco', 'reformular', 'registram', 'registrei', 'regularizar', 'reinstalo', 'relativo', 'religiosos', 'remetente', 'remove', 'removeu', 'rende', 'renovacao', 'renovar', 'reparacao', 'repetitiva', 'repetiu', 'reporta', 'reportado', 'reposto', 'representam', 'respeitando', 'respeitem', 'ressalto', 'restituido', 'resulta', 'resultou', 'resume', 'retirados', 'retire', 'retomar', 'retornando', 'retornavel', 'retrocesso', 'ribeirao', 'rigido', 'rigidos', 'roleta', 'rotacao', 'roxo', 'rts', 's20', 'sabedoria', 'sacolinha', 'safadeza', 'safado', 'sairia', 'sala', 'salas', 'salientar', 'salvamento', 'salvamos', 'satelite', 'satisfeitos', 'score', 'seca', 'seccao', 'segmentos', 'segredo', 'segurancas', 'selecionam', 'selecionarmos', 'seletividade', 'semanalmente', 'sensualizando', 'sensura', 'serventia', 'sextafeira', 'sexuais', 'sigam', 'significativas', 'significativo', 'silencia', 'silenciadas', 'silencioso', 'silva', 'simplemente', 'simultaneas', 'sinais', 'sinalizou', 'sincronismo', 'sinta', 'snapchat', 'sobrepoe', 'sobrepondo', 'sobreposicao', 'sobreposto', 'sobreviver', 'sobrinho', 'socializacao', 'socializar', 'sogra', 'solicitaram', 'solta', 'solteiro', 'solucionam', 'solucionou', 'sono', 'sorteios', 'sozinhas', 'space', 'spaces', 'splash', 'sr', 'star', 'storis', 'storyse', 'stream', 'studio', 'suave', 'subi', 'subido', 'subiram', 'substituto', 'subtotal', 'sucessivos', 'sufoco', 'sugar', 'sugeriu', 'sujar', 'sumia', 'suportando', 'suportes', 'supriu', 'surgiram', 'surja', 'surpreendendo', 'surpreendentemente', 'suspeitos', 'suspendeu', 'tab', 'tamben', 'tatica', 'taubate', 'taxado', 'tecnicamente', 'tecnicas', 'tecnologias', 'teleentrega', 'televisor', 'tens', 'teor', 'terapia', 'termica', 'terrivelmente', 'teus', 'themes', 'tic', 'tipico', 'tiraria', 'tirasse', 'titular', 'tivermos', 'tktk', 'tm', 'token', 'tokers', 'tolerar', 'tomadas', 'tomaram', 'torcendo', 'torcer', 'tornara', 'tornei', 'tornem', 'tosco', 'totalizando', 'touch', 'toxidade', 'trabalhador', 'trabalharem', 'traduzidas', 'traduzidos', 'traga', 'trajetos', 'trampo', 'transfere', 'transmito', 'tratativa', 'trate', 'trato', 'trending', 'trip', 'trm', 'troquem', 'tudooo', 'tumbnail', 'tweetes', 'twets', 'twittar', 'twitters', 'ui', 'ultrapassam', 'unidos', 'usala', 'usavam', 'usos', 'utilizadora', 'utilizamos', 'utilizaram', 'utilizasse', 'v', 'vacilo', 'vaga', 'validei', 'valioso', 'valorizado', 'vamo', 'vantajosa', 'variado', 'vasilhames', 'vaza', 'vegano', 'vegetarianos', 'velas', 'veloz', 'vencida', 'vendeu', 'verdades', 'verdes', 'verificam', 'vey', 'vezese', 'viaja', 'viajando', 'vibe', 'videochamada', 'vincula', 'virado', 'viraram', 'visivelmente', 'visualizam', 'visualizaram', 'visualizo', 'vitoria', 'vivi', 'voluntarios', 'votar', 'w', 'wallet', 'watsap', 'windows', 'x3', 'zerado', 'zerou', 'zonas', '00', '0030', '02', '0810', '1001', '100k', '103', '1080p60', '1090', '10h', '10mins', '10minutos', '1100', '1150', '115h', '1190', '127', '12eur', '1305', '13h', '13y', '1400', '1430', '14h', '15062022', '160', '1605', '171', '17h', '1830', '1930', '1988', '20000', '2004', '2005', '200k', '200mil', '2050', '20r', '2100', '2130', '2145', '21h', '21hs', '2205', '235', '2499', '24horas', '25min', '2999', '2o', '30000', '300ml', '340', '3400', '3490', '3990', '3k', '450', '4600', '460p', '49', '490', '4estrelas', '510', '5200', '56', '57', '5s', '6000', '601', '699', '720', '75', '750', '79', '7k', '8000', '8eur', '8h', '91', 'abaixaram', 'abandonados', 'abastecer', 'aborrecer', 'abreviar', 'abusados', 'acabara', 'acabarem', 'acada', 'acerca', 'acerta', 'acertado', 'acerto', 'acervo', 'acessala', 'acessalo', 'acidentes', 'acionado', 'acompanhamos', 'acompanhante', 'acompanhe', 'aconcelho', 'acontecimento', 'acordado', 'acordos', 'acreditam', 'acreditando', 'acreditei', 'acreditem', 'acrescentado', 'acrescentaria', 'actualizar', 'acusando', 'acusar', 'acustumei', 'adequados', 'aderido', 'adiantam', 'adiantando', 'adicionalo', 'adicionava', 'adivinhe', 'adivinhem', 'admira', 'admiro', 'admite', 'admito', 'advinha', 'advinhem', 'afasta', 'afastado', 'afetar', 'afeto', 'afinidades', 'afora', 'agoniada', 'agradaria', 'agradecem', 'agradecendo', 'agrega', 'agressivo', 'agressoes', 'agrupar', 'agt', 'aguardem', 'aguardou', 'aguentam', 'ahhh', 'aida', 'ajeitasse', 'ajudada', 'ajudasse', 'ajudassem', 'ajustada', 'alcoolica', 'aleatoriedade', 'alguna', 'aliado', 'aliais', 'alimentares', 'aliviado', 'almenta', 'alteralo', 'alterem', 'alternando', 'alternativos', 'altissima', 'altofalante', 'alturas', 'alugado', 'alugar', 'am', 'amais', 'amam', 'amassada', 'americana', 'americanas', 'americano', 'amg', 'amgs', 'amooo', 'amoroso', 'amou', 'ampliada', 'amstel', 'ana', 'analisado', 'analisam', 'anciosa', 'andado', 'andou', 'angola', 'animal', 'annuncios', 'antecipar', 'antonio', 'anunciada', 'anunciadas', 'anunciosmais', 'anunciou', 'aoarece', 'apagarem', 'apaguem', 'aparecese', 'aparecessem', 'apartamentos', 'apelacao', 'apelativo', 'apelido', 'aperfeicoamento', 'aperfeicoem', 'apertava', 'apice', 'aplicativosoftware', 'aplicavel', 'aplicavo', 'apoiam', 'apontava', 'appa', 'appgosto', 'apppois', 'apreciar', 'apresentada', 'aprimorado', 'aprontaram', 'apropriado', 'aprovando', 'aprovaram', 'aproveitado', 'aquisicao', 'arabes', 'argentina', 'arma', 'armazem', 'armazenado', 'armazenados', 'army', 'arquitetura', 'arquivadas', 'arrasada', 'arrastado', 'arrastando', 'arrasto', 'arrependida', 'arrependido', 'arriscado', 'arriscar', 'arroz', 'arrumen', 'arrumou', 'artes', 'artesanal', 'arvore', 'ass', 'assedio', 'assento', 'assinaria', 'assis', 'assistente', 'assistirmos', 'associadas', 'assume', 'assumir', 'astral', 'atacadao', 'ataques', 'atendiam', 'atentei', 'atinge', 'ativam', 'ativou', 'atrai', 'atrativa', 'atribuido', 'atts', 'au', 'audiencia', 'auditiva', 'aue', 'augumas', 'aumentos', 'autenticar', 'automacao', 'automovel', 'autoridades', 'autorizacoes', 'autorizadas', 'autorizados', 'autorizam', 'autorizando', 'autorizou', 'avaliada', 'avalialos', 'avaliam', 'avaliarmos', 'avaliasse', 'avariado', 'aveiro', 'aver', 'backups', 'bacon', 'bagaca', 'bagagem', 'baguncadas', 'baixalos', 'baixaram', 'baixissimo', 'balde', 'baloes', 'bancario', 'bandas', 'bandejas', 'bandido', 'banimentos', 'bao', 'barrada', 'barrar', 'barreto', 'barriga', 'barro', 'barzinho', 'baseadas', 'baseando', 'basear', 'baseia', 'bastava', 'bastou', 'batalha', 'batido', 'beats', 'bebo', 'beijinhos', 'bela', 'bemestar', 'bemeu', 'ben', 'bencao', 'bencaos', 'bernardo', 'bi', 'bicicletas', 'bilionaria', 'bizarras', 'bloqueasse', 'boatos', 'bobagem', 'bohemia', 'boi', 'bolos', 'boma', 'bome', 'bommuito', 'bomtem', 'bon', 'bonitinho', 'book', 'borrado', 'braba', 'brabo', 'brincar', 'broxante', 'bruna', 'bts', 'bugerro', 'bugo', 'bugues', 'bumble', 'bumerangue', 'burocracias', 'bus', 'buscador', 'busquem', 'buzina', 'cacar', 'caches', 'cadastrem', 'cadastrou', 'cadeirante', 'caes', 'calcinha', 'calcula', 'calculou', 'camada', 'caminha', 'cancelassem', 'cantada', 'cantando', 'canva', 'cao', 'capitais', 'capitalistas', 'capturas', 'carai', 'carentes', 'carissimas', 'carissimos', 'carnes', 'carregados', 'carregou', 'carta', 'cartas', 'casado', 'casar', 'casca', 'cashbacks', 'catchup', 'causados', 'cc', 'cega', 'censurar', 'centros', 'chamaram', 'chamase', 'chamativas', 'chao', 'chateacao', 'checagem', 'chiken', 'china', 'chines', 'chips', 'chique', 'chove', 'ciclista', 'cidadao', 'cim', 'cinquenta', 'cinta', 'cinto', 'citada', 'clips', 'cllrs', 'clonada', 'clonaram', 'cobertor', 'cobrindo', 'coco', 'coincidentemente', 'coisase', 'colalo', 'colando', 'colou', 'combina', 'combinam', 'combinando', 'combinei', 'comecamos', 'comecasse', 'comemoracao', 'comemos', 'comercialmente', 'comessa', 'cometem', 'cometeu', 'comeu', 'comia', 'compacto', 'comparacoes', 'comparo', 'compensam', 'competitivos', 'complementos', 'completando', 'completou', 'complicar', 'comprada', 'compraram', 'comprarmos', 'comprometendo', 'comprometido', 'computou', 'comta', 'comunistas', 'comunitario', 'conceitos', 'concentracao', 'concluia', 'concluo', 'concordam', 'concretizado', 'concretizar', 'condutas', 'conduzida', 'conectadas', 'conectividade', 'confeccao', 'confiamos', 'confiante', 'configura', 'confiram', 'confirmados', 'conflitos', 'confortaveis', 'confundir', 'conhecela', 'conhecesse', 'conivente', 'coniventes', 'conquistas', 'consecutivas', 'conseguirei', 'conseguiriamos', 'consertados', 'consertaram', 'consigui', 'consiste', 'consistencia', 'constancia', 'constavam', 'constrangimentos', 'consultor', 'consultoria', 'consumiu', 'contabilizar', 'contactalos', 'contae', 'contam', 'contanto', 'contase', 'contei', 'contendo', 'contenha', 'contentar', 'contento', 'contigo', 'continente', 'continuara', 'contornar', 'contradiz', 'contrata', 'contribuinte', 'conveniados', 'conversacao', 'conversava', 'conversou', 'convertendo', 'conviver', 'copacabana', 'copiados', 'coracaozinho', 'corno', 'corremos', 'correntes', 'corrigiam', 'corrigiu', 'cortaram', 'cortasse', 'cosegui', 'coupom', 'couro', 'credenciados', 'creditados', 'creme', 'cresca', 'crescam', 'cresci', 'criativas', 'criativos', 'criminosa', 'crises', 'cristao', 'criteriosa', 'criteriosos', 'crua', 'ctt', 'cuidem', 'cultos', 'cumpom', 'cumpons', 'cumprimento', 'cunho', 'cupoms', 'curiosamente', 'curiosidades', 'curiosos', 'cursor', 'custou', 'cv', 'cvs', 'dahora', 'danificado', 'danificados', 'dano', 'daora', 'darao', 'date', 'ddd', 'debitada', 'decadas', 'decepcaoo', 'decidindo', 'decifrar', 'declarar', 'declinio', 'decoracao', 'defasado', 'defendem', 'definitiva', 'deitar', 'deixada', 'deletados', 'deletou', 'deliberadamente', 'deliciosos', 'demandas', 'demasiada', 'demasiadamente', 'demoradas', 'demorarem', 'denunciada', 'denunciamos', 'denuncie', 'denv', 'deparar', 'dependesse', 'deppis', 'derramou', 'derrota', 'desabilitada', 'desabilite', 'desafio', 'desafixados', 'desamparado', 'desanimo', 'desapareceram', 'desastrosa', 'desatentos', 'desativacao', 'desconectando', 'desconfio', 'descontinho', 'descontrair', 'descrevi', 'desculpou', 'descumpri', 'descumprimento', 'desda', 'desembolsar', 'desempregada', 'desempregado', 'desenhado', 'desenvolve', 'desenvolverem', 'desenvolveu', 'desenvolvidores', 'desesperada', 'desestimula', 'desfazendo', 'desfeita', 'desfeito', 'desinstalava', 'desinstalou', 'desisntalando', 'desistalado', 'desistirem', 'desistiria', 'desistiu', 'desitalei', 'desleal', 'deslocacao', 'deslocado', 'deslogado', 'deslogando', 'desloquei', 'desmotivado', 'desonestas', 'despencou', 'despreziveis', 'desrespeitam', 'desrespeitando', 'destacam', 'destrair', 'destroi', 'destruicao', 'destruir', 'destruiram', 'desvantagens', 'desvantajoso', 'desviou', 'detestavel', 'diabo', 'diadema', 'difere', 'diferenciacao', 'dificilimo', 'digitou', 'diminuiu', 'dinhero', 'direcionamento', 'direcionando', 'dirige', 'discorda', 'discordar', 'discrepancia', 'discreta', 'discricao', 'discriminacao', 'discursos', 'discutindo', 'dispensada', 'disponha', 'disponibilizacao', 'dispor', 'distintas', 'distraido', 'ditadura', 'ditatorial', 'diverso', 'divertia', 'divertimento', 'dividido', 'divididos', 'divirta', 'divulgacoes', 'divulgados', 'doa', 'docerias', 'doentes', 'dog', 'doida', 'dom', 'dominio', 'dominos', 'dormi', 'dose', 'dourado', 'du', 'dum', 'duplicar', 'e6', 'eai', 'eas', 'ecran', 'edificio', 'edit1', 'editores', 'eeu', 'efetividade', 'efetuam', 'efim', 'ego', 'ein', 'elemento', 'elevador', 'elevar', 'eli', 'elimina', 'eliminado', 'eliminando', 'elogiei', 'embalada', 'emissao', 'emissora', 'emitem', 'emplementar', 'encaminha', 'encaminhado', 'encaminhamento', 'encaminhando', 'encaminhei', 'encaminhou', 'encantada', 'encerrem', 'encomendei', 'enderecoe', 'energetico', 'energias', 'enfase', 'enfeite', 'enganados', 'enganaram', 'enganos', 'enquadramento', 'entediante', 'entegador', 'entendam', 'entorno', 'entrarei', 'entrarmos', 'entregavam', 'entreguem', 'entrevista', 'enviarmos', 'envolvem', 'enxergo', 'epocas', 'equilibrar', 'equivocada', 'eroticas', 'escasso', 'escolhermos', 'escondidas', 'escreveram', 'escroto', 'escuros', 'esferas', 'esfriando', 'esgotados', 'esgoto', 'espalhar', 'espanto', 'espectativas', 'espectro', 'espeto', 'espirito', 'espressar', 'esquecermos', 'esquerdista', 'estabecimento', 'estabelecida', 'estariamos', 'estarmos', 'estatica', 'estelas', 'estender', 'esteticos', 'esticada', 'estima', 'estimacao', 'estimulo', 'estimulou', 'estiveram', 'estories', 'estornando', 'estornem', 'estory', 'estourar', 'estr', 'estragam', 'estrago', 'estranhei', 'estreia', 'estrelaso', 'estritamente', 'ests', 'estudado', 'estudante', 'estudantes', 'estupidas', 'europa', 'euros', 'eventualmente', 'evidencia', 'evidencias', 'excedeu', 'excessivas', 'exclusividade', 'executa', 'executo', 'exibem', 'exibindo', 'exigiu', 'existindo', 'existiram', 'existirem', 'existiu', 'expediente', 'expirados', 'explicada', 'explicadas', 'explicaram', 'explicitas', 'explora', 'exportar', 'expresso', 'extornar', 'extornaram', 'extorsao', 'extremo', 'extressante', 'fabricante', 'facamos', 'fachada', 'facilite', 'fadas', 'fais', 'faltado', 'family', 'fanta', 'fantasticas', 'fantasticos', 'faqs', 'farao', 'fardos', 'faremos', 'fascinante', 'faso', 'fassa', 'faturados', 'faturamento', 'favoritei', 'fazen', 'fazse', 'features', 'feijao', 'feriado', 'festas', 'ficao', 'ficarao', 'ficaremos', 'ficcao', 'fideliza', 'filmagens', 'filtrando', 'finalizam', 'finalizamos', 'fingindo', 'fingir', 'fingiu', 'fiq', 'fis', 'fix', 'fixadas', 'fixado', 'flores', 'floripa', 'fluindo', 'flutuante', 'fo', 'fogem', 'folga', 'follows', 'fones', 'footer', 'formatado', 'formularios', 'fornecida', 'fornecidas', 'fornecidos', 'fotografias', 'fotosmas', 'francisco', 'franco', 'fraquinho', 'fraudulento', 'frequentadores', 'fresca', 'fronteiras', 'frustada', 'frustradas', 'fuca', 'fugindo', 'fugiu', 'fulana', 'funcionabilidade', 'funcionare', 'funcionem', 'fundamento', 'funks', 'furado', 'futilidade', 'g7', 'gabriel', 'galinha', 'gata', 'geleia', 'generica', 'generico', 'generosos', 'gerada', 'geraria', 'gifts', 'gigantesco', 'gira', 'globais', 'globo', 'gostariam', 'gostasse', 'gostosa', 'gourmet', 'gramas', 'grandeza', 'gravava', 'gritando', 'grosseira', 'gruposcanais', 'guarapari', 'guardado', 'guarulhos', 'guinada', 'habib', 'habibis', 'habilitou', 'hackear', 'hackeou', 'hamburguers', 'happi', 'haters', 'havido', 'heteros', 'hipotese', 'histories', 'homossexual', 'horrendo', 'horrorosas', 'horrorosos', 'hortifruti', 'hot', 'houveram', 'http', 'humanizado', 'hut', 'hype', 'id', 'identificam', 'identificando', 'identificou', 'idoso', 'ifoodpois', 'ig', 'ignoradas', 'ignorante', 'igreja', 'iguacu', 'igualar', 'igualdade', 'ii', 'iludam', 'im', 'imagemvideo', 'imagensvideos', 'imaginem', 'imbecil', 'imediacoes', 'imensas', 'imitacao', 'impeca', 'impediu', 'implantar', 'implementacao', 'implementadas', 'implorando', 'importantissima', 'imposicao', 'impossibilitam', 'imposto', 'impressiona', 'impresso', 'imprudente', 'inacessiveis', 'inbox', 'incentivado', 'incentivando', 'incluirem', 'inclusa', 'inclusas', 'inclusos', 'incomodacao', 'incomodos', 'incomparavel', 'incompativel', 'incompreensivel', 'inconveniencia', 'incoveniente', 'inda', 'indicador', 'indicarei', 'inducao', 'ineficiencia', 'inevitavel', 'inexplicavelmente', 'infligir', 'influencers', 'influenciadores', 'informacoe', 'informamos', 'informem', 'ingual', 'iniciativas', 'iniciava', 'injustos', 'inocente', 'inovadora', 'inovando', 'insatisfatorio', 'insere', 'inseridos', 'insiram', 'insistente', 'instalada', 'instalaram', 'instalava', 'instantaneos', 'instituicao', 'insustentavel', 'intacta', 'integra', 'integrantes', 'integrar', 'intelectual', 'intencionadas', 'intencionalmente', 'intendo', 'intens', 'intenso', 'interagem', 'interessava', 'interfonar', 'internamente', 'internauta', 'interrompem', 'interrompidos', 'intervalos', 'intervencao', 'intimidade', 'intreterimento', 'introducao', 'invade', 'invadir', 'invadiu', 'invalidas', 'invasiva', 'inventem', 'investigada', 'investimentos', 'invista', 'ip', 'iris', 'irreais', 'irreal', 'irregularidades', 'is', 'isencao', 'isentando', 'iss', 'issomas', 'issoo', 'issopois', 'istalar', 'it', 'italico', 'j5', 'japa', 'jaquetas', 'jaumo', 'jogados', 'jornal', 'judiciais', 'julgamento', 'julgando', 'justificam', 'kawai', 'kawaii', 'kibe', 'kkkkkkkk', 'kms', 'krl', 'ksksks', 'lae', 'lag', 'lancam', 'lancando', 'lanchar', 'lar', 'lascar', 'latinhas', 'lava', 'legalmas', 'lembramos', 'lembrese', 'lentas', 'lerdeza', 'lerdos', 'lerem', 'lesando', 'levantar', 'liberal', 'liberassem', 'libertar', 'lidando', 'limao', 'list', 'litros', 'logadas', 'logando', 'loguin', 'lol', 'lorena', 'los', 'lota', 'loteria', 'lucas', 'lupinha', 'luva', 'luxo', 'm0rr3r', 'macdonalds', 'machista', 'macho', 'maes', 'magia', 'magica', 'mai', 'maionese', 'maisnao', 'maistem', 'malandro', 'mania', 'manipula', 'manipulado', 'mantemse', 'mantenha', 'mantenham', 'mantenhao', 'mapas', 'maquinas', 'maquineta', 'maraba', 'marcacoes', 'marcamos', 'marcaram', 'marcos', 'marilia', 'martirio', 'mass', 'mata', 'matche', 'materia', 'maz', 'mediano', 'mediocres', 'megas', 'melhoramento', 'melhorara', 'melhorasem', 'melhorei', 'melhorzinho', 'memorias', 'memorizar', 'menciona', 'mencionam', 'mendigando', 'meninos', 'meno', 'mentiu', 'mer', 'mera', 'mereceria', 'mereciam', 'merito', 'mesagem', 'metrica', 'mg', 'migalhas', 'migracao', 'migrado', 'milhas', 'militancia', 'minecraft', 'minimalista', 'minimizo', 'mins', 'minusculas', 'miseria', 'misturadas', 'miui', 'ml', 'mocas', 'moco', 'modal', 'modificados', 'moedinhas', 'moldura', 'monetizados', 'monetizando', 'monetizar', 'monitor', 'monitorado', 'monopolio', 'morreu', 'mostraria', 'mostro', 'motivacionais', 'motog', 'move', 'movendo', 'movido', 'mrd', 'mtt', 'mudavam', 'muiito', 'multi', 'multilaser', 'mural', 'muuuuuito', 'muuuuuuuito', 'nadaa', 'nadaaa', 'nadanao', 'nadinha', 'namorados', 'namorando', 'naoo', 'navego', 'necessitando', 'negligencia', 'negra', 'negro', 'neta', 'netos', 'network', 'never', 'next', 'nitidamente', 'noiva', 'nope', 'nostalgia', 'not', 'notando', 'notavel', 'notificam', 'noto', 'notorio', 'noutra', 'novatos', 'nove', 'novomais', 'nso', 'nua', 'nuggets', 'nulo', 'obrigadas', 'obrigatorias', 'obrigatorios', 'obrigou', 'obscenas', 'ocasiona', 'ocultando', 'ocultos', 'ocupam', 'odiar', 'ofende', 'oferecerem', 'ofertar', 'oficialmente', 'oie', 'oioi', 'oleo', 'olhaeu', 'olhao', 'olhassem', 'onix', 'operacionais', 'operacoes', 'operando', 'ops', 'opte', 'orcamento', 'ordens', 'orgao', 'orientais', 'ortografico', 'oscila', 'otimoo', 'otimoso', 'ouco', 'ouvidos', 'ouvimos', 'ouviram', 'padronizacao', 'paes', 'page', 'pagode', 'panificadora', 'paragem', 'paralelas', 'parcelada', 'parciais', 'pareado', 'parque', 'parti', 'participava', 'partido', 'partiu', 'passaporte', 'passara', 'passarei', 'passarinho', 'passouse', 'pastagens', 'patamar', 'patrocinado', 'pausando', 'pcd', 'pecimo', 'pedagio', 'pedidoo', 'pedidosendo', 'pedofilos', 'pefeito', 'pegado', 'pegarem', 'peguem', 'peido', 'pelamor', 'peleja', 'pelomenos', 'peneirar', 'pensada', 'pensaram', 'penultimo', 'pepino', 'percorrer', 'percursos', 'perdao', 'perdese', 'pereira', 'perguntado', 'periodicamente', 'permaneceu', 'permanencia', 'permitirem', 'pesam', 'pesos', 'pesquisado', 'pesquisava', 'pessoaa', 'petisco', 'pfvvv', 'pg', 'piedade', 'pin', 'pinca', 'pioraram', 'pioro', 'pip', 'pir', 'piso', 'place', 'planeja', 'plantaforma', 'plantas', 'players', 'plobema', 'ploblema', 'pneu', 'png', 'podeira', 'poderosa', 'pofavo', 'pontaaponta', 'pontuacoes', 'porcao', 'pork', 'pornograficos', 'porqur', 'porr4', 'portador', 'portas', 'portuguesa', 'posicionados', 'posicoes', 'possibilitou', 'possuindo', 'postarmos', 'postas', 'postassem', 'posteriores', 'poupanca', 'pp', 'praga', 'prata', 'praticando', 'precisamente', 'precisara', 'precisavam', 'precisem', 'preconceitos', 'preenchi', 'prefeitura', 'prego', 'preguicosos', 'prejudicasse', 'prejudique', 'premiacoes', 'premissa', 'prende', 'prender', 'preocupou', 'preparadas', 'preparou', 'prescisa', 'presenciais', 'pressas', 'pressionado', 'presto', 'prever', 'pricipalmente', 'primitivo', 'printar', 'prioridades', 'prioriza', 'priva', 'privilegiar', 'privilegios', 'problemaeu', 'problematica', 'problematicos', 'procom', 'procure', 'produtiva', 'produtividade', 'produtores', 'produz', 'profundamente', 'promessas', 'prometeu', 'pronunciar', 'propio', 'propoem', 'proporcional', 'propositadamente', 'propriamente', 'prostituta', 'protegido', 'protesto', 'provei', 'proxy', 'prudente', 'psicologico', 'publicada', 'puderam', 'pulou', 'punidos', 'putz', 'qnto', 'quadrada', 'quadrados', 'qualificacoes', 'qualificado', 'qualificar', 'quanta', 'quebram', 'queima', 'queimado', 'quele', 'quentinhos', 'queres', 'querida', 'questionamento', 'questionamentos', 'questionando', 'questionario', 'queto', 'quinto', 'quizer', 'quw', 'r1', 'r1200', 'r1500', 'r25', 'r35', 'r50', 'r500', 'rabo', 'raca', 'racao', 'raciocinio', 'raios', 'raiz', 'ramos', 'rap', 'rapazes', 'rapidao', 'rapidomas', 'raridade', 'rarissimas', 'rasa', 'rasgada', 'rastreado', 'rastreados', 'rastreia', 'reabrindo', 'reaise', 'reajuste', 'realizamos', 'rebaixar', 'recadastrei', 'recebelo', 'recebera', 'reclamado', 'reclamarem', 'recolocar', 'recomeca', 'recomendei', 'reconectar', 'reconhecem', 'reconhecida', 'reconhecidos', 'record', 'recorde', 'recorri', 'recuperalo', 'red', 'reduzidas', 'reduziram', 'reembolsem', 'reenbolso', 'reencontrar', 'reencontrei', 'referencias', 'referido', 'referindo', 'refinada', 'reforcando', 'reforcar', 'reformulacao', 'refresh', 'regressao', 'reiniciou', 'reinstala', 'reinstalalo', 'reis', 'rejeitam', 'rejeitar', 'rejeitou', 'relaxar', 'reler', 'relevar', 'relogar', 'remoto', 'removela', 'removida', 'remunerados', 'reparos', 'repassou', 'repentina', 'repentinamente', 'repeticao', 'replica', 'reportagem', 'reportando', 'representantes', 'republica', 'reputacao', 'requisicao', 'reseta', 'resetando', 'resgatados', 'residencial', 'resolucoes', 'respectivos', 'respondesse', 'respondidos', 'ressarcidos', 'restaurei', 'restritos', 'resumidamente', 'retencao', 'retiralo', 'retornava', 'retorne', 'retornos', 'retratar', 'retrato', 'retroceder', 'revelia', 'reverem', 'revertam', 'revise', 'revisei', 'revistas', 'rezar', 'ridiculamente', 'rigida', 'rigidas', 'rigorosa', 'risos', 'robotico', 'robux', 'rocha', 'rodape', 'rodizio', 'rogerio', 'rolamento', 'role', 'roteador', 'roubalheira', 'rsrsrsrs', 'ru', 'rui', 's10', 's20fe', 's9', 'sa', 'saberemos', 'saberiamos', 'saborear', 'saborosa', 'saidas', 'salao', 'salgada', 'salgadinho', 'salto', 'salvaram', 'saques', 'saturados', 'saudade', 'saudaveis', 'save', 'script', 'secreta', 'seguiu', 'segundaria', 'sejamos', 'selecionem', 'selecionou', 'seletiva', 'seletivos', 'self', 'sensibilidade', 'serra', 'sertanejo', 'serto', 'servido', 'setas', 'shoopers', 'shows', 'significativamente', 'silenciados', 'silhueta', 'sima', 'simbolos', 'simulacoes', 'sinceros', 'sincroniza', 'sintonia', 'skype', 'slk', 'slogan', 'smpr', 'sobrar', 'sobrecarregar', 'sobrepostos', 'sofreu', 'sofrido', 'sofrimento', 'softs', 'solicitante', 'solicitos', 'solitacao', 'solo', 'solto', 'solucionarem', 'solucione', 'somado', 'sonhos', 'sonoro', 'soubessem', 'start', 'statusstorys', 'sticks', 'stikers', 'strogonoff', 'suaves', 'subo', 'subpasta', 'subs', 'substituem', 'substituicoes', 'substituida', 'substituiram', 'sucedida', 'sucedido', 'sucessivamente', 'sucessivas', 'sugerida', 'sugeridos', 'sugeriria', 'sujando', 'sumiam', 'supor', 'supostas', 'suprido', 'suprir', 'surra', 'susto', 'suzano', 'tabela', 'tabem', 'tai', 'talento', 'talentos', 'talves', 'talz', 'tamo', 'tampa', 'tan', 'taptap', 'tar', 'tardeeu', 'tartaruga', 'taxistas', 'teclar', 'teko', 'telefonicas', 'telefonicos', 'telemoveis', 'temho', 'temperada', 'temperos', 'tempoeu', 'temporaria', 'tendencioso', 'tendeu', 'tenebroso', 'tenque', 'tentassem', 'territorio', 'testo', 'teto', 'textura', 'this', 'tickets', 'tikbonus', 'tiket', 'tiktokmas', 'timeout', 'timer', 'tindermas', 'tir3', 'tir4', 'tiradas', 'tiramos', 'tlgd', 'tocantins', 'toppp', 'tops', 'toquei', 'torcam', 'torpedo', 'torre', 'tortura', 'tosca', 'trabalhado', 'trabalhamos', 'trabalhao', 'tracas', 'tracking', 'traco', 'traduzida', 'traduzido', 'tranferir', 'tranquilas', 'transexual', 'transfobico', 'transformou', 'transmite', 'transmitem', 'transportador', 'tratados', 'tratase', 'tratou', 'treinar', 'trendings', 'trigo', 'trincando', 'trocada', 'tts', 'tudoe', 'tumb', 'tvs', 'tweetada', 'tweeter', 'twitch', 'twite', 'twites', 'twitte', 'tx', 'uberlandia', 'ubermas', 'ucrania', 'ultilizando', 'una', 'unmatch', 'uno', 'upar', 'urbano', 'usarmos', 'usassem', 'usavel', 'usso', 'usuarias', 'utensilios', 'utilizavel', 'utilizou', 'uxp383349', 'vago', 'valerefeicao', 'validada', 'validou', 'valorizam', 'vanessa', 'variando', 'vasilhame', 'vazando', 'vd', 'vegetarianas', 'vela', 'velos', 'vence', 'venceu', 'vendia', 'verbalmente', 'verduras', 'veremos', 'veria', 'veridico', 'versatilidade', 'vezesmas', 'viagen', 'viajei', 'viajens', 'vias', 'vicia', 'videoconferencia', 'videoe', 'videoeu', 'videoisso', 'videosmas', 'videoso', 'vidros', 'vierem', 'vies', 'vinda', 'vinham', 'violava', 'violento', 'violou', 'viralizou', 'virtualmente', 'visam', 'visiada', 'visor', 'vissem', 'visualizados', 'visualizamos', 'vitimas', 'vizinhanca', 'vizualizar', 'voceis', 'volei', 'voltamos', 'voltaria', 'vom', 'vontades', 'vossos', 'vpn', 'vrs', 'vulneravel', 'whatssap', 'whtsapp', 'wors', 'wrong', 'xingado', 'xingamentos', 'xingando', 'xingar', 'xp', 'xxx', 'yts', 'z', 'zerada', 'zerando', '00h', '0106', '0200', '03', '0400', '050', '0502', '0606', '07', '07032022', '0805', '0905', '0906', '0908', '1000x', '10052022', '1006', '10062022', '101', '10hs', '1112', '11h', '11h40', '1210', '12112019', '1250', '12hs', '13052022', '1406', '140eur', '140p', '15000', '1503', '1520', '1560eur', '15s', '15x', '165', '170', '175x', '190', '1946', '1952', '1999', '1h20', '1h30min', '1min', '200000', '202', '2045', '20s', '21032022', '2141', '2149', '218', '21h45', '220422', '22062022', '2215', '2250', '2299', '22h30', '230', '2305', '2350', '2404', '240p', '2412', '2490', '2492', '2503', '2505', '26052022', '269', '2701', '270622', '280', '29k', '2l', '2minutos', '2quando', '2x1', '3001', '3009', '30s', '310', '3101', '3200', '3334', '336', '345', '3492', '360deg', '364', '380', '3800', '39', '395', '3o', '4050', '41', '430', '4410', '444', '4490', '45min', '47', '48hs', '495', '4990', '4a', '4h', '4mcchicken', '4o', '500mil', '52', '53eur', '5400', '58', '5a', '5deg', '5h', '62', '69', '690', '6deg', '6h', '7075', '72hrs', '74', '7500', '769', '87', '895', '899', '9000', '916', '92', '94', '99fod', '9h', 'a01', 'a10s', 'a12', 'a30s', 'a31', 'a32', 'a51', 'a7', 'a71', 'aaah', 'aap', 'abacaxi', 'abaixada', 'abaixado', 'abaixando', 'abaixarem', 'abaixe', 'abaixou', 'abandonam', 'abare', 'abatido', 'abatimento', 'abencoado', 'abertamente', 'abilitar', 'abismado', 'abisurdo', 'abordado', 'abordagem', 'aborrecendo', 'aborrecida', 'aborrecido', 'abrefecha', 'abrirem', 'abrirquando', 'abrisse', 'abs', 'absolvido', 'abstem', 'abusa', 'abusado', 'abusam', 'acabava', 'academia', 'acalmar', 'acarretando', 'acc', 'aceitamos', 'acentos', 'acertarem', 'acertei', 'acertivo', 'acertou', 'acessadas', 'acessamos', 'acessare', 'acessarem', 'acessoria', 'acessou', 'achalo', 'achem', 'acidental', 'acionam', 'acionamento', 'aciono', 'acionou', 'acolhedor', 'acolhida', 'acompanhados', 'acompanhasse', 'aconselhou', 'aconta', 'acorda', 'acostumadas', 'acredite', 'acresce', 'acrescentasse', 'acrescentei', 'acrescento', 'acrescentou', 'acumulei', 'acumulo', 'acusaram', 'adapta', 'adaptacoes', 'adaptado', 'adaptei', 'adblocker', 'adendo', 'adepta', 'aderencia', 'aderentes', 'aderi', 'aderirem', 'adesivos', 'adiada', 'adicionavam', 'adjetivos', 'administradora', 'admins', 'admirar', 'admitir', 'adoramos', 'adotar', 'adulta', 'advertir', 'advogado', 'advogados', 'aeroportos', 'afastam', 'afastar', 'afastei', 'afetam', 'affff', 'afffffff', 'afirmam', 'afirmo', 'aflicao', 'afronta', 'afs', 'ageis', 'ageita', 'ageitar', 'agencias', 'agendando', 'agilizando', 'agnt', 'agradeci', 'agradecidos', 'agravar', 'agregam', 'agressao', 'agressiva', 'agressivas', 'agressor', 'agrupados', 'aguado', 'aguardam', 'aguas', 'agudos', 'aguentamos', 'ahh', 'aiai', 'aifoood', 'aipor', 'air', 'ais', 'ajam', 'ajeitassem', 'ajudame', 'ajudariam', 'ajudavam', 'ajudinha', 'ajusta', 'ajustadas', 'al', 'alavancar', 'alcanca', 'alcancasse', 'alcoolico', 'aleatory', 'alergia', 'alergias', 'alergico', 'alface', 'alfinete', 'algunas', 'alheia', 'alheias', 'alinhadas', 'all', 'almas', 'almenos', 'alocacao', 'alteradas', 'alterava', 'altere', 'alterna', 'altomaticamente', 'altomatico', 'altualizacao', 'alves', 'alvo', 'amado', 'amadora', 'amadoras', 'amantes', 'amaram', 'amarelos', 'amassado', 'amassar', 'amazon', 'ambiental', 'amem', 'amizadese', 'amorosos', 'amostra', 'amparar', 'amparo', 'amplas', 'ampliando', 'amplie', 'amplos', 'amr', 'an', 'analfabetos', 'analisa', 'analisando', 'analisaram', 'analisarem', 'analisem', 'anciedade', 'andava', 'androide', 'anexada', 'anexados', 'anexando', 'anexei', 'anexos', 'angariar', 'angustiante', 'anima', 'anitta', 'anjinho', 'anjos', 'anonimos', 'anormal', 'anose', 'anotar', 'anotei', 'anotem', 'anseios', 'ansia', 'antarctica', 'anteontem', 'anterio', 'antietico', 'antipatico', 'anula', 'anunciante', 'anuncioe', 'anunciose', 'anunciosfica', 'anything', 'aovivo', 'apagala', 'apagaram', 'apagasse', 'apaixonar', 'apanhei', 'aparace', 'aparecemdo', 'apareco', 'aparem', 'aparentando', 'apcao', 'apelativa', 'aperfeicoado', 'aperitivos', 'apertarmos', 'apicativo', 'apitando', 'apks', 'apl', 'aplicalos', 'aplicativoalem', 'aplicativoas', 'aplicativoeu', 'aplicativomuito', 'aplicativonao', 'aplicativoo', 'aplicativopor', 'aplicativoporem', 'aplicativoquando', 'aplicativoque', 'aplicativorede', 'aplicativoservico', 'aplicativotenho', 'aplicativovoce', 'apliquem', 'aplivativo', 'aplocativo', 'apoiado', 'apoiem', 'apologia', 'aponta', 'apontados', 'apontou', 'aposentadoria', 'apostam', 'appacho', 'appde', 'appele', 'appentao', 'appficou', 'appfiz', 'appo', 'apppara', 'appque', 'appse', 'appseria', 'apreciei', 'apreensiva', 'aprenda', 'aprendeu', 'aprendizagem', 'apresar', 'apresento', 'apricativo', 'aprimorada', 'aprofundar', 'aprovam', 'aprovava', 'aproveitada', 'aproveitaram', 'aproximadas', 'aqles', 'aquario', 'aque', 'aquecendo', 'aquem', 'aquivos', 'arabe', 'aracaju', 'aranha', 'arbitrariamente', 'areia', 'argumentar', 'argumentos', 'armadilhas', 'armazena', 'armazenando', 'arquitetos', 'arrasaram', 'arrastamos', 'arrastava', 'arrecadacao', 'arredores', 'arrisquei', 'arroba', 'arrombado', 'arrumada', 'arumem', 'asa', 'asim', 'asisti', 'assado', 'assaltada', 'assalto', 'assegurando', 'assesiveis', 'assimeu', 'assimmais', 'assimnao', 'assinamos', 'assinava', 'assinou', 'assistamos', 'assistilo', 'assistiram', 'assistirem', 'assiti', 'associar', 'assuma', 'assumiu', 'assustado', 'assustador', 'assustadora', 'assustadoras', 'assustar', 'astronomicos', 'asus', 'at', 'ata', 'atacado', 'atem', 'atentam', 'atingindo', 'atipico', 'ativados', 'ativalo', 'ative', 'atracao', 'atraindo', 'atrapalhado', 'atrapalhan', 'atrasem', 'atrelada', 'atribui', 'atributos', 'atropelou', 'atuacoes', 'atualisacao', 'atualizacaes', 'atualizacaoagora', 'atualizacaoisso', 'atualizao', 'atualizasse', 'atuante', 'aturar', 'audacia', 'auditivos', 'auditores', 'auge', 'aumentassem', 'autenticos', 'autentificacao', 'authenticator', 'autista', 'autocarro', 'autodestruir', 'automaticos', 'autoral', 'auxiliado', 'auxiliando', 'avacalhando', 'avacalhar', 'avaliamos', 'avaliaram', 'avaliarei', 'avalie', 'avancando', 'avancava', 'avenidas', 'aventurar', 'aventuras', 'avisada', 'avisadas', 'avisasse', 'avise', 'avista', 'avoce', 'avontade', 'avonteceu', 'avulsos', 'away', 'azarada', 'azeitona', 'b0st', 'b0sta', 'ba', 'baboseiras', 'backend', 'baconese', 'bad', 'bagageiro', 'bags', 'bagulho', 'baile', 'baladas', 'balaozinho', 'balinha', 'banais', 'banal', 'bancando', 'bancar', 'bandidos', 'banidaeu', 'banio', 'banissem', 'banquete', 'banrisul', 'baratinha', 'baratinho', 'barbara', 'barram', 'barreira', 'barueri', 'baseada', 'baseandose', 'baseiase', 'bastos', 'bata', 'batesse', 'batia', 'batom', 'bct', 'beba', 'bebendo', 'because', 'beeeeem', 'beeem', 'beer', 'bei', 'beijao', 'belas', 'belezura', 'bemvindo', 'beneficie', 'benefico', 'bens', 'betas', 'bibisfira', 'bilhoes', 'bilhonario', 'bilionario', 'bino', 'biquine', 'biscoito', 'bissexual', 'bizarra', 'blefando', 'blogueiras', 'blogueiros', 'bloqueiou', 'bloqueram', 'bloquiei', 'blumenau', 'blur', 'boaa', 'bog', 'boicota', 'boicotar', 'bolsos', 'bomagora', 'bombam', 'bombando', 'bombardeio', 'bombom', 'bomesta', 'bomestou', 'bomisso', 'bommm', 'bommmm', 'bomos', 'bompoderia', 'bompq', 'bomse', 'bomsuper', 'bondade', 'boneco', 'boomerag', 'boomerangs', 'bordas', 'borradas', 'boss', 'botado', 'botaozinho', 'botaram', 'botas', 'botasse', 'bote', 'botou', 'bou', 'boulevard', 'bracos', 'braga', 'brasa', 'bravos', 'brechas', 'brenda', 'brevemente', 'brigado', 'brimcar', 'brinca', 'brincadeiras', 'brinquedos', 'bronca', 'broqueado', 'broqueiam', 'brutal', 'brutalmente', 'bsb', 'bugaro', 'bugse', 'buguis', 'bullying', 'buques', 'burgue', 'burlar', 'burros', 'buscada', 'but', 'buzinou', 'c6', 'cabecalho', 'cabecas', 'cabelos', 'cabem', 'cabendo', 'cabia', 'cacando', 'cacaniquel', 'cachee', 'cachorros', 'cadeiras', 'cagando', 'cagou', 'caiba', 'cairia', 'calabresa', 'caladas', 'calao', 'calca', 'calculos', 'calda', 'caldas', 'california', 'camara', 'camarada', 'campinassp', 'canaise', 'canalhas', 'canc', 'cancelare', 'cancelaria', 'cancelariam', 'canja', 'cansativa', 'canseira', 'cansela', 'canselou', 'cantar', 'cantareira', 'capacetes', 'capacitacao', 'capacitadas', 'capitalista', 'capitulos', 'captados', 'captar', 'caption', 'capturar', 'car', 'caraca', 'caracas', 'caracter', 'caractere', 'caracterizar', 'caral', 'caramelo', 'cardboard', 'cargo', 'carismatica', 'carnaval', 'carregadas', 'carregavam', 'carrego', 'carreguei', 'carretos', 'carrinhos', 'carroca', 'carteirinha', 'casadepois', 'cascos', 'casei', 'caseira', 'casquinha', 'castelo', 'castigo', 'casualmente', 'catar', 'cativa', 'caxias', 'cdigo', 'cebolas', 'celebridade', 'celebridades', 'celere', 'celo', 'celuar', 'celularmas', 'cenoura', 'censor', 'centers', 'centido', 'centralizacao', 'centralizar', 'ceo', 'ceps', 'cereja', 'certinha', 'certissimo', 'ces', 'cez', 'cg', 'cha', 'chamaria', 'chamativo', 'chamativos', 'change', 'charlie', 'charme', 'chatao', 'chatbot', 'chatinho', 'chatisse', 'chatoo', 'chaves', 'checadores', 'check', 'checkbox', 'cheeseburguer', 'chefao', 'chevrolet', 'chineses', 'chocada', 'chorar', 'chorei', 'chorone', 'cia', 'ciclismo', 'cido', 'ciencias', 'cientifico', 'cintura', 'cinzas', 'circuito', 'circulacao', 'circulando', 'circulos', 'circunstancia', 'cirrose', 'cis', 'citadas', 'citados', 'civil', 'classic', 'classicas', 'classificacoes', 'classificados', 'clic', 'clicou', 'clientea', 'clientenao', 'clonar', 'clr', 'clubes', 'cnpj', 'coberta', 'cobrandome', 'cobrassem', 'cobria', 'cobriu', 'codashop', 'coerentes', 'coincide', 'coincidem', 'coisaa', 'coisae', 'coisaquando', 'coisasmais', 'coisasnao', 'coisaspor', 'coitadas', 'colaborado', 'colada', 'colado', 'colecionar', 'coletar', 'coletivo', 'coletivos', 'colo', 'colocarei', 'colocarmos', 'colocase', 'coloquemos', 'colorado', 'coloridas', 'coloridos', 'coluna', 'coma', 'comam', 'combate', 'combater', 'comboio', 'combram', 'comecava', 'coment', 'comentamos', 'comentaram', 'comentarem', 'comermos', 'cometa', 'cometam', 'cometario', 'cometarios', 'cometendo', 'cometido', 'comido', 'comissao', 'comparamos', 'comparei', 'compartilhacao', 'compensado', 'compensou', 'completado', 'complexas', 'complexidade', 'complexos', 'complicados', 'complicando', 'complicou', 'componente', 'componentes', 'comportam', 'comportando', 'compostos', 'compradores', 'compreendam', 'compreende', 'compreensiveis', 'compremos', 'compressao', 'compreto', 'comprir', 'comprometam', 'comprometese', 'compromissadas', 'comprovado', 'comprovam', 'computacao', 'computar', 'comsegui', 'comunica', 'comunicador', 'comunicamos', 'comunicao', 'comunicavam', 'comuniquei', 'comunista', 'concede', 'concedida', 'conceitual', 'concentrar', 'concertam', 'concertaram', 'concertasse', 'concertassem', 'concigo', 'concluidas', 'conclusoes', 'concordando', 'concreto', 'concursos', 'condicionamento', 'conduz', 'coneccao', 'conectava', 'conecte', 'conectei', 'conferido', 'conferindo', 'confiado', 'confiando', 'configurada', 'configuradas', 'configurados', 'configure', 'confinamento', 'confins', 'confirmae', 'confirmaria', 'confundi', 'confundiu', 'congelador', 'conhecam', 'conhecelas', 'conheciamos', 'conprei', 'conquistou', 'consagrados', 'consecutiva', 'consecutivo', 'conseguese', 'conseguiam', 'conseguissem', 'conselhos', 'consenso', 'consertava', 'conserteza', 'consideracoes', 'considerados', 'considerava', 'considerou', 'consoante', 'constado', 'constasse', 'constata', 'constatando', 'constrangida', 'construtivo', 'consultando', 'consultas', 'consultei', 'consumidorgov', 'contabilizado', 'contamas', 'contantes', 'contaperfil', 'contatado', 'contatou', 'contemporaneo', 'contenham', 'conteudoja', 'contidos', 'continha', 'continuaram', 'continuaria', 'continuas', 'continuasse', 'continui', 'contiodos', 'contradizendo', 'contramao', 'contraste', 'contratado', 'contratados', 'contrataram', 'contratou', 'contribuem', 'contribuindo', 'control', 'controlam', 'controlando', 'controlo', 'convem', 'conveniado', 'conversado', 'conversamos', 'conversem', 'converssa', 'convertido', 'conviccao', 'coo', 'cookies', 'cool', 'coordenadas', 'copiam', 'copiaram', 'copias', 'copiei', 'copiou', 'coracaozin', 'cordialidade', 'coreano', 'coreanos', 'corredores', 'correlacao', 'correram', 'corria', 'corrigam', 'corriqueiramente', 'corriqueiros', 'corro', 'corrogir', 'corrompido', 'corrupto', 'corruptos', 'cortidas', 'costa', 'couber', 'coupon', 'covardes', 'covardia', 'coveres', 'coxinha', 'coxinhas', 'cpom', 'cravar', 'crescente', 'cresceria', 'crescido', 'cretina', 'cretinas', 'criativa', 'criatividades', 'criminoso', 'criptografada', 'cris', 'cristal', 'cristo', 'criterioso', 'criticam', 'criticando', 'critiquei', 'cropped', 'crtz', 'cruciais', 'crucial', 'cruz', 'cruzes', 'cueca', 'cuidadosamente', 'cujos', 'culpar', 'culpom', 'culpou', 'cumpri', 'cumpria', 'cumpridos', 'cumprimentos', 'cupido', 'cupum', 'curar', 'curtam', 'curva', 'custas', 'customizacoes', 'dae', 'dame', 'danado', 'dance', 'danem', 'danese', 'danificando', 'danificar', 'darkmode', 'darmos', 'datado', 'dboa', 'dc', 'dd', 'debaixo', 'debate', 'debates', 'debitados', 'debora', 'decai', 'decaido', 'decepcionam', 'decepcionamos', 'decepcionantes', 'decepcione', 'decidiram', 'declinando', 'decoracoes', 'decorrencia', 'dedicam', 'dediquei', 'defeituoso', 'deferente', 'definem', 'defini', 'definicoes', 'definida', 'definidos', 'degradante', 'deitada', 'deitado', 'deitaram', 'deivid', 'deixados', 'deixala', 'deixandoo', 'deixara', 'deixariam', 'deixarme', 'deixavam', 'deleso', 'deletaram', 'delete', 'delicada', 'deliciar', 'delicias', 'deliveri', 'demasiados', 'deminui', 'demitam', 'democracia', 'demonios', 'demonstrou', 'demoraria', 'demos', 'densistalei', 'denunciadas', 'denuncialo', 'denunciava', 'denunciou', 'departamento', 'dependa', 'dependemos', 'dependente', 'dependera', 'depositei', 'depressa', 'dera', 'derepente', 'derivado', 'derramando', 'derrubado', 'derrubados', 'derrubando', 'derrubaram', 'derrubou', 'desabilita', 'desabone', 'desagrado', 'desagradou', 'desanimam', 'desanimou', 'desaparecerem', 'desapontados', 'desativadas', 'desatualizadas', 'desbloqueado', 'desbugar', 'descabida', 'descadastrar', 'descansar', 'descanse', 'descaradamente', 'descarregar', 'descartado', 'descentralizacao', 'descepcionada', 'descoberta', 'descobertas', 'desconectaram', 'desconectei', 'desconfiei', 'desconfigurou', 'desconfortante', 'desconfortaveis', 'desconhecia', 'desconsiderado', 'desconsiderando', 'desconsiderar', 'descontava', 'descontoeu', 'descontraida', 'descontroladamente', 'descrevendo', 'descritos', 'descurte', 'descurtir', 'desejados', 'desejando', 'desejos', 'deselegante', 'desempenhar', 'desemprego', 'desenrolar', 'desentendidos', 'desenvolvedora', 'desenvolvedore', 'desenvolvem', 'desenvolvendo', 'desenvolveres', 'desenvolvida', 'desesperadamente', 'desesperadas', 'desesperei', 'desestala', 'desfavor', 'desfavorece', 'desfecho', 'desfrutando', 'desgastes', 'desgostando', 'desgracado', 'desgracados', 'designar', 'designers', 'desigual', 'desigualdade', 'desilusao', 'desinformar', 'desinscrever', 'desinstalase', 'desintalando', 'desintalar', 'desinteressantes', 'desistoo', 'deslaique', 'desleixados', 'desligava', 'desligue', 'desloca', 'deslocando', 'deslogada', 'desmarcam', 'desmarcou', 'desmotiva', 'desmotivador', 'desmotivadora', 'desobedece', 'desocupado', 'desonesta', 'desorganizacao', 'desorganizada', 'desorganizados', 'despausar', 'despenca', 'despertar', 'despesas', 'despreparado', 'despreparo', 'desprezivel', 'desprezo', 'desproporcional', 'desrespeitada', 'desrespeitado', 'desrespeitei', 'desrespeitosa', 'desservico', 'destacados', 'destacando', 'destinados', 'destribui', 'destribuidor', 'destrocar', 'desvaloriza', 'desviam', 'desviando', 'detecta', 'detectando', 'detectei', 'deteriorou', 'determina', 'determinamos', 'determinar', 'detestou', 'detona', 'detrizes', 'devedor', 'deviamos', 'devolta', 'devolutiva', 'devolvesse', 'df', 'diabos', 'diahoje', 'dianteira', 'diferenciam', 'dificultado', 'dificultaram', 'dificultoso', 'digitada', 'digitalizacao', 'digitamos', 'digite', 'digna', 'dignas', 'dilema', 'dim', 'dimensao', 'dimensoes', 'diminuirem', 'diminuiria', 'diminuta', 'din', 'dinamicos', 'dindin', 'dinheiromas', 'dinheironao', 'dinovo', 'direcionadas', 'direcionava', 'direcionou', 'directamente', 'direitoe', 'dirigiu', 'discreto', 'discretos', 'discriminada', 'discussoes', 'discutir', 'diser', 'disfrutar', 'disfuncional', 'disgraca', 'disparidade', 'dispensa', 'disser', 'dissopor', 'distanciamento', 'distanciando', 'distinta', 'distorcao', 'distraindo', 'ditado', 'ditar', 'divergente', 'diversidades', 'diversificacao', 'diversificar', 'divia', 'diviam', 'dividiu', 'divisa', 'divulgadas', 'divulgou', 'divulguem', 'dizerem', 'doacoes', 'doar', 'doblo', 'dobrados', 'documentarios', 'doenca', 'doer', 'doidos', 'dolares', 'dominar', 'dongle', 'donwload', 'dorama', 'doro', 'doutor', 'downgrade', 'dpois', 'drama', 'drastica', 'driblando', 'driver', 'drogados', 'drogaria', 'dsclp', 'dsd', 'dual', 'dublados', 'dublagem', 'dublar', 'duetar', 'duetos', 'duolingo', 'duplicadas', 'duplicaram', 'duvidosa', 'duvidosos', 'dvd', 'dx', 'e7', 'eais', 'eco', 'edge', 'editada', 'editadas', 'editarei', 'editavel', 'educar', 'educativo', 'ee', 'efectuei', 'efetiva', 'efetuamos', 'efetuo', 'elaboracao', 'elaborar', 'elaborarem', 'eleele', 'eleeu', 'elegancia', 'elegiveis', 'elemas', 'eletista', 'eletrico', 'eletronicos', 'eliminaram', 'elite', 'elitista', 'elogia', 'emais', 'embacadas', 'embalar', 'embalo', 'embarcado', 'emergencias', 'emite', 'emitida', 'emocao', 'emocional', 'emocoes', 'emogis', 'emoij', 'emoticons', 'empenhar', 'emporta', 'empreendedor', 'empreendimento', 'empregado', 'empresariais', 'empurram', 'emtrega', 'encaixar', 'encaixou', 'encaminhamentos', 'encaminharam', 'encarar', 'encarece', 'encerraria', 'encheram', 'encheu', 'encomada', 'encomendado', 'encomodo', 'encontradas', 'encontralo', 'encontrara', 'encontrem', 'encrava', 'encravar', 'encurta', 'enfeites', 'enganador', 'enganadoras', 'engane', 'enganou', 'engarrafado', 'engessada', 'engodo', 'engolir', 'engracada', 'engracadinho', 'engula', 'enjoa', 'enjoado', 'enjoei', 'enqnto', 'enquadra', 'enquadram', 'enquadrem', 'enriquecer', 'ensino', 'ensinou', 'enstalar', 'entaoeu', 'ente', 'enter', 'entornada', 'entradanotificacoes', 'entradas', 'entragador', 'entrao', 'entrara', 'entrariam', 'entravam', 'entraves', 'entregados', 'entregae', 'entregao', 'entregassem', 'entres', 'entretando', 'entupindo', 'enviariam', 'enviarme', 'envolvente', 'envolvidas', 'epidemia', 'epis', 'equipes', 'eramos', 'eras', 'erotico', 'err', 'erradoe', 'erramos', 'erre', 'errem', 'errinho', 'erronea', 'esbarrar', 'esbarro', 'escada', 'escancarado', 'escapa', 'escassos', 'esclarece', 'esclareceram', 'esclareceu', 'esclareco', 'escolhese', 'escolhidas', 'escondendo', 'esconderem', 'escravizar', 'escreva', 'escritura', 'esculachar', 'escurece', 'escutei', 'escutou', 'esfarrapadas', 'esgota', 'esgotadas', 'esmagadora', 'espalha', 'espalhados', 'espalham', 'espalhando', 'especialidade', 'especializada', 'especificados', 'espectador', 'espelhamento', 'espelho', 'esperasse', 'esperem', 'espertinhos', 'espertoes', 'espetaculo', 'espira', 'espiritualidade', 'esplendido', 'espontaneo', 'esporro', 'esportes', 'espumando', 'esquecimento', 'esquenta', 'esquentar', 'esquerdistas', 'esquinas', 'esquisita', 'esra', 'esselete', 'esso', 'esss', 'essse', 'est', 'estabelecidas', 'estacionar', 'estagio', 'estalado', 'estale', 'estalou', 'estatico', 'estaveis', 'esteticamente', 'esteva', 'estimar', 'estipular', 'estivermos', 'estoques', 'estores', 'estornados', 'estorquindo', 'estouradas', 'estourado', 'estourou', 'estraguem', 'estrala', 'estralas', 'estrangeira', 'estranhamento', 'estrar', 'estrategias', 'estrelaspois', 'estrelasporque', 'estrema', 'estremamente', 'estuda', 'estudio', 'estupida', 'estupidez', 'estupido', 'estupidos', 'esvazio', 'etarias', 'etcentao', 'etcmais', 'etiqueta', 'euro', 'evangelica', 'evasivos', 'ever', 'evidentemente', 'evitado', 'evitam', 'evite', 'exasperante', 'exatas', 'exatidao', 'exaustiva', 'exceda', 'excelentepara', 'excelenteporem', 'excessao', 'excessos', 'excite', 'exclamacao', 'excluam', 'excluilos', 'excluimos', 'excluisse', 'exclusive', 'executadas', 'executado', 'executando', 'exemploeu', 'exemploo', 'exerce', 'exibicoes', 'exigido', 'exijam', 'eximem', 'exite', 'exorbitantemente', 'exp', 'expandidas', 'expansao', 'expendido', 'experienciafiz', 'experimentem', 'expiraram', 'explicados', 'exploda', 'explodindo', 'explorado', 'explorador', 'expondo', 'exposta', 'expressivo', 'expressoes', 'expulso', 'expus', 'extender', 'extensa', 'externas', 'extornado', 'extornam', 'extornarem', 'extorquir', 'extraviado', 'extraviados', 'extremas', 'fabrica', 'fabuloso', 'facada', 'faceb', 'facies', 'facilitador', 'faiz', 'falacia', 'falavam', 'falcatruas', 'faleceu', 'falhado', 'falharam', 'faliu', 'faltaacho', 'faltadela', 'falto', 'fan', 'fantasia', 'fariam', 'farias', 'farta', 'fartos', 'fases', 'fasio', 'fassam', 'fatias', 'faturado', 'faturando', 'favo', 'favorecem', 'favorecer', 'favoreceu', 'favoritado', 'favormas', 'favorna', 'favorse', 'fazelos', 'fazeram', 'fc', 'fdps', 'fece', 'fecebok', 'fechala', 'fechalo', 'fecharmos', 'fed', 'feesebook', 'feicebook', 'feicebuke', 'feijoada', 'felipe', 'feminina', 'feri', 'ferias', 'ferisse', 'feriu', 'fernandes', 'ferramente', 'ferro', 'fia', 'fiat', 'ficariamos', 'ficha', 'ficheiros', 'ficticio', 'fidelizando', 'filiados', 'filmesseries', 'filtrada', 'filtradas', 'fina', 'finalizarmos', 'finamente', 'financas', 'fiquemos', 'firme', 'five', 'fivela', 'fixadasfavoritas', 'fixados', 'fixe', 'flerte', 'flets', 'flexibilidade', 'flexibilizacao', 'flopada', 'flopam', 'flor', 'florianopolissc', 'fluem', 'fluminense', 'fluxos', 'flw', 'fofoca', 'fofos', 'foise', 'forcam', 'formiga', 'forna', 'fornecam', 'fornecedorentregador', 'fornecerem', 'fornecia', 'fornecimento', 'fortalecer', 'fortemente', 'fotografar', 'fotografia', 'fotonao', 'fotosimagens', 'fou', 'fracas', 'fracassadas', 'fralda', 'fraldas', 'frames', 'fraudulentos', 'freezer', 'frias', 'from', 'front', 'frustacao', 'frustrando', 'frustrar', 'fruta', 'fucoes', 'funcina', 'funcionao', 'funcionarias', 'funcionaso', 'funcoese', 'fundadores', 'fundamentado', 'fusao', 'fusion', 'fyy', 'fz', 'g4', 'g5', 'gachatuber', 'galaxias', 'galeao', 'galerias', 'galp', 'gambiarra', 'gaming', 'gananciosa', 'gananciosos', 'ganhara', 'garantida', 'garantido', 'garcia', 'garimpando', 'garimpo', 'garoto', 'garotos', 'gastado', 'gastronomia', 'gatas', 'gatinho', 'gatos', 'geladinhos', 'gemendo', 'general', 'generalizando', 'generosidade', 'generoso', 'genialidade', 'genteee', 'geo', 'geraram', 'gerenciam', 'gerencio', 'gerentes', 'gerir', 'gestores', 'getulio', 'glitch', 'glr', 'gomes', 'gora', 'gordura', 'gore', 'gospel', 'gostarem', 'gostinho', 'graduacao', 'graduada', 'gramatica', 'grampiado', 'gran', 'graninha', 'gratificar', 'gravam', 'gravareu', 'gravou', 'gretchen', 'grift', 'gringo', 'grosseiras', 'grotesca', 'grotescos', 'grudado', 'guararapes', 'guardam', 'guardanapo', 'guardei', 'guardem', 'guarnicoes', 'guela', 'guerra', 'guiando', 'guilherme', 'habilidade', 'habilita', 'habilitacao', 'habilitei', 'habilitem', 'habituados', 'habituais', 'hackeados', 'hacks', 'hakeada', 'hakeamento', 'hamburger', 'happn', 'hardware', 'hastags', 'have', 'hbo', 'hc', 'hehehe', 'hidratante', 'hipocrisia', 'hipocrita', 'hipoteses', 'history', 'hojeeu', 'homen', 'homenagem', 'homeoffice', 'homo', 'homofobico', 'homofobicos', 'honram', 'horizontes', 'horrivelas', 'horroso', 'hortolandia', 'hostil', 'hotdog', 'hoteis', 'house', 'huawei', 'humildemente', 'humilhado', 'humilhando', 'ice', 'idealizou', 'idem', 'identicas', 'identicos', 'identificaram', 'identifique', 'ideologias', 'ideologica', 'idonea', 'idosas', 'if', 'iffood', 'ifoo', 'ifoods', 'ignorancia', 'ignore', 'ignorei', 'ignoro', 'iguala', 'igualado', 'igualando', 'ilegiveis', 'ilheus', 'ilusorias', 'ilusorio', 'ilustrativas', 'ima', 'imaginam', 'imensos', 'imensuravel', 'imitacoes', 'imitando', 'imorais', 'impacta', 'imparcial', 'impertinentes', 'impessoal', 'implantadas', 'impoe', 'importantissimo', 'importarem', 'importaria', 'importava', 'importei', 'importunando', 'impostas', 'impraticavel', 'imprecisas', 'impresa', 'impressionada', 'impressionantemente', 'impressionou', 'impressora', 'imprestavel', 'imprevisiveis', 'improvavel', 'impulaveis', 'impulsiona', 'imundo', 'imundos', 'inadequada', 'inadimissivel', 'inapropiadas', 'inativa', 'inativada', 'inativar', 'incansavelmente', 'incessantemente', 'incial', 'incidencia', 'inclua', 'incluidos', 'incluisse', 'incluo', 'inclusivo', 'incoerentes', 'incompatibilidades', 'inconformado', 'inconstante', 'increnagem', 'incrivela', 'incrivelmas', 'incrivelso', 'indentificacao', 'independencia', 'indesejada', 'indesejado', 'indesejados', 'indesejavel', 'indevidos', 'indgnada', 'indicada', 'indicadas', 'indicaram', 'indiquem', 'indiretamente', 'indiscutivel', 'individuos', 'inesquecivel', 'inexiste', 'inexistencia', 'inexperiente', 'inexplicaveis', 'infalivel', 'infancia', 'infelismente', 'infestado', 'inflacao', 'inflar', 'infligem', 'infligido', 'influenciado', 'informadas', 'informatica', 'infringido', 'infringir', 'ingressar', 'iniciada', 'iniciantes', 'iniciarem', 'inimigo', 'injustas', 'injusticas', 'inocencia', 'inoportuna', 'inovadoras', 'inovarem', 'inscreva', 'inscrita', 'inseridas', 'inseto', 'insights', 'insistem', 'insistiu', 'inspiracao', 'instagrammas', 'instalacoes', 'instalam', 'instalamos', 'instalarei', 'instalarem', 'instalasse', 'insubstituivel', 'insultou', 'intactas', 'intactos', 'intalar', 'integram', 'integrante', 'integridade', 'intelectuais', 'intem', 'intencionado', 'intencional', 'intensa', 'intensao', 'intensionadas', 'interajam', 'interativas', 'interessadas', 'interessei', 'interferencia', 'interferencias', 'interferir', 'interminavel', 'internacionalizacao', 'internacionalmente', 'interpessoais', 'interssante', 'intimos', 'intolerancia', 'intolerante', 'intolerantes', 'intragavel', 'intriga', 'intrigada', 'introduzir', 'intuicao', 'inutilidade', 'invasivas', 'inventado', 'inventam', 'inverter', 'invertidas', 'invertido', 'investidores', 'iogurtes', 'ipa', 'iram', 'irlen', 'irmaos', 'irracionais', 'irregular', 'irritabilidade', 'irritacao', 'irritacoes', 'irritei', 'irritou', 'isabel', 'isenta', 'isentar', 'isento', 'isolados', 'isopor', 'isqueiro', 'israel', 'issoalem', 'issomeu', 'issopor', 'issoquero', 'issso', 'ista', 'itaipava', 'italiana', 'itaquera', 'items', 'iti', 'jaboatao', 'janelinha', 'jaragua', 'jardim', 'jeronimo', 'jm', 'jo', 'joelho', 'jogadas', 'jogadores', 'jogose', 'jogue', 'joguem', 'joguinho', 'jorge', 'jornalismo', 'juizo', 'jukn', 'julga', 'julgo', 'jump', 'juncao', 'juntam', 'juridica', 'juridico', 'juros', 'justificavel', 'justifique', 'k10', 'k8', 'kakakak', 'katchup', 'kb', 'kilometros', 'kinha', 'kkkkkkkkkkkk', 'krlh', 'ks', 'kwaii', 'lacrando', 'lada', 'lagar', 'lager', 'lagoa', 'lambanca', 'lamenta', 'lamentamos', 'lanchese', 'lapis', 'lapso', 'largou', 'las', 'lascou', 'laterais', 'latina', 'lavar', 'legalo', 'legalzinho', 'leigas', 'lembrou', 'leram', 'lerda', 'lesadas', 'lesbica', 'lesionada', 'lesoes', 'lessem', 'leste', 'levados', 'levava', 'levianas', 'lgpd', 'liberei', 'lidam', 'lidera', 'lidos', 'ligasse', 'ligeiramente', 'limitasse', 'limitei', 'limpado', 'limpe', 'limpezas', 'lindamente', 'linear', 'lingerie', 'linkar', 'liquida', 'listada', 'listado', 'listra', 'lit', 'lixooooo', 'ln', 'locacao', 'localizada', 'localizarem', 'logados', 'logicamente', 'loging', 'logista', 'logomarca', 'logon', 'logos', 'londrina', 'lotados', 'loucos', 'loucura', 'louvavel', 'louvores', 'lua', 'lucrativos', 'ludibriar', 'luiz', 'luluca', 'm21s', 'm62', 'maa', 'maaaas', 'macante', 'mache', 'machistas', 'machs', 'machucar', 'maconha', 'macth', 'maestria', 'maeztra', 'mafe', 'magic', 'magico', 'mails', 'maisas', 'maiseu', 'maisinclusive', 'maispor', 'maiss', 'maiuscula', 'maiusculas', 'maldita', 'maliciosos', 'malucas', 'mamas', 'mamdei', 'manager', 'mancada', 'mandaria', 'mandariam', 'mandassem', 'mangos', 'manipuladas', 'manipulam', 'manoo', 'manooo', 'manteiga', 'mantenhase', 'manterei', 'mantiver', 'manu', 'maracutaia', 'maravilhada', 'maravilho', 'maravilhosoporem', 'maravilhosotem', 'marcalas', 'markeplace', 'marra', 'marte', 'masc', 'mascarar', 'masquando', 'mat', 'matcher', 'matematica', 'matico', 'maxim', 'maximizar', 'maxxi', 'mbs', 'mce', 'mcnuggets', 'mcs', 'mcveggie', 'mecanicos', 'medica', 'medicacao', 'medicos', 'medir', 'mei', 'melhormas', 'melhoro', 'men', 'menas', 'mencionada', 'mencionaram', 'menciono', 'mensagems', 'mensionar', 'mentalidade', 'mentem', 'mentirosas', 'mercadolivre', 'mercadopago', 'merecemos', 'merecer', 'merecida', 'merecidas', 'mesas', 'mesclar', 'mesm', 'mesmice', 'mesmoalem', 'mesmomais', 'mesmomas', 'mesmoo', 'mesquinho', 'messagem', 'metades', 'metal', 'metas', 'metem', 'metido', 'metropole', 'meua', 'mexerem', 'mexeu', 'mfa', 'microsoft', 'migra', 'migraria', 'migre', 'migrem', 'migro', 'migrou', 'milagres', 'milagrosamente', 'milesima', 'milesimos', 'milho', 'militante', 'militar', 'milk', 'mimado', 'mime', 'mimeu', 'mimha', 'mimimimi', 'mimizento', 'mimmas', 'mimmesmo', 'mimnao', 'minas', 'mineiro', 'minh', 'minimas', 'minimizando', 'minusculos', 'minutagem', 'misera', 'miseros', 'misturam', 'misturava', 'mm', 'modem', 'moderado', 'moderar', 'modernizem', 'modinha', 'modulo', 'moedad', 'molas', 'molhada', 'molhado', 'molhou', 'momentaneo', 'momentaneos', 'momente', 'monetaria', 'monetariamente', 'monetarias', 'monetario', 'monitoradas', 'monitorando', 'mono', 'monstra', 'monta', 'montado', 'montei', 'montes', 'moot', 'moradas', 'moradia', 'moradores', 'mordomia', 'more', 'moroso', 'mortadela', 'mortais', 'mortal', 'mostradas', 'mostrarem', 'mostrasse', 'mostrassem', 'mostravam', 'mota', 'motivador', 'motivar', 'motociclista', 'motoristaoutra', 'movimentacoes', 'movimentam', 'mp', 'mq', 'mscs', 'msgm', 'msis', 'mtooooo', 'muchas', 'mudarmos', 'muio', 'muitooooo', 'muitoooooooo', 'multifuncional', 'multipla', 'multiplica', 'multiplicado', 'multiverso', 'municipais', 'muro', 'musiquinha', 'mussarela', 'mutada', 'mutuamente', 'muuuuita', 'muuuuuuuuito', 'naa', 'naaada', 'nacao', 'nacionais', 'nadaaaa', 'nadaas', 'nadaisso', 'nadao', 'nadatem', 'nai', 'nak', 'namoral', 'namoramos', 'nap', 'natureza', 'ndeg1', 'necessitam', 'negada', 'negativar', 'negociacao', 'nehum', 'neim', 'nelee', 'nelemas', 'nen', 'nenhuns', 'ner', 'nervos', 'nervosa', 'nestas', 'neto', 'neu', 'ni', 'nick', 'nickname', 'niquel', 'niver', 'noa', 'nocivos', 'noites', 'nomeacredito', 'nora', 'normaliza', 'normalizem', 'notada', 'notadamente', 'notamos', 'notbook', 'notificados', 'notifique', 'noturna', 'noutras', 'noutro', 'noutros', 'novato', 'novinho', 'novonao', 'nuca', 'null', 'numca', 'nun', 'nunero', 'nunes', 'nus', 'nv', 'obggg', 'obras', 'obrigafo', 'obrigasse', 'obrigava', 'obrigue', 'obscenos', 'obsequio', 'observa', 'obtemos', 'obtenha', 'obteve', 'obtidos', 'obvia', 'obvias', 'obvios', 'ocasionais', 'ocasionalmente', 'ocasionando', 'ocasionar', 'ocasionou', 'ocorresse', 'ocorriam', 'ocorridos', 'oculpa', 'ocultacao', 'ocultado', 'ocuparia', 'ocupem', 'ofenda', 'ofendem', 'ofendido', 'ofensa', 'ofensivos', 'oferecam', 'ofertada', 'ofertaram', 'oitavo', 'oitros', 'oitube', 'okmas', 'olabom', 'olasou', 'oled', 'olhado', 'olharam', 'olharem', 'olhares', 'olhava', 'oliveira', 'olx', 'omesseger', 'omisso', 'omissos', 'onerar', 'onoff', 'operador', 'opero', 'opiniaoum', 'oportunistas', 'oportuno', 'optarem', 'optaria', 'optimo', 'oracoes', 'oras', 'ordenadas', 'orelha', 'organico', 'organizalo', 'organizaria', 'organizem', 'orgaos', 'orientando', 'orientaram', 'oriento', 'osasco', 'oscilando', 'otaku', 'otaria', 'otimista', 'otimizada', 'otimizalo', 'otimizarem', 'otimizem', 'otimoate', 'otimoporem', 'otimouso', 'oucam', 'outa', 'outr', 'outrem', 'outroapesar', 'outromas', 'outrossim', 'ouvirem', 'ovomaltine', 'pac', 'pacei', 'padarias', 'padronizadas', 'padronizado', 'paea', 'pagador', 'pagamentoa', 'pagamentoe', 'pagase', 'pagem', 'paguemos', 'paineis', 'palestras', 'palha', 'palhaca', 'palhacos', 'pan', 'pancada', 'panda', 'papa', 'papal', 'papear', 'papeizinhos', 'paquerar', 'parachoque', 'paradas', 'paralisar', 'parasse', 'parassem', 'parceladas', 'parcialidade', 'pareando', 'pareceme', 'pareciam', 'parelho', 'park', 'parmegiana', 'paroueu', 'partem', 'partilho', 'pasa', 'passageiroscomo', 'passaramse', 'passasse', 'passeando', 'passivel', 'pastor', 'pate', 'patio', 'patrao', 'patrimonio', 'patriotas', 'patrocinada', 'patrocinadores', 'patrocinio', 'paula', 'pausados', 'pauso', 'pecas', 'pecou', 'peder', 'pedidoque', 'pedidosja', 'pedipor', 'pedira', 'pedirmos', 'pedisse', 'pedras', 'pedro', 'pegacao', 'pegamos', 'pegao', 'pegavam', 'peito', 'peitos', 'peladas', 'pelados', 'penalidades', 'penaliza', 'penalizada', 'penalizalos', 'penamas', 'penas', 'penha', 'pensamos', 'pensassem', 'pepsi', 'pequenininho', 'pera', 'perceberem', 'percebese', 'percentual', 'perceptivel', 'perdamos', 'perdia', 'perdoem', 'perfeitinho', 'perfeitomais', 'perfeitoo', 'perfeitooo', 'perfils', 'perfio', 'perguntamos', 'perguntaram', 'perguntavam', 'perguntem', 'periferia', 'perigosos', 'permaneca', 'permanecendo', 'permaneco', 'permitidas', 'permitiram', 'pernas', 'perrengue', 'persegue', 'perseguicoes', 'perseguir', 'persisti', 'persistindo', 'personalizacoes', 'personalizalo', 'personalizaveis', 'pertencem', 'pertenco', 'pertinente', 'pesames', 'pesando', 'pese', 'pesoas', 'pesquisada', 'pessimamente', 'pessimoo', 'pessoad', 'pessoasas', 'pessoasde', 'pessoasque', 'pesssimo', 'pets', 'pff', 'pfto', 'phishing', 'picaretagem', 'picles', 'pilantragem', 'pilar', 'pilha', 'pimba', 'pino', 'pinta', 'pintadinha', 'pintura', 'pioneiros', 'piore', 'pipocando', 'piracicaba', 'piramide', 'piranha', 'pirateada', 'pires', 'pisando', 'pista', 'pistola', 'piti', 'pixelado', 'placeholder', 'planejada', 'plasticas', 'plasticos', 'plataformamas', 'plataformamuitos', 'playstory', 'plenitude', 'ploblemas', 'pod', 'podcast', 'poderemos', 'poderosas', 'poderosos', 'podeser', 'podpah', 'podres', 'poesia', 'pofavor', 'pohan', 'polegar', 'polemicos', 'polido', 'polly', 'poluem', 'pontas', 'ponteiro', 'pontes', 'poos', 'poriso', 'pormenor', 'pormenores', 'porquee', 'porr', 'porre', 'portabilidade', 'portado', 'portadoras', 'portal', 'portamalas', 'portfolio', 'ports', 'posicionamentos', 'possua', 'possuam', 'possue', 'possuirem', 'postalo', 'postarisso', 'postasse', 'poster', 'postos', 'posvenda', 'pote', 'poupar', 'pracas', 'prateleiras', 'praticam', 'praticomas', 'praticoo', 'praticoporem', 'precaucao', 'precedentes', 'preciosas', 'precioso', 'precisariamos', 'precisase', 'precisomas', 'preconceituoso', 'preconseito', 'predomina', 'preenchendo', 'preencho', 'preferimos', 'preferiria', 'pregam', 'preguicosa', 'prejudicamos', 'prejudicaram', 'premiacao', 'premiado', 'preocupando', 'preocupante', 'preocuparam', 'prepago', 'preparese', 'presciso', 'presepada', 'preserva', 'presisa', 'presiso', 'pressuposto', 'prestarem', 'prestativas', 'prestatividade', 'prestigio', 'pretendem', 'pretendente', 'pretensao', 'preucupado', 'preucurar', 'prevenir', 'preventiva', 'previlegio', 'previsualizacao', 'preza', 'prezo', 'prfv', 'primario', 'printando', 'priorizado', 'priorize', 'privacidades', 'privam', 'probabilidades', 'problemaagora', 'problemame', 'problemanao', 'problemapor', 'problemase', 'problemaspor', 'procede', 'procedencia', 'procedentes', 'processada', 'processador', 'processalos', 'processava', 'procurado', 'procurarem', 'procuras', 'prod', 'producoes', 'produtivo', 'produtoe', 'produzindo', 'proeza', 'professor', 'proficionais', 'profissoes', 'profunda', 'programei', 'progredir', 'proibem', 'projetos', 'prol', 'prolongada', 'prometia', 'prometida', 'promocoese', 'promocoesmas', 'promos', 'promovendo', 'pronomes', 'prontifica', 'pronuncia', 'propagandasanuncios', 'propagar', 'propia', 'propor', 'proporcionado', 'proporcione', 'propos', 'proprietarios', 'prosperidades', 'protagonismo', 'protejam', 'provedor', 'prs', 'prv', 'pse', 'pu', 'publicarem', 'pudemos', 'pudim', 'pulados', 'pularem', 'pulei', 'pulsos', 'pune', 'punem', 'punicoes', 'punindo', 'puniu', 'puxada', 'puxado', 'puxo', 'puxou', 'qando', 'qhe', 'qtas', 'qtde', 'quadradinho', 'quadrilha', 'quadros', 'qualho', 'qualidadee', 'qualifico', 'quantias', 'quarenta', 'quartafeira', 'quatros', 'quebradas', 'quebrei', 'quebrem', 'quee', 'queimada', 'queimar', 'queimou', 'quelas', 'queles', 'quera', 'quere', 'quererem', 'querermos', 'questiona', 'questionamos', 'questionarios', 'quieto', 'quilometrica', 'quintafeira', 'quisessemos', 'quisito', 'r12', 'r14000', 'r1492', 'r15000', 'r2', 'r2090', 'r2490', 'r300', 'r600', 'r890', 'rafael', 'rakeada', 'ralacao', 'ralado', 'rampage', 'rancho', 'ranking', 'raparigas', 'rapidoe', 'rapidosem', 'raquearam', 'rara', 'rastreabilidade', 'rastreada', 'rastreando', 'rastros', 'rating', 'reaberto', 'readicionar', 'reagindo', 'reajo', 'reajustado', 'reajustes', 'realizaram', 'realizarem', 'realizarmos', 'reapareceu', 'reativala', 'reativem', 'reavaliarei', 'reavaliei', 'recados', 'recalculado', 'receberei', 'receberemos', 'recebermos', 'recebesse', 'recebir', 'rececao', 'receoso', 'recepcionado', 'recheadas', 'recibos', 'reciprocidade', 'reclamacaoajuda', 'reclamaram', 'reclamarmas', 'reclamem', 'recomendada', 'recomendadissimo', 'recomendaram', 'recomendarei', 'recomendoooooo', 'recompensado', 'recompensados', 'reconheceram', 'recriar', 'recuar', 'recupero', 'recusada', 'recuse', 'redbull', 'redefinicao', 'redefinindo', 'redimir', 'redirecionada', 'redirecionamento', 'redirecionou', 'redondezas', 'reduzam', 'reduzem', 'reduzidos', 'reeditando', 'reel', 'reelsnao', 'reembolsados', 'reembolsarem', 'reencontramos', 'reencontro', 'reeniciei', 'reenstalei', 'reenviando', 'reenviei', 'reenvio', 'reescrever', 'refaz', 'refazendo', 'refeito', 'referem', 'referir', 'refiro', 'refletem', 'refletindo', 'reflexoes', 'reflitam', 'reforma', 'reformas', 'refugio', 'regata', 'registradas', 'regravar', 'regredindo', 'regressiva', 'regularidade', 'reiniciada', 'reinstalacao', 'reinventar', 'reivindicacao', 'rejeitada', 'rejeitados', 'relatadas', 'relatados', 'relaxados', 'relaxante', 'reles', 'relevava', 'religiao', 'religioes', 'religiosamente', 'religuei', 'remediar', 'remete', 'remova', 'removelo', 'removidas', 'removo', 'renato', 'rendem', 'renderizando', 'rendimento', 'renovada', 'renovando', 'rentabilidade', 'rentavel', 'repaginado', 'reparam', 'reparo', 'repassadas', 'repassados', 'repassem', 'repensando', 'repeti', 'repleta', 'replicar', 'reply', 'reportaram', 'reporte', 'reports', 'reposicao', 'repost', 'repostando', 'repreender', 'reproducoes', 'reproduza', 'reproduzia', 'republicare', 'republicou', 'requisitado', 'resalva', 'reservado', 'reset', 'resetei', 'resgatado', 'resgatala', 'resgitrado', 'resguarda', 'residences', 'residente', 'resistencia', 'resistir', 'resolutivo', 'resolvelos', 'resolvera', 'resolvesem', 'resolvidas', 'respaldar', 'respeitado', 'respeitados', 'respeite', 'respeitosos', 'respondemos', 'respondiam', 'responsabilidades', 'responsabilizam', 'responsivo', 'ressarce', 'ressarciu', 'ressentimente', 'resso', 'restaur', 'restaura', 'restauracao', 'restaurado', 'restaurantelanchonete', 'restaurantese', 'restautante', 'restourante', 'restringi', 'restringido', 'restringindo', 'restringiram', 'resultando', 'resultaria', 'resumido', 'retangular', 'retangulo', 'retardada', 'retido', 'retificar', 'retornado', 'retornaria', 'retornasse', 'retrocede', 'retrocedeu', 'retrospectiva', 'retweet', 'retwetar', 'reunindo', 'reunioes', 'reunir', 'reutilizacao', 'revendo', 'revertido', 'revisada', 'revisadas', 'revoada', 'revolucionar', 'reze', 'ri', 'ridicularizando', 'rigorosamente', 'rigoroso', 'rim', 'risada', 'riscado', 'risivel', 'ritmo', 'robert', 'roberto', 'robotizadas', 'rodada', 'rodava', 'rodela', 'rodoviaria', 'rol', 'rolava', 'roletando', 'romper', 'rosas', 'roteiro', 'rotulos', 'rpg', 'rr', 'ruido', 'ruidos', 'ruimnao', 'ruimne', 'rural', 's22', 'sabao', 'saberia', 'saborosos', 'sabota', 'saca', 'sacada', 'sacana', 'sache', 'sadias', 'safados', 'sagrada', 'sagrado', 'saiam', 'saisse', 'salsicha', 'saltar', 'salvado', 'salvasse', 'samba', 'samos', 'samuel', 'sanada', 'saquei', 'sara', 'satelites', 'satifaz', 'satisfatorios', 'satisfaz', 'saturado', 'sb', 'screenshot', 'scripts', 'scrollar', 'search', 'seco', 'secundarios', 'sedo', 'seguira', 'seguiram', 'seguisse', 'segundafeira', 'segundas', 'seguramente', 'seguraram', 'segurose', 'sejaquando', 'seleccao', 'seleto', 'selinho', 'semaforo', 'semanal', 'semelhanca', 'semore', 'sendi', 'sensiveis', 'sensuais', 'sentar', 'sentia', 'sentirao', 'sento', 'separa', 'separador', 'separam', 'separou', 'sepre', 'sequestro', 'seram', 'seriamos', 'sertaneja', 'sertanejas', 'sertos', 'servida', 'servira', 'serviram', 'serviria', 'sessenta', 'severamente', 'sextou', 'sfihas', 'shooper', 'sigiloso', 'significado', 'significar', 'significativos', 'signo', 'silenciando', 'silenciaram', 'silenciei', 'silencio', 'simbolica', 'simbolico', 'simplese', 'simplifiquem', 'simplista', 'simula', 'simultaneo', 'simultaneos', 'sinalizado', 'sinalizam', 'sinalizei', 'sinceridade', 'sindrome', 'sinistro', 'sino', 'sinonimo', 'sinplesmente', 'sintam', 'sintome', 'sinuca', 'sirva', 'sitios', 'skip', 'sl', 'slide', 'smss', 'snapdragon', 'soba', 'soberbo', 'sobram', 'sobrecarrega', 'sobreposicoes', 'sobrepostas', 'sobressai', 'sobretudo', 'sobrinha', 'sobrinhos', 'sobrio', 'sofisticado', 'sofisticados', 'soh', 'solicitadas', 'solicitava', 'solitaria', 'solitario', 'solteira', 'solucionaria', 'somados', 'somavam', 'somi', 'sonha', 'sonic', 'sonoros', 'soq', 'sor', 'sorveteria', 'sossego', 'souberem', 'span', 'spray', 'srs', 'st', 'stacker', 'stagram', 'startup', 'statusou', 'stf', 'storee', 'storieseu', 'stors', 'storysnao', 'streamers', 'stressante', 'strike', 'striker', 'stumble', 'suado', 'sub', 'subdivisao', 'submetido', 'subscricao', 'substitui', 'substituidas', 'substituidos', 'subtrai', 'sufocado', 'suga', 'sugeriram', 'suicida', 'sujas', 'sujestoes', 'sumirao', 'sumirem', 'sup', 'supere', 'superfaturado', 'suplico', 'suponho', 'suportavel', 'supostos', 'supri', 'surpe', 'surpreendentes', 'surpreendida', 'surpreso', 'suspeitar', 'suspeitas', 'suspendendo', 'suspense', 'sustenta', 'sustentar', 'sustentavel', 'sutia', 't0b2', 't3ddy', 't9b9c9', 'tabelas', 'taboao', 'tabua', 'tac', 'taca', 'tacha', 'tah', 'take', 'talher', 'talheres', 'tambemmuito', 'tambemnao', 'tanbem', 'tange', 'tare', 'tarifado', 'taticas', 'tauz', 'tax', 'tbeim', 'tc', 'tchauuuu', 'tea', 'tec', 'teclas', 'tecnologica', 'teewts', 'teias', 'telefonema', 'telepizza', 'telha', 'telinha', 'tematicos', 'tembem', 'teme', 'tempoe', 'tempomas', 'tempoo', 'tempopra', 'tendenciosa', 'tenebrosa', 'tenhos', 'tenis', 'tenq', 'tentarei', 'tentariva', 'teorias', 'tequila', 'terco', 'terminamos', 'terminaram', 'terminarem', 'testado', 'testarem', 'testemunha', 'textao', 'thanks', 'theme', 'thread', 'threads', 'thumbnails', 'thumbs', 'tijuca', 'tiko', 'tiktoke', 'tiktokers', 'tiktokeu', 'tiktokvoces', 'til', 'timder', 'timing', 'tindero', 'tipica', 'tipsters', 'tiralo', 'tirasem', 'tissue', 'tivese', 'tlvz', 'tmp', 'toc', 'tocada', 'tocamos', 'tocante', 'tocasse', 'todoa', 'tokmais', 'toks', 'tomamos', 'tomarei', 'tomassem', 'tomate', 'tope', 'tora', 'tornandose', 'tornariam', 'tornasse', 'torres', 'tortinha', 'torto', 'toscos', 'totalpq', 'toxicidade', 'trabalhada', 'trabalhem', 'tracado', 'tracar', 'tracinho', 'traduza', 'trafegar', 'tragedia', 'tragico', 'trailer', 'trancar', 'tranquei', 'tranqueira', 'transferi', 'transferidos', 'transferindo', 'transformaram', 'transicoes', 'trasporte', 'trastorno', 'travadinha', 'travae', 'travaram', 'travoue', 'trazerem', 'trazido', 'trechos', 'treco', 'treme', 'tremer', 'tremida', 'trhu', 'trilha', 'triplica', 'trocalo', 'trocarao', 'trocaria', 'trocoe', 'tropa', 'tropical', 'trouxas', 'tsu', 'tuber', 'tubo', 'tudinho', 'tudos', 'tudoso', 'tufo', 'tumblr', 'turcas', 'turistas', 'turno', 'turo', 'tutorias', 'tweetado', 'twetts', 'twit', 'twittes', 'twts', 'ua', 'ual', 'uberx', 'ubet', 'ultilizei', 'ultizar', 'ultrapassa', 'ultrapassada', 'ultrapassaram', 'umaplicativo', 'umbigo', 'unanimidade', 'une', 'unha', 'unificado', 'unificar', 'unilateral', 'unilateralmente', 'unitario', 'universal', 'universidade', 'updates', 'uploading', 'urbana', 'urbe', 'usara', 'usare', 'usariam', 'usarios', 'useio', 'username', 'usuarioa', 'usufruimos', 'utilitarios', 'utilizadas', 'utilizarei', 'utilizarem', 'utilizaria', 'utilizassem', 'uwu', 'vagabundos', 'vais', 'valcher', 'valera', 'valesse', 'validades', 'validam', 'validaram', 'valiosa', 'valo', 'valorizacao', 'valorizarem', 'valorizem', 'valorizo', 'valos', 'vam', 'vanced', 'vanguarda', 'vargas', 'variam', 'variaveis', 'varredura', 'vas', 'vasta', 'vasto', 'vazamento', 'vazamentos', 'vcis', 'vedeo', 'vegana', 'vegetariana', 'veiculada', 'veiculado', 'veiculados', 'velo', 'vencem', 'venceram', 'venceria', 'vencidas', 'vendidas', 'vendido', 'verdd', 'verificadas', 'verificasse', 'verifico', 'verso', 'vezo', 'viabilizar', 'viageme', 'vibracao', 'vicente', 'viciando', 'vicioso', 'vidase', 'vide', 'videoas', 'videomas', 'videoo', 'videoseu', 'videosnao', 'videosque', 'videosvarias', 'videozinhos', 'vidochamadas', 'vidro', 'vigente', 'vigentes', 'vigilancia', 'vils', 'vimeo', 'vinculacao', 'vines', 'violao', 'violarem', 'virais', 'viraliza', 'viralizando', 'virao', 'viraria', 'virgem', 'virse', 'vision', 'visitei', 'vistoria', 'visualizava', 'visualizem', 'vitaliza', 'viuo', 'vivenciar', 'vivenciei', 'viz', 'vizualiza', 'vizualizacoes', 'vl', 'vodka', 'volante', 'voltaaaaaa', 'voltada', 'vomito', 'vossas', 'votaria', 'vozvideo', 'vsfd', 'wallpapers', 'watssap', 'whatsaap', 'whatspp', 'whatzapp', 'whts', 'wi', 'widget', 'widgets', 'wish', 'wu', 'xadrez', 'xau', 'xinga', 'xinguei', 'xxi', 'xxxtentacion', 'yakisoba', 'youtubeo', 'zapp', 'zelo', 'zeros', 'zl', 'zoada', 'zoar', 'zoeira', 'zuado', 'zuck']\n"
     ]
    }
   ],
   "source": [
    "print(vocab_transform.get_itos())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "c3f8c02f-13a1-42e7-91ca-251a8d523e3c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# print(vocab_transform.get_itos())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "21a95443-6ba5-4e36-9a69-5ec7734a9f7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import Tensor\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import math\n",
    "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "4aa562f4-abdd-4f3c-b0b9-b2df3a4d04ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PositionalEncoding(nn.Module):\n",
    "    def __init__(self,\n",
    "                 d_model: int,\n",
    "                 dropout: float,\n",
    "                 maxlen: int = 5000):\n",
    "        super(PositionalEncoding, self).__init__()\n",
    "        den = torch.exp(- torch.arange(0, d_model, 2)* math.log(10000) / d_model)\n",
    "        pos = torch.arange(0, maxlen).reshape(maxlen, 1)\n",
    "        pos_embedding = torch.zeros((maxlen, d_model))\n",
    "        pos_embedding[:, 0::2] = torch.sin(pos * den)\n",
    "        pos_embedding[:, 1::2] = torch.cos(pos * den)\n",
    "        pos_embedding = pos_embedding.unsqueeze(-2)\n",
    "\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.register_buffer('pos_embedding', pos_embedding)\n",
    "\n",
    "    def forward(self, token_embedding: Tensor):\n",
    "        return self.dropout(token_embedding + self.pos_embedding[:token_embedding.size(0), :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "f46f0044-c527-45b8-9ae3-22783e3a7563",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TokenEmbedding(nn.Module):\n",
    "    def __init__(self, vocab_size: int, d_model):\n",
    "        super(TokenEmbedding, self).__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, d_model)\n",
    "        self.d_model = d_model\n",
    "\n",
    "    def forward(self, tokens: Tensor):\n",
    "        return self.embedding(tokens.long()) * math.sqrt(self.d_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "9847af02-9cda-47d2-acb2-b6993bb438bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecoderBlock(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        d_model: int = 256,\n",
    "        nhead: int = 8,\n",
    "        num_decoder_layers: int = 3,\n",
    "        dim_feedforward: int = 512,\n",
    "        dropout: float = 0.1\n",
    "    ):\n",
    "        super(DecoderBlock, self).__init__()\n",
    "        self.decoder_layer = nn.TransformerDecoderLayer(\n",
    "            d_model=d_model,\n",
    "            nhead=nhead,\n",
    "            dim_feedforward=dim_feedforward,\n",
    "            dropout=dropout\n",
    "        )\n",
    "        \n",
    "        self.decoder = nn.TransformerDecoder(self.decoder_layer, num_layers=num_decoder_layers)\n",
    "    def forward(\n",
    "        self,\n",
    "        tgt,\n",
    "        memory,\n",
    "        tgt_mask=None,\n",
    "        memory_mask=None,\n",
    "        tgt_key_padding_mask=None,\n",
    "        memory_key_padding_mask=None\n",
    "    ):\n",
    "        output = self.decoder(\n",
    "            tgt,\n",
    "            memory, \n",
    "            tgt_mask=tgt_mask,\n",
    "            memory_mask=memory_mask,\n",
    "            tgt_key_padding_mask=tgt_key_padding_mask, \n",
    "            memory_key_padding_mask=memory_key_padding_mask\n",
    "        )\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "2ac27d96-bee4-4092-97ce-6cae97426be5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x17bff0da430>"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "278a71da-8d1e-404f-a617-04cc2600d733",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "31.0"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "124/4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "e7f04d8f-5797-4624-a2de-0bffcbb99085",
   "metadata": {},
   "outputs": [],
   "source": [
    "# configs\n",
    "NUM_DECODER_LAYERS = 3\n",
    "DIM_FF = 512\n",
    "D_MODEL = 256\n",
    "N_HEADS = 8\n",
    "VOCAB_SIZE = len(vocab_transform)\n",
    "DROPOUT = 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "6cb81740-374c-4de9-a5a6-f0f7df4876f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GooglePlayModel(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        num_decoder_layers: int = NUM_DECODER_LAYERS,\n",
    "        d_model: int = D_MODEL,\n",
    "        nhead: int = N_HEADS,\n",
    "        vocab_size: int = VOCAB_SIZE,\n",
    "        dim_feedforward: int = DIM_FF,\n",
    "        dropout: float = DROPOUT\n",
    "    ):\n",
    "        super(GooglePlayModel, self).__init__()\n",
    "        self.positional_encoding = PositionalEncoding(d_model=d_model, dropout=dropout)\n",
    "        self.embedding = TokenEmbedding(vocab_size=vocab_size, d_model=d_model)\n",
    "        self.decoder = DecoderBlock(\n",
    "            d_model=d_model,\n",
    "            nhead=nhead,\n",
    "            num_decoder_layers=num_decoder_layers,\n",
    "            dim_feedforward=dim_feedforward,\n",
    "            dropout=dropout\n",
    "        )\n",
    "        self.generator = nn.Linear(d_model, vocab_size)\n",
    "\n",
    "    def forward(self, x, mask, memory_mask):\n",
    "        pos_enc = self.positional_encoding(self.embedding(x))\n",
    "        decoder_output = self.decoder(pos_enc, tgt_mask=mask, memory_mask=memory_mask)\n",
    "        output = self.generator(decoder_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "8f82f310-1e1e-4561-9b1b-2cbe0f4a84df",
   "metadata": {},
   "outputs": [],
   "source": [
    "google_decoder = GooglePlayModel().to(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "29fedd6a-8598-4895-8312-5e4bc640eb8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchinfo import summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "8e9fc2c9-b1e3-41c3-b2a2-cd7f479e627e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "===============================================================================================\n",
       "Layer (type:depth-idx)                                                 Param #\n",
       "===============================================================================================\n",
       "GooglePlayModel                                                        --\n",
       "├─PositionalEncoding: 1-1                                              --\n",
       "│    └─Dropout: 2-1                                                    --\n",
       "├─TokenEmbedding: 1-2                                                  --\n",
       "│    └─Embedding: 2-2                                                  3,940,352\n",
       "├─DecoderBlock: 1-3                                                    --\n",
       "│    └─TransformerDecoderLayer: 2-3                                    --\n",
       "│    │    └─MultiheadAttention: 3-1                                    263,168\n",
       "│    │    └─MultiheadAttention: 3-2                                    263,168\n",
       "│    │    └─Linear: 3-3                                                131,584\n",
       "│    │    └─Dropout: 3-4                                               --\n",
       "│    │    └─Linear: 3-5                                                131,328\n",
       "│    │    └─LayerNorm: 3-6                                             512\n",
       "│    │    └─LayerNorm: 3-7                                             512\n",
       "│    │    └─LayerNorm: 3-8                                             512\n",
       "│    │    └─Dropout: 3-9                                               --\n",
       "│    │    └─Dropout: 3-10                                              --\n",
       "│    │    └─Dropout: 3-11                                              --\n",
       "│    └─TransformerDecoder: 2-4                                         --\n",
       "│    │    └─ModuleList: 3-12                                           2,372,352\n",
       "├─Linear: 1-4                                                          3,955,744\n",
       "===============================================================================================\n",
       "Total params: 11,059,232\n",
       "Trainable params: 11,059,232\n",
       "Non-trainable params: 0\n",
       "==============================================================================================="
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary(google_decoder, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "a63be7fd-8027-4b6d-ba80-905526f6e90e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memória alocada na GPU: 117.09423828125 MB\n"
     ]
    }
   ],
   "source": [
    "allocated_memory = torch.cuda.memory_allocated()\n",
    "print(\"Memória alocada na GPU:\", allocated_memory / 1024**2, \"MB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "04702054-bbd1-47de-8d99-0cf1d969ec81",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "forward() missing 1 required positional argument: 'memory'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[85], line 7\u001b[0m\n\u001b[0;32m      5\u001b[0m tgt \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mrand(\u001b[38;5;241m20\u001b[39m, \u001b[38;5;241m32\u001b[39m, \u001b[38;5;241m512\u001b[39m)\n\u001b[0;32m      6\u001b[0m \u001b[38;5;66;03m# out = transformer_decoder(tgt, memory)\u001b[39;00m\n\u001b[1;32m----> 7\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[43mtransformer_decoder\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtgt\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mM:\\disco M\\Python\\venvs\\env_torch\\lib\\site-packages\\torch\\nn\\modules\\module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "\u001b[1;31mTypeError\u001b[0m: forward() missing 1 required positional argument: 'memory'"
     ]
    }
   ],
   "source": [
    "# testando o decoder\n",
    "decoder_layer = nn.TransformerDecoderLayer(d_model=512, nhead=8)\n",
    "transformer_decoder = nn.TransformerDecoder(decoder_layer, num_layers=6)\n",
    "# memory = torch.rand(10, 32, 512)\n",
    "tgt = torch.rand(20, 32, 512)\n",
    "# out = transformer_decoder(tgt, memory)\n",
    "out = transformer_decoder(tgt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "99dd0884-eb15-4aeb-aac1-13e4c7d28d95",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "The shape of the 3D attn_mask is torch.Size([32, 20, 20]), but should be (256, 20, 20).",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[86], line 68\u001b[0m\n\u001b[0;32m     65\u001b[0m trg \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mrandint(\u001b[38;5;241m0\u001b[39m, output_dim, (\u001b[38;5;241m20\u001b[39m, \u001b[38;5;241m32\u001b[39m))  \u001b[38;5;66;03m# (target sequence length, batch size)\u001b[39;00m\n\u001b[0;32m     67\u001b[0m \u001b[38;5;66;03m# Forward pass\u001b[39;00m\n\u001b[1;32m---> 68\u001b[0m output \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmemory\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrg\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     69\u001b[0m \u001b[38;5;28mprint\u001b[39m(output\u001b[38;5;241m.\u001b[39mshape)  \n",
      "File \u001b[1;32mM:\\disco M\\Python\\venvs\\env_torch\\lib\\site-packages\\torch\\nn\\modules\\module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "Cell \u001b[1;32mIn[86], line 48\u001b[0m, in \u001b[0;36mSeq2SeqModel.forward\u001b[1;34m(self, memory, trg)\u001b[0m\n\u001b[0;32m     45\u001b[0m trg \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdecoder_embedding(trg) \u001b[38;5;241m*\u001b[39m math\u001b[38;5;241m.\u001b[39msqrt(memory\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m))\n\u001b[0;32m     46\u001b[0m trg \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpositional_encoding(trg)\n\u001b[1;32m---> 48\u001b[0m output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecoder\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtgt\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmemory\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmemory\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtgt_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrg_mask\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     49\u001b[0m output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfc_out(output)\n\u001b[0;32m     51\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m output\n",
      "File \u001b[1;32mM:\\disco M\\Python\\venvs\\env_torch\\lib\\site-packages\\torch\\nn\\modules\\module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[1;32mM:\\disco M\\Python\\venvs\\env_torch\\lib\\site-packages\\torch\\nn\\modules\\transformer.py:369\u001b[0m, in \u001b[0;36mTransformerDecoder.forward\u001b[1;34m(self, tgt, memory, tgt_mask, memory_mask, tgt_key_padding_mask, memory_key_padding_mask)\u001b[0m\n\u001b[0;32m    366\u001b[0m output \u001b[38;5;241m=\u001b[39m tgt\n\u001b[0;32m    368\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m mod \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlayers:\n\u001b[1;32m--> 369\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[43mmod\u001b[49m\u001b[43m(\u001b[49m\u001b[43moutput\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmemory\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtgt_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtgt_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    370\u001b[0m \u001b[43m                 \u001b[49m\u001b[43mmemory_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmemory_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    371\u001b[0m \u001b[43m                 \u001b[49m\u001b[43mtgt_key_padding_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtgt_key_padding_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    372\u001b[0m \u001b[43m                 \u001b[49m\u001b[43mmemory_key_padding_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmemory_key_padding_mask\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    374\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnorm \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    375\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnorm(output)\n",
      "File \u001b[1;32mM:\\disco M\\Python\\venvs\\env_torch\\lib\\site-packages\\torch\\nn\\modules\\module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[1;32mM:\\disco M\\Python\\venvs\\env_torch\\lib\\site-packages\\torch\\nn\\modules\\transformer.py:716\u001b[0m, in \u001b[0;36mTransformerDecoderLayer.forward\u001b[1;34m(self, tgt, memory, tgt_mask, memory_mask, tgt_key_padding_mask, memory_key_padding_mask, tgt_is_causal, memory_is_causal)\u001b[0m\n\u001b[0;32m    714\u001b[0m     x \u001b[38;5;241m=\u001b[39m x \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_ff_block(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnorm3(x))\n\u001b[0;32m    715\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 716\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnorm1(x \u001b[38;5;241m+\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sa_block\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtgt_mask\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtgt_key_padding_mask\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtgt_is_causal\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m    717\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnorm2(x \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_mha_block(x, memory, memory_mask, memory_key_padding_mask, memory_is_causal))\n\u001b[0;32m    718\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnorm3(x \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_ff_block(x))\n",
      "File \u001b[1;32mM:\\disco M\\Python\\venvs\\env_torch\\lib\\site-packages\\torch\\nn\\modules\\transformer.py:725\u001b[0m, in \u001b[0;36mTransformerDecoderLayer._sa_block\u001b[1;34m(self, x, attn_mask, key_padding_mask, is_causal)\u001b[0m\n\u001b[0;32m    723\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_sa_block\u001b[39m(\u001b[38;5;28mself\u001b[39m, x: Tensor,\n\u001b[0;32m    724\u001b[0m               attn_mask: Optional[Tensor], key_padding_mask: Optional[Tensor], is_causal: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[1;32m--> 725\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mself_attn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    726\u001b[0m \u001b[43m                       \u001b[49m\u001b[43mattn_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattn_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    727\u001b[0m \u001b[43m                       \u001b[49m\u001b[43mkey_padding_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkey_padding_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    728\u001b[0m \u001b[43m                       \u001b[49m\u001b[43mis_causal\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_causal\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    729\u001b[0m \u001b[43m                       \u001b[49m\u001b[43mneed_weights\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m    730\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdropout1(x)\n",
      "File \u001b[1;32mM:\\disco M\\Python\\venvs\\env_torch\\lib\\site-packages\\torch\\nn\\modules\\module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[1;32mM:\\disco M\\Python\\venvs\\env_torch\\lib\\site-packages\\torch\\nn\\modules\\activation.py:1205\u001b[0m, in \u001b[0;36mMultiheadAttention.forward\u001b[1;34m(self, query, key, value, key_padding_mask, need_weights, attn_mask, average_attn_weights, is_causal)\u001b[0m\n\u001b[0;32m   1191\u001b[0m     attn_output, attn_output_weights \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39mmulti_head_attention_forward(\n\u001b[0;32m   1192\u001b[0m         query, key, value, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39membed_dim, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_heads,\n\u001b[0;32m   1193\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39min_proj_weight, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39min_proj_bias,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1202\u001b[0m         average_attn_weights\u001b[38;5;241m=\u001b[39maverage_attn_weights,\n\u001b[0;32m   1203\u001b[0m         is_causal\u001b[38;5;241m=\u001b[39mis_causal)\n\u001b[0;32m   1204\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1205\u001b[0m     attn_output, attn_output_weights \u001b[38;5;241m=\u001b[39m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmulti_head_attention_forward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1206\u001b[0m \u001b[43m        \u001b[49m\u001b[43mquery\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43membed_dim\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnum_heads\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1207\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43min_proj_weight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43min_proj_bias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1208\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias_k\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias_v\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43madd_zero_attn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1209\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdropout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mout_proj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mout_proj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1210\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtraining\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtraining\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1211\u001b[0m \u001b[43m        \u001b[49m\u001b[43mkey_padding_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkey_padding_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1212\u001b[0m \u001b[43m        \u001b[49m\u001b[43mneed_weights\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mneed_weights\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1213\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattn_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattn_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1214\u001b[0m \u001b[43m        \u001b[49m\u001b[43maverage_attn_weights\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maverage_attn_weights\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1215\u001b[0m \u001b[43m        \u001b[49m\u001b[43mis_causal\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_causal\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1216\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbatch_first \u001b[38;5;129;01mand\u001b[39;00m is_batched:\n\u001b[0;32m   1217\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m attn_output\u001b[38;5;241m.\u001b[39mtranspose(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m0\u001b[39m), attn_output_weights\n",
      "File \u001b[1;32mM:\\disco M\\Python\\venvs\\env_torch\\lib\\site-packages\\torch\\nn\\functional.py:5256\u001b[0m, in \u001b[0;36mmulti_head_attention_forward\u001b[1;34m(query, key, value, embed_dim_to_check, num_heads, in_proj_weight, in_proj_bias, bias_k, bias_v, add_zero_attn, dropout_p, out_proj_weight, out_proj_bias, training, key_padding_mask, need_weights, attn_mask, use_separate_proj_weight, q_proj_weight, k_proj_weight, v_proj_weight, static_k, static_v, average_attn_weights, is_causal)\u001b[0m\n\u001b[0;32m   5254\u001b[0m     correct_3d_size \u001b[38;5;241m=\u001b[39m (bsz \u001b[38;5;241m*\u001b[39m num_heads, tgt_len, src_len)\n\u001b[0;32m   5255\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m attn_mask\u001b[38;5;241m.\u001b[39mshape \u001b[38;5;241m!=\u001b[39m correct_3d_size:\n\u001b[1;32m-> 5256\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe shape of the 3D attn_mask is \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mattn_mask\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, but should be \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcorrect_3d_size\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m   5257\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   5258\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mattn_mask\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124ms dimension \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mattn_mask\u001b[38;5;241m.\u001b[39mdim()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m is not supported\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mRuntimeError\u001b[0m: The shape of the 3D attn_mask is torch.Size([32, 20, 20]), but should be (256, 20, 20)."
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import math\n",
    "\n",
    "class PositionalEncoding(nn.Module):\n",
    "    def __init__(self, d_model, dropout, max_len=5000):\n",
    "        super(PositionalEncoding, self).__init__()\n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "\n",
    "        pe = torch.zeros(max_len, d_model)\n",
    "        position = torch.arange(0, max_len, dtype=torch.float).unsqueeze(1)\n",
    "        div_term = torch.exp(torch.arange(0, d_model, 2).float() * (-math.log(10000.0) / d_model))\n",
    "        pe[:, 0::2] = torch.sin(position * div_term)\n",
    "        pe[:, 1::2] = torch.cos(position * div_term)\n",
    "        pe = pe.unsqueeze(0).transpose(0, 1)\n",
    "        self.register_buffer('pe', pe)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x + self.pe[:x.size(0), :]\n",
    "        return self.dropout(x)\n",
    "\n",
    "class Seq2SeqModel(nn.Module):\n",
    "    def __init__(self, output_dim, d_model, nhead, num_decoder_layers, dim_feedforward, dropout):\n",
    "        super(Seq2SeqModel, self).__init__()\n",
    "        \n",
    "        self.decoder_embedding = nn.Embedding(output_dim, d_model)\n",
    "        self.positional_encoding = PositionalEncoding(d_model, dropout)\n",
    "        \n",
    "        decoder_layer = nn.TransformerDecoderLayer(d_model, nhead, dim_feedforward, dropout)\n",
    "        self.decoder = nn.TransformerDecoder(decoder_layer, num_layers=num_decoder_layers)\n",
    "        \n",
    "        self.fc_out = nn.Linear(d_model, output_dim)\n",
    "\n",
    "    def make_trg_mask(self, trg):\n",
    "        trg_pad_mask = (trg.transpose(0, 1) == 0).unsqueeze(-2)\n",
    "        trg_len = trg.shape[0]\n",
    "        trg_sub_mask = torch.tril(torch.ones((trg_len, trg_len), device=trg.device)).bool()\n",
    "        trg_mask = trg_pad_mask & trg_sub_mask\n",
    "        return trg_mask\n",
    "    \n",
    "    def forward(self, memory, trg):\n",
    "        trg_mask = self.make_trg_mask(trg)\n",
    "        \n",
    "        trg = self.decoder_embedding(trg) * math.sqrt(memory.size(-1))\n",
    "        trg = self.positional_encoding(trg)\n",
    "        \n",
    "        output = self.decoder(tgt=trg, memory=memory, tgt_mask=trg_mask)\n",
    "        output = self.fc_out(output)\n",
    "        \n",
    "        return output\n",
    "\n",
    "# Define hyperparameters and instantiate the model\n",
    "output_dim = 1000\n",
    "d_model = 512\n",
    "nhead = 8\n",
    "num_decoder_layers = 6\n",
    "dim_feedforward = 2048\n",
    "dropout = 0.1\n",
    "\n",
    "model = Seq2SeqModel(output_dim, d_model, nhead, num_decoder_layers, dim_feedforward, dropout)\n",
    "\n",
    "# Example input data\n",
    "memory = torch.randn(10, 32, d_model)  # (memory sequence length, batch size, d_model)\n",
    "trg = torch.randint(0, output_dim, (20, 32))  # (target sequence length, batch size)\n",
    "\n",
    "# Forward pass\n",
    "output = model(memory, trg)\n",
    "print(output.shape)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d0cd020-843c-44ee-b8b7-3de38fbbd0d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "transformer_decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "fdd6506c-303a-4a90-9c7a-41dd0c26bfe0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0.1118, -1.1710, -0.8959,  ...,  2.2851, -1.6192, -0.4946],\n",
       "         [ 0.8053, -0.6150, -1.0398,  ...,  2.0859, -1.3613, -0.5439],\n",
       "         [ 0.7293, -0.3388, -1.3759,  ...,  1.4920, -2.3704, -0.8122],\n",
       "         ...,\n",
       "         [-0.0059, -0.7287, -0.5765,  ...,  1.6382, -1.9487, -0.1709],\n",
       "         [ 0.4550, -0.9516, -1.5670,  ...,  1.5000, -1.2282, -0.3235],\n",
       "         [ 0.8331, -0.7414, -1.4953,  ...,  1.4084, -1.8277, -0.1350]],\n",
       "\n",
       "        [[ 0.0180, -1.0446, -1.0010,  ...,  1.6590, -1.4273, -0.2397],\n",
       "         [ 0.7317, -0.9325, -1.5092,  ...,  1.6700, -1.7922, -1.0420],\n",
       "         [-0.3930, -0.5197, -1.2167,  ...,  1.4408, -2.1300,  0.1562],\n",
       "         ...,\n",
       "         [-0.0971, -0.4941, -0.4797,  ...,  2.0280, -1.5911, -0.1578],\n",
       "         [ 0.2414, -1.0646, -2.2118,  ...,  1.7787, -1.5203, -0.9634],\n",
       "         [ 1.3117, -0.4621, -0.8127,  ...,  1.8086, -1.5333, -0.6950]],\n",
       "\n",
       "        [[ 0.5540, -1.1116, -2.3528,  ...,  1.2588, -2.1234, -0.2447],\n",
       "         [ 0.7436, -0.6004, -1.4084,  ...,  1.7221, -2.3653, -0.8093],\n",
       "         [ 0.1223, -0.1864, -1.5936,  ...,  0.1677, -2.3417, -0.7038],\n",
       "         ...,\n",
       "         [ 0.3275, -0.1810, -0.4733,  ...,  2.0208, -1.1291, -0.2971],\n",
       "         [ 0.7539, -0.5880, -1.9893,  ...,  1.9098, -1.0860, -1.4246],\n",
       "         [ 0.7430, -0.5961, -1.7549,  ...,  1.2740, -1.9138, -0.8634]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[ 0.4232, -1.4324, -1.8080,  ...,  1.7341, -1.6154, -0.4849],\n",
       "         [ 0.5523, -1.0602, -1.5547,  ...,  1.7536, -1.7173, -0.2753],\n",
       "         [ 0.8387, -0.8044, -1.2409,  ...,  1.4166, -2.5106,  0.1109],\n",
       "         ...,\n",
       "         [-0.3461, -0.7946, -0.5319,  ...,  2.0450, -0.9474, -0.4649],\n",
       "         [ 0.8699, -0.9709, -1.9962,  ...,  1.9580, -1.9209, -0.6571],\n",
       "         [ 0.6855, -1.0975, -1.7367,  ...,  2.4008, -1.9066, -0.7733]],\n",
       "\n",
       "        [[ 0.1318, -1.3042, -1.5723,  ...,  2.3423, -1.7424,  0.1064],\n",
       "         [ 1.0939, -0.3920, -1.9614,  ...,  1.3863, -1.6016, -1.3510],\n",
       "         [-0.3091, -0.5290, -1.3248,  ...,  1.2278, -1.7089, -0.7325],\n",
       "         ...,\n",
       "         [-0.2391, -0.1701, -0.1926,  ...,  1.4633, -1.5964, -0.7101],\n",
       "         [ 0.7575, -1.6059, -0.8533,  ...,  1.3231, -1.8464, -1.0100],\n",
       "         [ 0.5777, -0.3833, -2.1198,  ...,  1.6494, -1.9766, -1.0389]],\n",
       "\n",
       "        [[ 0.4998, -1.0045, -1.7608,  ...,  1.9522, -1.9623, -0.3721],\n",
       "         [ 1.3146, -0.2874, -0.7724,  ...,  2.6229, -1.5519, -0.5939],\n",
       "         [-0.4202, -0.7439, -0.9851,  ...,  1.2867, -2.5186, -0.4945],\n",
       "         ...,\n",
       "         [-0.4051, -0.2992, -0.3700,  ...,  2.5998, -1.8539, -0.5913],\n",
       "         [ 0.8665, -1.1731, -1.6594,  ...,  1.5213, -2.1547, -1.0328],\n",
       "         [ 0.5862, -0.7278, -1.6231,  ...,  1.9906, -2.2834, -0.3646]]],\n",
       "       grad_fn=<NativeLayerNormBackward0>)"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0e43ca6-feab-48bb-a061-b32da3440686",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f02174fe-75bb-48ad-bfaf-d961675ad2fa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4aaa5e8-a3bd-4f79-8614-9281b7d2eecb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3d3489bf-7c88-402b-a850-309c0863d15f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9512bb6-a4c4-4ff4-8a84-f6f9d44e91b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "for ln in [SRC_LANGUAGE, TGT_LANGUAGE]:\n",
    "    # Training data Iterator\n",
    "    train_iter = Multi30k(split='train', language_pair=(SRC_LANGUAGE, TGT_LANGUAGE))\n",
    "    # Create torchtext's Vocab object\n",
    "    vocab_transform[ln] = build_vocab_from_iterator(yield_tokens(train_iter, ln),\n",
    "                                                    min_freq=1,\n",
    "                                                    specials=special_symbols,\n",
    "                                                    special_first=True)\n",
    "\n",
    "# Set ``UNK_IDX`` as the default index. This index is returned when the token is not found.\n",
    "# If not set, it throws ``RuntimeError`` when the queried token is not found in the Vocabulary.\n",
    "for ln in [SRC_LANGUAGE, TGT_LANGUAGE]:\n",
    "    vocab_transform[ln].set_default_index(UNK_IDX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5094212b-fdbe-4404-9660-c83a69e65c3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\luiz_\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# usando o tokenizer\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "from nltk.tokenize import word_tokenize\n",
    "from typing import List, Dict\n",
    "from unidecode import unidecode\n",
    "from nltk.tokenize.treebank import TreebankWordDetokenizer\n",
    "\n",
    "class MyWordLevelTokenizer:\n",
    "    def __init__(self):\n",
    "        self.mode = 'train'\n",
    "        self.special_tokens = {\n",
    "            'PAD': 0,\n",
    "            'UNK': 1,\n",
    "            'SOS': 2,\n",
    "            'EOF': 3\n",
    "        }\n",
    "        self.vocab = {**self.special_tokens}\n",
    "        self.id_token = {v: k for k, v in self.vocab.items()}\n",
    "        self.normalize: bool = True\n",
    "    \n",
    "    def encode(self, text: str) -> List[str]:\n",
    "        if self.normalize:\n",
    "            text = unidecode(text)\n",
    "\n",
    "        tokens = word_tokenize(text, language='portuguese')\n",
    "\n",
    "        if self.mode == 'train':\n",
    "            for token in tokens:\n",
    "                if token not in self.vocab:\n",
    "                    id_ = max(self.vocab.values()) + 1\n",
    "                    self.vocab[token] = id_\n",
    "                    self.id_token[id_] = token\n",
    "        return tokens\n",
    "\n",
    "    def decoder(self, ids_list: List[int]):\n",
    "        return TreebankWordDetokenizer().detokenize(ids_list)\n",
    "\n",
    "    def tokens_to_ids(self, tokens_list: List[str]):\n",
    "        return [self.vocab[token] for token in tokens_list]\n",
    "\n",
    "    def ids_to_tokens(self, ids_list: List[int]):\n",
    "        return [self.id_token[id_] for id_ in ids_list]\n",
    "\n",
    "    def add_special_tokens(self, special_tokens: Dict[str, int]):\n",
    "        self.special_tokens = {**special_tokens}\n",
    "        return self.special_tokens\n",
    "\n",
    "    def encoder_txt(self, text: str) -> List[int]:\n",
    "        tokens_list = self.encode(text)\n",
    "        # tokens_list = self.cut_seq(tokens_list)\n",
    "        ids_list = self.tokens_to_ids(tokens_list)\n",
    "        return ids_list\n",
    "\n",
    "    def decoder_ids(self, ids_list: List[int]):\n",
    "        tokens_list = self.ids_to_tokens(ids_list)\n",
    "        print(tokens_list)\n",
    "        return self.decoder(tokens_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b3039ed7-a520-4e5f-bd72-a332d4ad5d75",
   "metadata": {},
   "outputs": [],
   "source": [
    "d = MyWordLevelTokenizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e14c6c48-b64c-4813-b233-aa0060db6e38",
   "metadata": {},
   "outputs": [],
   "source": [
    "# gerando o Dataset\n",
    "import torch\n",
    "import numpy as np\n",
    "from torch.utils.data import Dataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "dfce011b-e9fd-489e-ac34-ea0ff92b88bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GooglePlayAppsPt(Dataset):\n",
    "    def __init__(self, data, tokenizer: MyWordLevelTokenizer, max_len: int = 124):\n",
    "        self.data = data\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_len = max_len\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.data.num_rows\n",
    "\n",
    "    def __getitem__(self, id_i):\n",
    "        item = self.data[id_i]\n",
    "        text = item['review']\n",
    "        text_to_ids = self.tokenizer.encoder_txt(text)\n",
    "        text_to_ids = self.cut_seq(text_to_ids)\n",
    "\n",
    "        tokenized = torch.from_numpy(np.array(text_to_ids))\n",
    "        tokenized = torch.tensor(tokenized, dtype=torch.long)\n",
    "        \n",
    "        decoder_input = tokenized[: self.max_len]\n",
    "        desired_output = tokenized[1 : self.max_len + 1]\n",
    "        return {'decoder_input': decoder_input, 'desired_output': desired_output}\n",
    "        \n",
    "    def cut_seq(self, ids_list: List[str]):\n",
    "        len_token_list = len(ids_list)\n",
    "        if len_token_list > self.max_len + 1:\n",
    "            return ids_list[: self.max_len + 1]\n",
    "        elif len_token_list < self.max_len + 1:\n",
    "            return ids_list + [0] * (self.max_len + 1 - len_token_list)\n",
    "        return ids_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "98224eae-1899-4c2e-a5d8-83ed7457a7cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['review', 'sentiment'],\n",
       "        num_rows: 20000\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f0c994c9-c9ed-4ce1-8f5b-14aadce59967",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer=MyWordLevelTokenizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7fa49ef5-380d-4167-b267-383159a8f577",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_train = GooglePlayAppsPt(dataset['train'], tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f3bea264-63ed-456e-9f7b-f6ef25b03534",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\luiz_\\AppData\\Local\\Temp\\ipykernel_20576\\2861760060.py:17: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  tokenized = torch.tensor(tokenized, dtype=torch.long)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'decoder_input': tensor([ 4,  5,  6,  7,  8,  9, 10,  4, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20,\n",
       "         21, 22, 23, 24, 16, 25, 26,  4, 27, 28, 29, 30, 16, 31, 32, 33,  6, 34,\n",
       "         28, 15, 16, 35, 36, 37, 38, 39, 40, 41, 31, 42, 43, 44, 28, 15, 16, 45,\n",
       "         46, 47, 31, 48, 49, 16, 50, 45,  4,  5, 20, 51, 52, 53,  6, 54, 55,  4,\n",
       "         56, 57,  5, 20, 58, 59, 60, 47, 40, 61, 62, 28, 15, 16, 63, 64, 26, 65,\n",
       "          6, 63, 66, 26, 67, 68, 69, 70, 71, 72, 28, 73, 16, 31, 74, 75, 20, 76,\n",
       "         38, 10, 77, 78, 29, 79, 10, 80, 81, 82, 44, 83, 84, 85, 86, 16]),\n",
       " 'desired_output': tensor([ 5,  6,  7,  8,  9, 10,  4, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21,\n",
       "         22, 23, 24, 16, 25, 26,  4, 27, 28, 29, 30, 16, 31, 32, 33,  6, 34, 28,\n",
       "         15, 16, 35, 36, 37, 38, 39, 40, 41, 31, 42, 43, 44, 28, 15, 16, 45, 46,\n",
       "         47, 31, 48, 49, 16, 50, 45,  4,  5, 20, 51, 52, 53,  6, 54, 55,  4, 56,\n",
       "         57,  5, 20, 58, 59, 60, 47, 40, 61, 62, 28, 15, 16, 63, 64, 26, 65,  6,\n",
       "         63, 66, 26, 67, 68, 69, 70, 71, 72, 28, 73, 16, 31, 74, 75, 20, 76, 38,\n",
       "         10, 77, 78, 29, 79, 10, 80, 81, 82, 44, 83, 84, 85, 86, 16, 51])}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f1f0d09f-fc90-41ca-b4f7-2fbabd73131e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataloader\n",
    "BATCH_SIZE = 16\n",
    "dataloader = DataLoader(dataset_train, batch_size=BATCH_SIZE, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e8f8904f-5ec7-49a4-bf02-ae134de96ff2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model\n",
    "import torch.nn as nn\n",
    "import math\n",
    "\n",
    "def generate_square_subsequent_mask(sz):\n",
    "    \"\"\"\n",
    "    Generate a square mask for the sequence. The masked positions are filled with float('-inf').\n",
    "    Unmasked positions are filled with float(0.0).\n",
    "    \"\"\"\n",
    "    mask = (torch.triu(torch.ones(sz, sz)) == 1).transpose(0, 1)\n",
    "    mask = mask.float().masked_fill(mask == 0, float('-inf')).masked_fill(mask == 1, float(0.0))\n",
    "    return mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "440fbb87-ca36-4ff2-889f-b4d5a51e0b1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PositionalEncoding(nn.Module):\n",
    "    def __init__(self, max_len, d_model, dropout=0.1):\n",
    "        \"\"\"\n",
    "        :param max_len: Input length sequence.\n",
    "        :param d_model: Embedding dimension.\n",
    "        :param dropout: Dropout value (default=0.1)\n",
    "        \"\"\"\n",
    "        super(PositionalEncoding, self).__init__()\n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "        pe = torch.zeros(max_len, d_model)\n",
    "        position = torch.arange(0, max_len, dtype=torch.float).unsqueeze(1)\n",
    "        div_term = torch.exp(torch.arange(0, d_model, 2).float() * (-math.log(10000.0) / d_model))\n",
    "        pe[:, 0::2] = torch.sin(position * div_term)\n",
    "        pe[:, 1::2] = torch.cos(position * div_term)\n",
    "        pe = pe.unsqueeze(0)\n",
    "        self.register_buffer('pe', pe)\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        Inputs of forward function\n",
    "        :param x: the sequence fed to the positional encoder model (required).\n",
    "        Shape:\n",
    "            x: [sequence length, batch size, embed dim]\n",
    "            output: [sequence length, batch size, embed dim]\n",
    "        \"\"\"\n",
    "        x = x + self.pe[:, :x.size(1)]\n",
    "        return self.dropout(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "84f8f030-a525-4508-9fc3-016f75b00875",
   "metadata": {},
   "outputs": [],
   "source": [
    "SEQUENCE_LENGTH = 124\n",
    "\n",
    "class GooglePlayModel(nn.Module):\n",
    "    def __init__(self, vocab_size, embed_dim, num_layers, num_heads):\n",
    "        super(GooglePlayModel, self).__init__()\n",
    "        self.pos_encoder = PositionalEncoding(max_len=SEQUENCE_LENGTH, d_model=embed_dim)\n",
    "        self.emb = nn.Embedding(vocab_size, embed_dim)\n",
    "        self.decoder_layer = nn.TransformerDecoderLayer(\n",
    "            d_model=embed_dim, \n",
    "            nhead=num_heads, \n",
    "            batch_first=True\n",
    "        )\n",
    "        self.decoder = nn.TransformerDecoder(\n",
    "            decoder_layer=self.decoder_layer,\n",
    "            num_layers=num_layers,\n",
    "        )\n",
    "        self.linear = nn.Linear(embed_dim, vocab_size)\n",
    "        self.dropout = nn.Dropout(0.2)\n",
    "        \n",
    "    # Positional encoding is required. Else the model does not learn.\n",
    "    def forward(self, x):\n",
    "        emb = self.emb(x)\n",
    "        \n",
    "        # Generate input sequence mask with shape (SEQUENCE_LENGTH, SEQUENCE_LENGTH)\n",
    "        input_mask = generate_square_subsequent_mask(x.size(1)).to(x.device)\n",
    "        \n",
    "        x = self.pos_encoder(emb)\n",
    "        x = self.decoder(x, memory=x, tgt_mask=input_mask, memory_mask=input_mask)\n",
    "        x = self.dropout(x)\n",
    "        out = self.linear(x)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2731edb7-a0d5-492d-ac6a-369a3f2c4529",
   "metadata": {},
   "outputs": [],
   "source": [
    "for text in dataset['train']:\n",
    "    tokenizer.encoder_txt(text['review'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "1fdbb832-862b-46b7-93ec-de3b3dc580d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 100\n",
    "learning_rate = 1e-5\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = GooglePlayModel(\n",
    "    vocab_size=len(tokenizer.vocab), \n",
    "    embed_dim=256,\n",
    "    num_layers=2, \n",
    "    num_heads=4,\n",
    ").to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "f24304dc-5b99-4422-aef4-349e8a6fdb23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ignorando o parâmetro emb.weight devido ao tamanho incompatível.\n",
      "Ignorando o parâmetro linear.weight devido ao tamanho incompatível.\n",
      "Ignorando o parâmetro linear.bias devido ao tamanho incompatível.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Carregue o estado salvo, ignorando os parâmetros com tamanho diferente\n",
    "checkpoint = torch.load('model/googleplay_model_9.pth', map_location=device)\n",
    "\n",
    "# Crie uma nova state_dict ignorando os parâmetros com tamanho diferente\n",
    "model_state_dict = model.state_dict()\n",
    "for key in checkpoint.keys():\n",
    "    if key in model_state_dict and checkpoint[key].size() == model_state_dict[key].size():\n",
    "        model_state_dict[key] = checkpoint[key]\n",
    "    else:\n",
    "        print(f\"Ignorando o parâmetro {key} devido ao tamanho incompatível.\")\n",
    "\n",
    "model.load_state_dict(model_state_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "fb661e68-bb52-4a15-87e0-9e5c724f836b",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Error(s) in loading state_dict for GooglePlayModel:\n\tsize mismatch for emb.weight: copying a param with shape torch.Size([34853, 256]) from checkpoint, the shape in current model is torch.Size([34854, 256]).\n\tsize mismatch for linear.weight: copying a param with shape torch.Size([34853, 256]) from checkpoint, the shape in current model is torch.Size([34854, 256]).\n\tsize mismatch for linear.bias: copying a param with shape torch.Size([34853]) from checkpoint, the shape in current model is torch.Size([34854]).",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[31], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Carregar o modelo completo salvo\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_state_dict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mmodel/googleplay_model_8.pth\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# Colocar o modelo em modo de avaliação\u001b[39;00m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;66;03m# model.eval()\u001b[39;00m\n",
      "File \u001b[1;32mm:\\disco m\\python\\pythonprojects\\pytorch\\env_pytorch\\lib\\site-packages\\torch\\nn\\modules\\module.py:2041\u001b[0m, in \u001b[0;36mModule.load_state_dict\u001b[1;34m(self, state_dict, strict)\u001b[0m\n\u001b[0;32m   2036\u001b[0m         error_msgs\u001b[38;5;241m.\u001b[39minsert(\n\u001b[0;32m   2037\u001b[0m             \u001b[38;5;241m0\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMissing key(s) in state_dict: \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m. \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[0;32m   2038\u001b[0m                 \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(k) \u001b[38;5;28;01mfor\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m missing_keys)))\n\u001b[0;32m   2040\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(error_msgs) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m-> 2041\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mError(s) in loading state_dict for \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[0;32m   2042\u001b[0m                        \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(error_msgs)))\n\u001b[0;32m   2043\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _IncompatibleKeys(missing_keys, unexpected_keys)\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Error(s) in loading state_dict for GooglePlayModel:\n\tsize mismatch for emb.weight: copying a param with shape torch.Size([34853, 256]) from checkpoint, the shape in current model is torch.Size([34854, 256]).\n\tsize mismatch for linear.weight: copying a param with shape torch.Size([34853, 256]) from checkpoint, the shape in current model is torch.Size([34854, 256]).\n\tsize mismatch for linear.bias: copying a param with shape torch.Size([34853]) from checkpoint, the shape in current model is torch.Size([34854])."
     ]
    }
   ],
   "source": [
    "# Carregar o modelo completo salvo\n",
    "model.load_state_dict(torch.load('model/googleplay_model_8.pth'))\n",
    "\n",
    "# Colocar o modelo em modo de avaliação\n",
    "# model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15f7553f-8764-4814-b3ba-01eeaefec508",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GooglePlayModel(\n",
      "  (pos_encoder): PositionalEncoding(\n",
      "    (dropout): Dropout(p=0.1, inplace=False)\n",
      "  )\n",
      "  (emb): Embedding(34853, 256)\n",
      "  (decoder_layer): TransformerDecoderLayer(\n",
      "    (self_attn): MultiheadAttention(\n",
      "      (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)\n",
      "    )\n",
      "    (multihead_attn): MultiheadAttention(\n",
      "      (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)\n",
      "    )\n",
      "    (linear1): Linear(in_features=256, out_features=2048, bias=True)\n",
      "    (dropout): Dropout(p=0.1, inplace=False)\n",
      "    (linear2): Linear(in_features=2048, out_features=256, bias=True)\n",
      "    (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "    (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "    (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "    (dropout1): Dropout(p=0.1, inplace=False)\n",
      "    (dropout2): Dropout(p=0.1, inplace=False)\n",
      "    (dropout3): Dropout(p=0.1, inplace=False)\n",
      "  )\n",
      "  (decoder): TransformerDecoder(\n",
      "    (layers): ModuleList(\n",
      "      (0-1): 2 x TransformerDecoderLayer(\n",
      "        (self_attn): MultiheadAttention(\n",
      "          (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)\n",
      "        )\n",
      "        (multihead_attn): MultiheadAttention(\n",
      "          (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)\n",
      "        )\n",
      "        (linear1): Linear(in_features=256, out_features=2048, bias=True)\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "        (linear2): Linear(in_features=2048, out_features=256, bias=True)\n",
      "        (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "        (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "        (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "        (dropout1): Dropout(p=0.1, inplace=False)\n",
      "        (dropout2): Dropout(p=0.1, inplace=False)\n",
      "        (dropout3): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (linear): Linear(in_features=256, out_features=34853, bias=True)\n",
      "  (dropout): Dropout(p=0.2, inplace=False)\n",
      ")\n",
      "22,615,845 total parameters.\n",
      "22,615,845 training parameters.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "print(model)\n",
    "# Total parameters and trainable parameters.\n",
    "total_params = sum(p.numel() for p in model.parameters())\n",
    "print(f\"{total_params:,} total parameters.\")\n",
    "total_trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "print(f\"{total_trainable_params:,} training parameters.\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a1c88f30-f1f9-48a0-8c63-6d1e4fde2018",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\luiz_\\AppData\\Local\\Temp\\ipykernel_14504\\2861760060.py:17: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  tokenized = torch.tensor(tokenized, dtype=torch.long)\n"
     ]
    }
   ],
   "source": [
    "for batch in dataloader:\n",
    "    input_seq = batch['decoder_input'].to(device)\n",
    "    target_seq = batch['desired_output'].to(device)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "539edcbd-a062-42b6-908f-cedeb105a28a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch.autograd.anomaly_mode.set_detect_anomaly at 0x2225326bd30>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Defina esta variável para capturar melhor os erros\n",
    "import os\n",
    "os.environ['CUDA_LAUNCH_BLOCKING'] = '1'\n",
    "\n",
    "# Habilite a detecção de anomalias no grafo computacional\n",
    "torch.autograd.set_detect_anomaly(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4f7cc101-0768-48c1-b012-df2033eca6d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "2b1e44b2-3298-4ee0-858a-e6eee8f14bf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "2c25c9ac-a3de-42d4-90cd-36ac66fcdc62",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Path('model').exists()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "7121de3a-1b26-4697-850b-bda971f7c628",
   "metadata": {},
   "outputs": [],
   "source": [
    "def callbacks():\n",
    "    memory = {'loss': 0.0}\n",
    "\n",
    "    def memory_function(model, loss, epoch, path: Path = 'model'):\n",
    "        nonlocal memory\n",
    "        if loss < memory['loss']:\n",
    "            torch.save(model.state_dict(), path / Path(f'googleplay_model_{epoch}.pth'))\n",
    "        memory.update({'loss': loss})\n",
    "    return memory_function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "c263772f-1884-4fa4-892c-41ea1564fb05",
   "metadata": {},
   "outputs": [],
   "source": [
    "callback = callbacks()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "29a69599-ffd5-40cb-8cb3-cdcedaf8b4a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training\n",
    "from tqdm import tqdm\n",
    "def train(model, epochs, dataloader, criterion):\n",
    "    model.train()\n",
    "    epoch_loss = 0\n",
    "    for epoch in range(epochs):\n",
    "        torch.cuda.empty_cache()\n",
    "        running_loss = 0\n",
    "        batch_iterator = tqdm(dataloader, desc=f\"Processing Epoch {epoch:02d}\")\n",
    "        for batch in batch_iterator:\n",
    "            input_seq = batch['decoder_input'].to(device)\n",
    "            target_seq = batch['desired_output'].to(device)\n",
    "            outputs = model(input_seq)\n",
    "            target_seq = target_seq.contiguous().view(-1)\n",
    "            outputs = outputs.view(-1, len(tokenizer.vocab))\n",
    "            \n",
    "            loss = criterion(outputs, target_seq.view(-1))\n",
    "            callback(model, loss.item(), epoch)\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            running_loss += loss.detach().cpu().numpy()\n",
    "            batch_iterator.set_postfix({\"loss\": f\"{loss.item():6.3f}\", \"running loss\": f\"{running_loss:.3f}\", \"epoch loss\": f\"{epoch_loss:.3f}\"})\n",
    "        epoch_loss = running_loss / len(dataloader)\n",
    "        print(f\"Epoch {epoch} loss: {epoch_loss:.3f}\")        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "270df128-ddb5-44e3-adf8-d282961b9214",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Epoch 00:   0%|                                                                    | 0/1250 [00:00<?, ?it/s]C:\\Users\\luiz_\\AppData\\Local\\Temp\\ipykernel_14504\\2861760060.py:17: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  tokenized = torch.tensor(tokenized, dtype=torch.long)\n",
      "Processing Epoch 00: 100%|████| 1250/1250 [09:09<00:00,  2.27it/s, loss=3.979, running loss=5766.251, epoch loss=0.000]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 loss: 4.613\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Epoch 01: 100%|████| 1250/1250 [08:22<00:00,  2.49it/s, loss=3.679, running loss=4520.548, epoch loss=4.613]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 loss: 3.616\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Epoch 02: 100%|████| 1250/1250 [08:27<00:00,  2.46it/s, loss=3.558, running loss=4320.413, epoch loss=3.616]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2 loss: 3.456\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Epoch 03: 100%|████| 1250/1250 [08:57<00:00,  2.33it/s, loss=3.206, running loss=4212.708, epoch loss=3.456]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3 loss: 3.370\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Epoch 04: 100%|████| 1250/1250 [08:38<00:00,  2.41it/s, loss=3.667, running loss=4128.083, epoch loss=3.370]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4 loss: 3.302\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Epoch 05: 100%|████| 1250/1250 [08:20<00:00,  2.50it/s, loss=3.596, running loss=4057.672, epoch loss=3.302]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5 loss: 3.246\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Epoch 06: 100%|████| 1250/1250 [09:04<00:00,  2.29it/s, loss=3.209, running loss=3997.879, epoch loss=3.246]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6 loss: 3.198\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Epoch 07: 100%|████| 1250/1250 [09:03<00:00,  2.30it/s, loss=3.373, running loss=3946.192, epoch loss=3.198]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7 loss: 3.157\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Epoch 08: 100%|████| 1250/1250 [08:26<00:00,  2.47it/s, loss=2.898, running loss=3900.989, epoch loss=3.157]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8 loss: 3.121\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Epoch 09:   2%|▏       | 20/1250 [00:08<08:29,  2.42it/s, loss=3.184, running loss=61.621, epoch loss=3.121]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[47], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdataloader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m)\u001b[49m \n",
      "Cell \u001b[1;32mIn[46], line 20\u001b[0m, in \u001b[0;36mtrain\u001b[1;34m(model, epochs, dataloader, criterion)\u001b[0m\n\u001b[0;32m     18\u001b[0m callback(model, loss\u001b[38;5;241m.\u001b[39mitem(), epoch)\n\u001b[0;32m     19\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[1;32m---> 20\u001b[0m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     21\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[0;32m     22\u001b[0m running_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m loss\u001b[38;5;241m.\u001b[39mdetach()\u001b[38;5;241m.\u001b[39mcpu()\u001b[38;5;241m.\u001b[39mnumpy()\n",
      "File \u001b[1;32mm:\\disco m\\python\\pythonprojects\\pytorch\\env_pytorch\\lib\\site-packages\\torch\\_tensor.py:487\u001b[0m, in \u001b[0;36mTensor.backward\u001b[1;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[0;32m    477\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    478\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[0;32m    479\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[0;32m    480\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    485\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[0;32m    486\u001b[0m     )\n\u001b[1;32m--> 487\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    488\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[0;32m    489\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mm:\\disco m\\python\\pythonprojects\\pytorch\\env_pytorch\\lib\\site-packages\\torch\\autograd\\__init__.py:200\u001b[0m, in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[0;32m    195\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[0;32m    197\u001b[0m \u001b[38;5;66;03m# The reason we repeat same the comment below is that\u001b[39;00m\n\u001b[0;32m    198\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[0;32m    199\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[1;32m--> 200\u001b[0m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[0;32m    201\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    202\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train(model, epochs, dataloader, criterion) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "3753bd5e-b662-4053-8905-3b85f06e4ddf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cut_seq(ids_list: List[str]):\n",
    "    len_token_list = len(ids_list)\n",
    "    if len_token_list > 124:\n",
    "        return ids_list[: 124]\n",
    "    elif len_token_list < 124:\n",
    "        return ids_list + [0] * (124 - len_token_list)\n",
    "    return ids_list\n",
    "    \n",
    "def return_int_vector(text):\n",
    "    tokens = tokenizer.encoder_txt(text)\n",
    "    tokens = cut_seq(tokens)\n",
    "    return torch.tensor(tokens, dtype=torch.int).unsqueeze(0)\n",
    "\n",
    "def sample_next(predictions):\n",
    "    \"\"\"\n",
    "    Greedy sampling.\n",
    "    \"\"\"\n",
    "    # Greedy approach.\n",
    "    probabilities = F.softmax(predictions[:, -1, :], dim=-1).cpu()\n",
    "    next_token = torch.argmax(probabilities)\n",
    "    return int(next_token.cpu())\n",
    "\n",
    "def text_generator(sentence, generate_length):\n",
    "    model.eval()\n",
    "    sample = sentence\n",
    "    for i in range(generate_length):\n",
    "        int_vector = return_int_vector(sample)\n",
    "        if len(int_vector) >= SEQUENCE_LENGTH - 1:\n",
    "            break\n",
    "        input_tensor = int_vector.to(device)\n",
    "        with torch.no_grad():\n",
    "            predictions = model(input_tensor)\n",
    "        next_token = sample_next(predictions)\n",
    "        # sample += ' ' + int_to_word[next_token]  # decode o token\n",
    "        sample += ' ' + tokenizer.decoder_ids([next_token])\n",
    "        print(sample)\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "56900e06-2849-4a8b-bf63-3396ae730c31",
   "metadata": {},
   "outputs": [],
   "source": [
    "int_vector = return_int_vector('Eu gostaria')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "170ecf87-80f9-4b74-b82b-6e6c2db8848b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[34853,   485,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0]], dtype=torch.int32)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "int_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "1d551187-7221-4c1c-9cde-e48bad0d1a92",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nome da GPU: NVIDIA GeForce GTX 1650\n",
      "Memória disponível: 543547392\n"
     ]
    }
   ],
   "source": [
    "# Se disponível, obtenha informações sobre a GPU\n",
    "if torch.cuda.is_available():\n",
    "    print(\"Nome da GPU:\", torch.cuda.get_device_name(0))\n",
    "    print(\"Memória disponível:\", torch.cuda.memory_allocated(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "b2cc38a7-eb6d-441a-9450-846195b1d94b",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_tensor = int_vector.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "aa50293d-8ec4-4bd3-ac49-22c3edd63950",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0.1724, -0.1588, -0.7231,  ..., -0.1175,  0.7343, -0.2147],\n",
       "         [ 0.8182, -0.2380, -0.1657,  ..., -0.5185,  1.4670, -0.4672],\n",
       "         [-0.0557, -0.2524, -0.4005,  ..., -0.6704,  1.3754, -0.1633],\n",
       "         ...,\n",
       "         [-0.0437, -0.1592, -0.2196,  ..., -0.7589,  0.3030, -0.2768],\n",
       "         [-0.0635, -0.1781, -0.1911,  ..., -0.7686,  0.2920, -0.3342],\n",
       "         [-0.0485, -0.2036, -0.1916,  ..., -0.7854,  0.3391, -0.3913]]],\n",
       "       device='cuda:0', grad_fn=<ViewBackward0>)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model(input_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "9503f8f4-981d-4141-86b3-e14b42aafd10",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PROMPT: Eu gostaria\n",
      "['deveras']\n",
      "Eu gostaria deveras\n",
      "['deveras']\n",
      "Eu gostaria deveras deveras\n",
      "['deveras']\n",
      "Eu gostaria deveras deveras deveras\n",
      "['deveras']\n",
      "Eu gostaria deveras deveras deveras deveras\n",
      "['deveras']\n",
      "Eu gostaria deveras deveras deveras deveras deveras\n",
      "['deveras']\n",
      "Eu gostaria deveras deveras deveras deveras deveras deveras\n",
      "['deveras']\n",
      "Eu gostaria deveras deveras deveras deveras deveras deveras deveras\n",
      "['deveras']\n",
      "Eu gostaria deveras deveras deveras deveras deveras deveras deveras deveras\n",
      "['deveras']\n",
      "Eu gostaria deveras deveras deveras deveras deveras deveras deveras deveras deveras\n",
      "['deveras']\n",
      "Eu gostaria deveras deveras deveras deveras deveras deveras deveras deveras deveras deveras\n",
      "['deveras']\n",
      "Eu gostaria deveras deveras deveras deveras deveras deveras deveras deveras deveras deveras deveras\n",
      "['deveras']\n",
      "Eu gostaria deveras deveras deveras deveras deveras deveras deveras deveras deveras deveras deveras deveras\n",
      "['deveras']\n",
      "Eu gostaria deveras deveras deveras deveras deveras deveras deveras deveras deveras deveras deveras deveras deveras\n",
      "['deveras']\n",
      "Eu gostaria deveras deveras deveras deveras deveras deveras deveras deveras deveras deveras deveras deveras deveras deveras\n",
      "['deveras']\n",
      "Eu gostaria deveras deveras deveras deveras deveras deveras deveras deveras deveras deveras deveras deveras deveras deveras deveras\n",
      "['deveras']\n",
      "Eu gostaria deveras deveras deveras deveras deveras deveras deveras deveras deveras deveras deveras deveras deveras deveras deveras deveras\n",
      "['deveras']\n",
      "Eu gostaria deveras deveras deveras deveras deveras deveras deveras deveras deveras deveras deveras deveras deveras deveras deveras deveras deveras\n",
      "['deveras']\n",
      "Eu gostaria deveras deveras deveras deveras deveras deveras deveras deveras deveras deveras deveras deveras deveras deveras deveras deveras deveras deveras\n",
      "['deveras']\n",
      "Eu gostaria deveras deveras deveras deveras deveras deveras deveras deveras deveras deveras deveras deveras deveras deveras deveras deveras deveras deveras deveras\n",
      "['deveras']\n",
      "Eu gostaria deveras deveras deveras deveras deveras deveras deveras deveras deveras deveras deveras deveras deveras deveras deveras deveras deveras deveras deveras deveras\n",
      "['deveras']\n",
      "Eu gostaria deveras deveras deveras deveras deveras deveras deveras deveras deveras deveras deveras deveras deveras deveras deveras deveras deveras deveras deveras deveras deveras\n",
      "['deveras']\n",
      "Eu gostaria deveras deveras deveras deveras deveras deveras deveras deveras deveras deveras deveras deveras deveras deveras deveras deveras deveras deveras deveras deveras deveras deveras\n",
      "['deveras']\n",
      "Eu gostaria deveras deveras deveras deveras deveras deveras deveras deveras deveras deveras deveras deveras deveras deveras deveras deveras deveras deveras deveras deveras deveras deveras deveras\n",
      "['deveras']\n",
      "Eu gostaria deveras deveras deveras deveras deveras deveras deveras deveras deveras deveras deveras deveras deveras deveras deveras deveras deveras deveras deveras deveras deveras deveras deveras deveras\n",
      "['deveras']\n",
      "Eu gostaria deveras deveras deveras deveras deveras deveras deveras deveras deveras deveras deveras deveras deveras deveras deveras deveras deveras deveras deveras deveras deveras deveras deveras deveras deveras\n",
      "['deveras']\n",
      "Eu gostaria deveras deveras deveras deveras deveras deveras deveras deveras deveras deveras deveras deveras deveras deveras deveras deveras deveras deveras deveras deveras deveras deveras deveras deveras deveras deveras\n",
      "['deveras']\n",
      "Eu gostaria deveras deveras deveras deveras deveras deveras deveras deveras deveras deveras deveras deveras deveras deveras deveras deveras deveras deveras deveras deveras deveras deveras deveras deveras deveras deveras deveras\n",
      "['deveras']\n",
      "Eu gostaria deveras deveras deveras deveras deveras deveras deveras deveras deveras deveras deveras deveras deveras deveras deveras deveras deveras deveras deveras deveras deveras deveras deveras deveras deveras deveras deveras deveras\n",
      "['deveras']\n",
      "Eu gostaria deveras deveras deveras deveras deveras deveras deveras deveras deveras deveras deveras deveras deveras deveras deveras deveras deveras deveras deveras deveras deveras deveras deveras deveras deveras deveras deveras deveras deveras\n",
      "['deveras']\n",
      "Eu gostaria deveras deveras deveras deveras deveras deveras deveras deveras deveras deveras deveras deveras deveras deveras deveras deveras deveras deveras deveras deveras deveras deveras deveras deveras deveras deveras deveras deveras deveras deveras\n",
      "['deveras']\n",
      "Eu gostaria deveras deveras deveras deveras deveras deveras deveras deveras deveras deveras deveras deveras deveras deveras deveras deveras deveras deveras deveras deveras deveras deveras deveras deveras deveras deveras deveras deveras deveras deveras deveras\n",
      "['deveras']\n",
      "Eu gostaria deveras deveras deveras deveras deveras deveras deveras deveras deveras deveras deveras deveras deveras deveras deveras deveras deveras deveras deveras deveras deveras deveras deveras deveras deveras deveras deveras deveras deveras deveras deveras deveras\n",
      "['deveras']\n",
      "Eu gostaria deveras deveras deveras deveras deveras deveras deveras deveras deveras deveras deveras deveras deveras deveras deveras deveras deveras deveras deveras deveras deveras deveras deveras deveras deveras deveras deveras deveras deveras deveras deveras deveras deveras\n",
      "['deveras']\n",
      "Eu gostaria deveras deveras deveras deveras deveras deveras deveras deveras deveras deveras deveras deveras deveras deveras deveras deveras deveras deveras deveras deveras deveras deveras deveras deveras deveras deveras deveras deveras deveras deveras deveras deveras deveras deveras\n",
      "['deveras']\n",
      "Eu gostaria deveras deveras deveras deveras deveras deveras deveras deveras deveras deveras deveras deveras deveras deveras deveras deveras deveras deveras deveras deveras deveras deveras deveras deveras deveras deveras deveras deveras deveras deveras deveras deveras deveras deveras deveras\n",
      "['deveras']\n",
      "Eu gostaria deveras deveras deveras deveras deveras deveras deveras deveras deveras deveras deveras deveras deveras deveras deveras deveras deveras deveras deveras deveras deveras deveras deveras deveras deveras deveras deveras deveras deveras deveras deveras deveras deveras deveras deveras deveras\n",
      "['deveras']\n",
      "Eu gostaria deveras deveras deveras deveras deveras deveras deveras deveras deveras deveras deveras deveras deveras deveras deveras deveras deveras deveras deveras deveras deveras deveras deveras deveras deveras deveras deveras deveras deveras deveras deveras deveras deveras deveras deveras deveras deveras\n",
      "['deveras']\n",
      "Eu gostaria deveras deveras deveras deveras deveras deveras deveras deveras deveras deveras deveras deveras deveras deveras deveras deveras deveras deveras deveras deveras deveras deveras deveras deveras deveras deveras deveras deveras deveras deveras deveras deveras deveras deveras deveras deveras deveras deveras\n",
      "['deveras']\n",
      "Eu gostaria deveras deveras deveras deveras deveras deveras deveras deveras deveras deveras deveras deveras deveras deveras deveras deveras deveras deveras deveras deveras deveras deveras deveras deveras deveras deveras deveras deveras deveras deveras deveras deveras deveras deveras deveras deveras deveras deveras deveras\n",
      "['deveras']\n",
      "Eu gostaria deveras deveras deveras deveras deveras deveras deveras deveras deveras deveras deveras deveras deveras deveras deveras deveras deveras deveras deveras deveras deveras deveras deveras deveras deveras deveras deveras deveras deveras deveras deveras deveras deveras deveras deveras deveras deveras deveras deveras deveras\n",
      "['deveras']\n",
      "Eu gostaria deveras deveras deveras deveras deveras deveras deveras deveras deveras deveras deveras deveras deveras deveras deveras deveras deveras deveras deveras deveras deveras deveras deveras deveras deveras deveras deveras deveras deveras deveras deveras deveras deveras deveras deveras deveras deveras deveras deveras deveras deveras\n",
      "['deveras']\n",
      "Eu gostaria deveras deveras deveras deveras deveras deveras deveras deveras deveras deveras deveras deveras deveras deveras deveras deveras deveras deveras deveras deveras deveras deveras deveras deveras deveras deveras deveras deveras deveras deveras deveras deveras deveras deveras deveras deveras deveras deveras deveras deveras deveras deveras\n",
      "['deveras']\n",
      "Eu gostaria deveras deveras deveras deveras deveras deveras deveras deveras deveras deveras deveras deveras deveras deveras deveras deveras deveras deveras deveras deveras deveras deveras deveras deveras deveras deveras deveras deveras deveras deveras deveras deveras deveras deveras deveras deveras deveras deveras deveras deveras deveras deveras deveras\n",
      "['deveras']\n",
      "Eu gostaria deveras deveras deveras deveras deveras deveras deveras deveras deveras deveras deveras deveras deveras deveras deveras deveras deveras deveras deveras deveras deveras deveras deveras deveras deveras deveras deveras deveras deveras deveras deveras deveras deveras deveras deveras deveras deveras deveras deveras deveras deveras deveras deveras deveras\n",
      "['deveras']\n",
      "Eu gostaria deveras deveras deveras deveras deveras deveras deveras deveras deveras deveras deveras deveras deveras deveras deveras deveras deveras deveras deveras deveras deveras deveras deveras deveras deveras deveras deveras deveras deveras deveras deveras deveras deveras deveras deveras deveras deveras deveras deveras deveras deveras deveras deveras deveras deveras\n",
      "['deveras']\n",
      "Eu gostaria deveras deveras deveras deveras deveras deveras deveras deveras deveras deveras deveras deveras deveras deveras deveras deveras deveras deveras deveras deveras deveras deveras deveras deveras deveras deveras deveras deveras deveras deveras deveras deveras deveras deveras deveras deveras deveras deveras deveras deveras deveras deveras deveras deveras deveras deveras\n",
      "['deveras']\n",
      "Eu gostaria deveras deveras deveras deveras deveras deveras deveras deveras deveras deveras deveras deveras deveras deveras deveras deveras deveras deveras deveras deveras deveras deveras deveras deveras deveras deveras deveras deveras deveras deveras deveras deveras deveras deveras deveras deveras deveras deveras deveras deveras deveras deveras deveras deveras deveras deveras deveras\n",
      "['deveras']\n",
      "Eu gostaria deveras deveras deveras deveras deveras deveras deveras deveras deveras deveras deveras deveras deveras deveras deveras deveras deveras deveras deveras deveras deveras deveras deveras deveras deveras deveras deveras deveras deveras deveras deveras deveras deveras deveras deveras deveras deveras deveras deveras deveras deveras deveras deveras deveras deveras deveras deveras deveras\n",
      "['deveras']\n",
      "Eu gostaria deveras deveras deveras deveras deveras deveras deveras deveras deveras deveras deveras deveras deveras deveras deveras deveras deveras deveras deveras deveras deveras deveras deveras deveras deveras deveras deveras deveras deveras deveras deveras deveras deveras deveras deveras deveras deveras deveras deveras deveras deveras deveras deveras deveras deveras deveras deveras deveras deveras\n",
      "['deveras']\n",
      "Eu gostaria deveras deveras deveras deveras deveras deveras deveras deveras deveras deveras deveras deveras deveras deveras deveras deveras deveras deveras deveras deveras deveras deveras deveras deveras deveras deveras deveras deveras deveras deveras deveras deveras deveras deveras deveras deveras deveras deveras deveras deveras deveras deveras deveras deveras deveras deveras deveras deveras deveras deveras\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import torch.nn.functional as F\n",
    "sentences = [\n",
    "    \"Eu gostaria\"\n",
    "]\n",
    "generate_length = 50\n",
    "for sentence in sentences:\n",
    "    print(f\"PROMPT: {sentence}\")\n",
    "    text_generator(sentence, generate_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a00cadc9-87ab-493c-abf0-bebb27c55f15",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c4e89d1-da74-40e4-9f9a-a7464bf6d66f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "fb81b4ea-7700-4259-b75b-6cfd9d078059",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1033,  221]])"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "return_int_vector(\"ola você\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "0a6f7fbf-fecb-4b46-9f48-ee82adeec3c1",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('pos_encoder.pe',\n",
       "              tensor([[[ 0.0000e+00,  1.0000e+00,  0.0000e+00,  ...,  1.0000e+00,\n",
       "                         0.0000e+00,  1.0000e+00],\n",
       "                       [ 8.4147e-01,  5.4030e-01,  8.0196e-01,  ...,  1.0000e+00,\n",
       "                         1.0746e-04,  1.0000e+00],\n",
       "                       [ 9.0930e-01, -4.1615e-01,  9.5814e-01,  ...,  1.0000e+00,\n",
       "                         2.1492e-04,  1.0000e+00],\n",
       "                       ...,\n",
       "                       [ 9.9882e-01, -4.8664e-02, -4.7778e-01,  ...,  9.9990e-01,\n",
       "                         1.3002e-02,  9.9992e-01],\n",
       "                       [ 4.9871e-01, -8.6677e-01,  4.1910e-01,  ...,  9.9990e-01,\n",
       "                         1.3110e-02,  9.9991e-01],\n",
       "                       [-4.5990e-01, -8.8797e-01,  9.7849e-01,  ...,  9.9990e-01,\n",
       "                         1.3217e-02,  9.9991e-01]]], device='cuda:0')),\n",
       "             ('emb.weight',\n",
       "              tensor([[-0.8738, -0.1837,  1.4700,  ...,  0.3221, -0.1774,  0.6775],\n",
       "                      [-0.4894, -1.4769,  0.2193,  ..., -0.0100, -0.2530,  0.2674],\n",
       "                      [-0.3707,  0.5993,  0.9936,  ..., -0.0492,  1.0395, -0.5193],\n",
       "                      ...,\n",
       "                      [ 0.6275,  0.2210, -1.0162,  ..., -1.8979,  0.5656, -0.7528],\n",
       "                      [ 0.4511,  0.7592,  0.2793,  ...,  1.4459,  0.4380, -0.3491],\n",
       "                      [-1.2134,  0.5283, -0.8588,  ...,  0.3037, -0.6471,  1.5076]],\n",
       "                     device='cuda:0')),\n",
       "             ('decoder_layer.self_attn.in_proj_weight',\n",
       "              tensor([[ 0.0681, -0.0463, -0.0426,  ..., -0.0352, -0.0490,  0.0126],\n",
       "                      [ 0.0692,  0.0568,  0.0586,  ...,  0.0570,  0.0054,  0.0760],\n",
       "                      [-0.0529,  0.0010,  0.0112,  ...,  0.0594,  0.0316, -0.0435],\n",
       "                      ...,\n",
       "                      [-0.0078,  0.0676,  0.0410,  ...,  0.0427,  0.0096,  0.0366],\n",
       "                      [-0.0239,  0.0057, -0.0721,  ...,  0.0367, -0.0504, -0.0014],\n",
       "                      [-0.0036,  0.0299, -0.0191,  ...,  0.0677,  0.0608,  0.0567]],\n",
       "                     device='cuda:0')),\n",
       "             ('decoder_layer.self_attn.in_proj_bias',\n",
       "              tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "                     device='cuda:0')),\n",
       "             ('decoder_layer.self_attn.out_proj.weight',\n",
       "              tensor([[ 0.0178,  0.0016, -0.0378,  ...,  0.0038,  0.0254,  0.0610],\n",
       "                      [-0.0419, -0.0127, -0.0241,  ..., -0.0481, -0.0454, -0.0390],\n",
       "                      [ 0.0531, -0.0127, -0.0024,  ...,  0.0037,  0.0442,  0.0301],\n",
       "                      ...,\n",
       "                      [ 0.0367, -0.0607, -0.0170,  ..., -0.0605, -0.0569, -0.0438],\n",
       "                      [ 0.0474,  0.0613,  0.0621,  ...,  0.0609, -0.0356,  0.0227],\n",
       "                      [ 0.0106, -0.0107,  0.0610,  ...,  0.0254, -0.0011, -0.0045]],\n",
       "                     device='cuda:0')),\n",
       "             ('decoder_layer.self_attn.out_proj.bias',\n",
       "              tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "                     device='cuda:0')),\n",
       "             ('decoder_layer.multihead_attn.in_proj_weight',\n",
       "              tensor([[-0.0026, -0.0402, -0.0130,  ...,  0.0483, -0.0268, -0.0321],\n",
       "                      [-0.0408,  0.0123, -0.0457,  ...,  0.0763, -0.0595, -0.0681],\n",
       "                      [-0.0150,  0.0005,  0.0473,  ...,  0.0284,  0.0183, -0.0391],\n",
       "                      ...,\n",
       "                      [-0.0631,  0.0176, -0.0757,  ...,  0.0672, -0.0586, -0.0157],\n",
       "                      [-0.0628,  0.0537,  0.0644,  ..., -0.0423, -0.0435, -0.0023],\n",
       "                      [-0.0113,  0.0412, -0.0731,  ..., -0.0164, -0.0487, -0.0510]],\n",
       "                     device='cuda:0')),\n",
       "             ('decoder_layer.multihead_attn.in_proj_bias',\n",
       "              tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "                     device='cuda:0')),\n",
       "             ('decoder_layer.multihead_attn.out_proj.weight',\n",
       "              tensor([[ 0.0278, -0.0034, -0.0088,  ..., -0.0413, -0.0483, -0.0185],\n",
       "                      [-0.0235, -0.0146, -0.0088,  ..., -0.0216,  0.0153, -0.0168],\n",
       "                      [-0.0024, -0.0367,  0.0495,  ...,  0.0277, -0.0460,  0.0216],\n",
       "                      ...,\n",
       "                      [ 0.0266, -0.0269, -0.0129,  ..., -0.0229,  0.0364, -0.0197],\n",
       "                      [ 0.0213, -0.0044, -0.0148,  ..., -0.0576,  0.0598,  0.0167],\n",
       "                      [-0.0261,  0.0561,  0.0021,  ...,  0.0140, -0.0075, -0.0543]],\n",
       "                     device='cuda:0')),\n",
       "             ('decoder_layer.multihead_attn.out_proj.bias',\n",
       "              tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "                     device='cuda:0')),\n",
       "             ('decoder_layer.linear1.weight',\n",
       "              tensor([[-0.0347,  0.0422,  0.0345,  ...,  0.0297,  0.0113, -0.0014],\n",
       "                      [-0.0115,  0.0109, -0.0505,  ...,  0.0363, -0.0032,  0.0617],\n",
       "                      [-0.0235,  0.0191,  0.0060,  ..., -0.0284, -0.0175,  0.0130],\n",
       "                      ...,\n",
       "                      [-0.0238, -0.0114, -0.0332,  ..., -0.0019, -0.0393, -0.0158],\n",
       "                      [-0.0182, -0.0131,  0.0499,  ..., -0.0265,  0.0025,  0.0180],\n",
       "                      [ 0.0299, -0.0465,  0.0375,  ...,  0.0583, -0.0347,  0.0332]],\n",
       "                     device='cuda:0')),\n",
       "             ('decoder_layer.linear1.bias',\n",
       "              tensor([ 0.0577, -0.0084, -0.0045,  ...,  0.0177,  0.0217, -0.0484],\n",
       "                     device='cuda:0')),\n",
       "             ('decoder_layer.linear2.weight',\n",
       "              tensor([[ 0.0185, -0.0014, -0.0063,  ..., -0.0055,  0.0208, -0.0081],\n",
       "                      [ 0.0064,  0.0042, -0.0025,  ..., -0.0045, -0.0220, -0.0122],\n",
       "                      [-0.0091, -0.0215, -0.0090,  ..., -0.0175,  0.0112,  0.0001],\n",
       "                      ...,\n",
       "                      [ 0.0112,  0.0129, -0.0100,  ..., -0.0011,  0.0149, -0.0199],\n",
       "                      [ 0.0206, -0.0189, -0.0039,  ...,  0.0212, -0.0190,  0.0110],\n",
       "                      [-0.0071, -0.0163,  0.0135,  ..., -0.0050, -0.0041, -0.0117]],\n",
       "                     device='cuda:0')),\n",
       "             ('decoder_layer.linear2.bias',\n",
       "              tensor([ 2.0941e-02, -1.2544e-02,  1.0344e-03,  9.9753e-03,  1.7969e-02,\n",
       "                      -8.9357e-03,  2.0093e-02,  1.1945e-02,  1.5049e-02, -1.9665e-02,\n",
       "                      -2.1905e-02, -1.5084e-02, -1.6198e-02, -8.6594e-03, -1.8053e-02,\n",
       "                       1.5810e-02,  1.9384e-02,  8.2996e-04, -1.0800e-02, -1.0990e-02,\n",
       "                      -1.0086e-02,  2.0974e-02, -8.3326e-03,  2.0937e-02,  1.3889e-02,\n",
       "                      -1.8032e-02,  9.5985e-03,  9.4012e-03, -1.5580e-02,  3.1624e-03,\n",
       "                       1.9067e-02, -7.6743e-03,  1.7691e-02,  2.0326e-02, -4.5621e-03,\n",
       "                      -1.3120e-02, -8.7387e-03,  5.9338e-03, -1.5653e-02, -6.8905e-04,\n",
       "                       7.4852e-03, -3.0297e-03, -8.9748e-03, -1.1881e-02, -1.5214e-02,\n",
       "                       9.4754e-03, -3.3241e-03, -8.7060e-03,  7.2812e-03, -1.0239e-02,\n",
       "                      -2.0528e-02,  8.8840e-03,  2.9305e-03,  1.7500e-02, -1.6153e-02,\n",
       "                       3.9123e-03,  1.2439e-02,  5.7307e-03,  3.9972e-03, -1.5525e-02,\n",
       "                      -1.5371e-02, -2.1167e-02, -2.1546e-03,  2.1394e-03,  3.0001e-04,\n",
       "                       1.1585e-02, -7.4578e-03,  6.2895e-03, -2.0204e-02,  8.6519e-03,\n",
       "                      -7.5209e-03, -1.8687e-02, -1.1861e-03,  1.3334e-02, -1.6569e-02,\n",
       "                       1.5866e-02,  1.6242e-02,  2.0959e-02, -7.8961e-03,  1.6445e-02,\n",
       "                      -5.6939e-03, -1.9597e-03,  5.7712e-03,  1.8465e-02, -1.9298e-02,\n",
       "                       3.0342e-03,  1.2542e-02, -4.4025e-03,  5.4186e-03, -1.9520e-02,\n",
       "                       1.2409e-02,  5.1531e-03,  1.3864e-02,  6.1036e-03,  5.5735e-03,\n",
       "                       1.9779e-02, -3.0875e-05,  9.9931e-03, -4.2170e-03,  1.8412e-02,\n",
       "                      -7.2241e-03, -1.6444e-02, -1.5888e-02, -1.2797e-02, -3.0125e-03,\n",
       "                      -1.5207e-02,  2.1138e-02,  5.0365e-03, -1.0787e-02,  1.6059e-02,\n",
       "                       1.8361e-02,  2.2421e-03, -1.9186e-02, -3.2517e-03, -1.5297e-02,\n",
       "                       4.0823e-03,  2.5412e-03, -4.2799e-03, -2.3557e-03, -2.4636e-04,\n",
       "                       8.1896e-03,  1.6070e-02, -1.6307e-03,  1.8978e-02,  1.6756e-02,\n",
       "                       8.8979e-03, -4.2292e-03, -1.6529e-02,  5.9321e-03,  1.3553e-02,\n",
       "                      -1.5568e-02, -1.3896e-02, -8.2164e-03, -5.5449e-05,  2.5505e-03,\n",
       "                      -2.1193e-02, -2.0310e-02,  1.7037e-02,  2.3080e-04,  7.1940e-03,\n",
       "                      -1.3299e-02, -9.1715e-03, -1.3947e-02,  9.2039e-03, -9.5270e-03,\n",
       "                      -1.1739e-02, -2.2324e-03,  1.0976e-02,  2.1501e-02,  5.8186e-03,\n",
       "                      -1.2604e-02, -3.0685e-03, -8.8731e-03,  1.5897e-02,  1.4056e-04,\n",
       "                      -1.1517e-02,  1.8558e-02,  1.0068e-02,  1.5691e-02, -1.6124e-02,\n",
       "                       7.0191e-03, -4.1855e-04, -1.8108e-02, -2.1649e-02,  3.9535e-03,\n",
       "                      -1.0672e-02,  1.2272e-02, -8.9161e-04,  1.6473e-02,  1.4814e-02,\n",
       "                       1.8341e-02,  4.2566e-04, -1.5108e-03, -8.0519e-03, -2.4162e-03,\n",
       "                       5.6430e-03,  1.7772e-02, -2.0670e-02, -9.9315e-03, -1.3351e-02,\n",
       "                      -3.9172e-03,  1.7271e-02, -4.5635e-03, -2.4967e-04,  5.1431e-03,\n",
       "                      -3.9838e-03,  1.3950e-02,  1.1268e-03, -9.8578e-03, -1.5583e-04,\n",
       "                       2.0241e-02,  9.1944e-04,  1.1934e-02, -5.0170e-03,  2.1556e-03,\n",
       "                      -1.8665e-02,  1.2373e-02,  1.7122e-02, -1.7008e-02,  2.6511e-03,\n",
       "                       1.3335e-02, -1.7295e-02, -1.5259e-02,  1.3960e-02, -8.1729e-03,\n",
       "                      -1.2206e-02, -2.1544e-02, -1.1958e-02, -1.7808e-02,  1.9260e-02,\n",
       "                      -1.4320e-02,  1.1200e-02, -1.7524e-02,  1.8162e-02, -1.9311e-02,\n",
       "                       3.2253e-03,  2.0426e-02,  1.2767e-02,  2.1814e-02,  1.9512e-02,\n",
       "                      -2.0028e-03, -5.0423e-03,  1.6991e-02, -1.6937e-02,  1.5041e-02,\n",
       "                       1.0146e-02,  2.0532e-02,  1.9836e-02,  2.7877e-03,  5.8472e-03,\n",
       "                       2.0351e-02, -8.0519e-04,  1.6396e-02,  1.2749e-02, -9.0732e-03,\n",
       "                       1.8731e-02, -1.5668e-02,  1.5906e-03, -8.2568e-03, -1.5995e-02,\n",
       "                       1.0317e-02, -1.7104e-02, -3.1263e-03,  5.8583e-03,  1.3792e-02,\n",
       "                      -1.3040e-02,  1.3207e-02, -2.8857e-03,  1.8470e-02,  1.0538e-03,\n",
       "                      -2.0619e-02,  6.7806e-03,  1.4255e-03,  1.0974e-02,  4.9456e-03,\n",
       "                       2.1350e-02], device='cuda:0')),\n",
       "             ('decoder_layer.norm1.weight',\n",
       "              tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1.], device='cuda:0')),\n",
       "             ('decoder_layer.norm1.bias',\n",
       "              tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "                     device='cuda:0')),\n",
       "             ('decoder_layer.norm2.weight',\n",
       "              tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1.], device='cuda:0')),\n",
       "             ('decoder_layer.norm2.bias',\n",
       "              tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "                     device='cuda:0')),\n",
       "             ('decoder_layer.norm3.weight',\n",
       "              tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1.], device='cuda:0')),\n",
       "             ('decoder_layer.norm3.bias',\n",
       "              tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "                     device='cuda:0')),\n",
       "             ('decoder.layers.0.self_attn.in_proj_weight',\n",
       "              tensor([[ 0.0762, -0.0461, -0.0462,  ..., -0.0308, -0.0564,  0.0164],\n",
       "                      [ 0.0794,  0.0577,  0.0633,  ...,  0.0582,  0.0050,  0.0679],\n",
       "                      [-0.0602, -0.0069,  0.0081,  ...,  0.0539,  0.0329, -0.0502],\n",
       "                      ...,\n",
       "                      [-0.0118,  0.0750,  0.0429,  ...,  0.0420,  0.0127,  0.0370],\n",
       "                      [-0.0324,  0.0055, -0.0739,  ...,  0.0357, -0.0550,  0.0003],\n",
       "                      [-0.0028,  0.0309, -0.0171,  ...,  0.0652,  0.0674,  0.0546]],\n",
       "                     device='cuda:0')),\n",
       "             ('decoder.layers.0.self_attn.in_proj_bias',\n",
       "              tensor([-7.9653e-04, -2.9777e-03, -7.6870e-03,  3.2814e-03, -2.7279e-03,\n",
       "                      -6.2494e-03, -3.3247e-04, -2.5208e-03,  1.4225e-03,  1.9634e-03,\n",
       "                       3.2429e-03,  1.1296e-02, -4.1100e-03,  2.5984e-03, -8.8601e-04,\n",
       "                      -5.8833e-03, -1.4282e-02,  9.6866e-03,  7.2437e-03,  3.6748e-03,\n",
       "                      -8.8170e-03,  1.9581e-03,  9.1463e-03, -1.8764e-03, -9.4731e-03,\n",
       "                      -2.9212e-03, -8.6640e-03,  4.3283e-03, -1.7874e-03,  8.2429e-03,\n",
       "                       7.9336e-03, -7.3887e-03,  1.2396e-02,  3.2770e-03,  1.0132e-03,\n",
       "                       2.1877e-03, -8.5635e-03, -6.7604e-03,  5.6904e-03,  3.5211e-03,\n",
       "                      -4.9739e-04,  8.2945e-03, -9.2264e-03,  5.0690e-03,  9.9381e-03,\n",
       "                       1.1414e-03,  2.5587e-03,  8.2211e-03,  6.4973e-04,  8.0598e-03,\n",
       "                       8.5460e-03, -1.9073e-03, -3.2172e-03,  6.3892e-03, -1.1019e-03,\n",
       "                      -2.2050e-04,  3.3306e-04, -1.4123e-04,  7.9567e-03, -1.0048e-02,\n",
       "                      -4.4857e-03, -6.2850e-03, -1.6630e-03, -2.0500e-03, -4.7257e-04,\n",
       "                       5.6531e-03, -1.8468e-03, -2.3440e-03, -4.7318e-03, -9.2847e-03,\n",
       "                      -2.7582e-04, -2.3636e-03, -2.0290e-03,  1.0809e-04,  1.6599e-03,\n",
       "                      -1.7643e-03, -1.0710e-03,  2.8516e-03,  5.1012e-04,  7.3048e-03,\n",
       "                      -2.9978e-03, -9.2651e-04, -2.9591e-04,  8.1973e-04, -2.8564e-03,\n",
       "                      -1.8330e-03, -4.6723e-03, -6.1073e-03,  4.9746e-03, -4.2348e-03,\n",
       "                      -1.3571e-03, -1.0571e-03, -8.2193e-03, -2.1110e-03, -3.0129e-03,\n",
       "                      -3.0055e-03, -4.8971e-03, -8.5359e-03,  1.5841e-04, -4.4798e-04,\n",
       "                      -2.9226e-03,  3.1023e-03, -2.6567e-03, -7.3809e-03,  5.6726e-03,\n",
       "                       6.0225e-04, -2.3694e-03,  3.7179e-03,  3.4996e-03,  2.1427e-03,\n",
       "                      -4.8644e-03,  6.4332e-03,  4.7018e-04, -2.8479e-03,  3.6637e-03,\n",
       "                       5.8833e-04,  1.1606e-03, -5.9142e-03, -3.2647e-03, -3.9592e-03,\n",
       "                      -3.6468e-03,  1.0718e-03,  3.5189e-04, -3.6712e-03,  3.2066e-03,\n",
       "                       1.3105e-03,  8.1690e-03,  2.2554e-03, -1.8099e-03, -6.4109e-04,\n",
       "                      -3.1764e-03,  6.5887e-03, -1.2961e-03,  6.4732e-04,  4.8371e-03,\n",
       "                       1.7742e-03,  7.0649e-03,  1.7476e-03,  2.1069e-03,  4.6715e-06,\n",
       "                      -4.3192e-04, -4.2261e-03, -1.3136e-04,  7.7485e-03,  3.1617e-03,\n",
       "                      -3.3201e-03, -1.7403e-03,  1.7909e-03, -1.2696e-03,  2.2258e-03,\n",
       "                       2.2785e-03,  4.6871e-03, -5.1756e-03, -7.5684e-04,  1.7236e-03,\n",
       "                      -1.5288e-03,  3.9076e-03,  7.3136e-04, -2.2791e-03, -4.9071e-04,\n",
       "                       4.3924e-03,  1.2055e-04, -4.1739e-04,  3.4271e-03, -1.7031e-03,\n",
       "                      -2.0852e-03,  2.4136e-03,  1.4248e-03, -4.2320e-03, -3.0494e-03,\n",
       "                       2.0602e-03,  1.4858e-05, -3.2058e-03,  6.1569e-03,  1.4432e-03,\n",
       "                      -2.3344e-03,  4.0830e-03,  2.9903e-03, -7.3068e-04,  5.9147e-03,\n",
       "                      -2.3772e-03, -3.6511e-04, -3.9438e-03, -3.4539e-04,  6.6811e-03,\n",
       "                      -3.2180e-03, -1.0619e-03, -4.7172e-03, -7.6537e-05, -1.5899e-03,\n",
       "                       1.4212e-03, -6.0840e-03,  2.0721e-03,  3.5281e-03,  2.2852e-04,\n",
       "                       4.7876e-03, -2.1264e-03,  1.3654e-03, -6.8853e-03, -4.6768e-03,\n",
       "                      -2.8600e-03, -1.0758e-03, -8.4858e-04,  2.9862e-04,  1.0410e-03,\n",
       "                       1.1201e-04, -2.4411e-03,  5.2031e-04,  2.6848e-03, -5.8141e-03,\n",
       "                      -4.4694e-03,  2.3596e-03, -4.9084e-03,  6.9063e-03, -2.1589e-03,\n",
       "                       4.0431e-03, -2.6838e-03,  4.4851e-03,  5.7206e-04, -3.2455e-03,\n",
       "                       9.8538e-03, -1.2485e-03, -6.6548e-03, -2.7241e-03, -1.0003e-02,\n",
       "                      -3.8884e-03,  3.9083e-03,  5.0154e-04,  3.6188e-03, -1.1004e-04,\n",
       "                      -1.2294e-03, -2.5203e-03,  2.9760e-03, -1.6440e-03,  8.6516e-04,\n",
       "                      -8.8027e-03, -2.2254e-03,  9.0566e-03,  4.9734e-03, -1.7040e-02,\n",
       "                      -2.6770e-03, -1.7105e-04,  2.6558e-03, -3.7637e-03,  8.2043e-03,\n",
       "                      -8.4573e-04,  4.2210e-03, -3.5608e-03, -9.1466e-04, -6.1078e-03,\n",
       "                       1.0959e-04, -1.5422e-03,  1.7912e-03, -6.0821e-03, -3.3780e-04,\n",
       "                      -2.5376e-03,  5.7534e-04,  3.2286e-04,  2.0197e-04,  9.5202e-04,\n",
       "                       3.2563e-04, -2.6221e-04, -4.3755e-04, -4.8480e-04, -4.4353e-04,\n",
       "                      -3.8428e-04, -5.2914e-04,  4.5150e-04, -1.6544e-04,  2.8961e-04,\n",
       "                      -3.8785e-04, -3.2083e-04, -3.4577e-04, -5.5848e-04,  4.0506e-04,\n",
       "                      -4.5405e-04, -5.3812e-04,  6.8891e-04,  5.2682e-04,  4.3208e-04,\n",
       "                      -4.6444e-04, -5.0908e-04, -2.0606e-05, -4.0317e-04, -4.8024e-04,\n",
       "                       4.7642e-04,  4.3132e-04, -6.3188e-04,  6.0407e-04,  5.9972e-04,\n",
       "                      -4.8456e-04,  4.5467e-04, -3.1281e-04, -5.5929e-04, -4.5574e-04,\n",
       "                       4.4906e-04, -3.3873e-04, -4.3948e-04, -4.7998e-04,  5.8945e-04,\n",
       "                       6.5603e-04,  4.8715e-04, -5.1122e-04,  4.7060e-04, -5.5834e-04,\n",
       "                       4.0615e-04, -4.3639e-04,  1.6778e-04, -4.9007e-04,  3.7680e-04,\n",
       "                      -6.4714e-04, -3.2683e-04,  3.4004e-04, -7.1075e-04,  3.3520e-04,\n",
       "                      -5.6476e-05, -3.3817e-04, -3.1064e-04,  4.6347e-04,  3.1487e-04,\n",
       "                       4.6601e-04,  3.3409e-04, -4.4549e-04,  3.3291e-05, -4.9838e-04,\n",
       "                      -7.1111e-04,  3.7841e-04,  1.2592e-04, -4.5055e-04,  1.6707e-04,\n",
       "                      -3.3734e-04, -3.5071e-04,  3.4852e-04,  3.2585e-04,  3.4616e-04,\n",
       "                       2.9067e-04, -2.4318e-04,  1.9506e-05,  2.8638e-04,  3.7278e-04,\n",
       "                       3.2531e-04, -3.2724e-04, -3.4613e-04, -2.8769e-04, -4.8765e-04,\n",
       "                      -4.4994e-04,  3.1255e-04, -3.9160e-04, -5.6372e-04,  2.5020e-04,\n",
       "                      -2.7546e-04,  4.4281e-04, -2.6064e-04, -3.1591e-04,  3.1514e-04,\n",
       "                      -5.2204e-04, -5.2341e-04,  3.3162e-04, -5.2893e-04,  6.5202e-04,\n",
       "                       4.9153e-04,  3.3894e-04, -2.2021e-04,  3.5886e-04,  8.4266e-05,\n",
       "                      -5.1149e-04,  1.2678e-04, -3.6388e-04,  5.7883e-05, -3.5030e-04,\n",
       "                       2.8559e-04, -3.5930e-04,  4.5096e-04,  4.5565e-04, -3.9134e-04,\n",
       "                      -3.4645e-04, -3.4482e-04,  3.8777e-04,  2.7370e-04, -2.4352e-04,\n",
       "                      -3.2284e-04,  3.2697e-04, -3.2679e-04, -3.7632e-04,  1.4941e-04,\n",
       "                      -9.0529e-05, -2.8893e-04, -9.7820e-05, -2.3651e-04,  1.3325e-04,\n",
       "                       1.9464e-04, -1.7601e-04,  1.6320e-04, -2.2076e-04,  2.6599e-04,\n",
       "                       2.6385e-04,  1.7725e-04,  2.5117e-04,  1.8148e-04,  3.2033e-04,\n",
       "                      -7.1928e-05, -2.2668e-04, -5.1916e-05,  1.8946e-04, -1.3162e-04,\n",
       "                       1.1022e-04,  2.1487e-04,  9.7660e-05, -2.9156e-04, -2.6269e-04,\n",
       "                      -1.0950e-04, -2.0126e-04,  2.6139e-04, -2.0116e-04, -1.5895e-04,\n",
       "                      -8.2280e-06,  2.0599e-04, -1.8710e-05,  1.7494e-04,  1.1951e-04,\n",
       "                       5.8121e-05, -1.6789e-04,  2.4461e-04, -1.7666e-04,  1.1721e-04,\n",
       "                      -2.0653e-04,  2.2760e-04,  1.3465e-04,  2.5968e-04,  1.8234e-04,\n",
       "                      -1.9303e-04, -1.2079e-04,  6.3078e-05, -4.7578e-05, -3.3485e-04,\n",
       "                       1.6546e-04, -1.8775e-04, -1.9648e-04,  3.5339e-04, -2.1489e-04,\n",
       "                       1.7351e-04, -1.0734e-04, -4.1951e-05, -2.4483e-04, -9.7374e-06,\n",
       "                      -1.1548e-04,  2.8775e-04,  1.9503e-04,  5.2730e-05,  2.0946e-04,\n",
       "                       1.4317e-04,  1.7333e-04, -2.2746e-04,  2.6157e-04, -3.2646e-04,\n",
       "                      -3.4474e-04,  2.3808e-04, -2.2811e-04, -7.7758e-05, -5.8739e-05,\n",
       "                      -1.8547e-04,  1.7453e-04, -2.7564e-04, -1.9313e-04, -2.2725e-04,\n",
       "                      -2.2255e-04, -1.5286e-04, -3.1651e-04,  2.7162e-04,  3.2693e-04,\n",
       "                      -2.2063e-04,  2.0434e-04,  2.3602e-04, -2.4021e-05,  1.9217e-04,\n",
       "                       7.9429e-05,  2.1653e-04,  1.9979e-04, -2.6115e-04, -2.3637e-04,\n",
       "                      -1.7128e-04, -1.7635e-04, -1.8961e-04,  2.2986e-04,  2.1845e-04,\n",
       "                      -1.6787e-04, -2.0988e-04, -2.2612e-04,  2.2044e-04, -2.6800e-04,\n",
       "                      -9.4605e-05, -1.9384e-04, -2.1723e-04, -2.5260e-04, -2.6927e-04,\n",
       "                      -4.7885e-05,  2.1815e-04,  2.0608e-04,  2.0742e-04,  1.8186e-04,\n",
       "                       2.7729e-04, -2.2036e-04, -2.3328e-04, -9.7774e-06, -2.2362e-04,\n",
       "                      -1.7606e-04,  2.0187e-04, -2.0046e-04, -1.2821e-04, -2.0519e-04,\n",
       "                       2.3480e-04, -1.9862e-04, -3.2176e-04, -1.9873e-03, -7.2485e-04,\n",
       "                       2.7786e-03, -8.7860e-04, -1.9982e-03, -7.6578e-04,  5.3499e-04,\n",
       "                       2.1419e-03,  1.0926e-03,  6.1892e-04,  1.1589e-03,  7.7997e-04,\n",
       "                      -8.6963e-04, -2.4231e-03, -1.3778e-03, -2.1812e-03,  3.7092e-03,\n",
       "                      -1.5379e-03, -2.1386e-03, -2.8191e-03,  1.5368e-03, -1.9635e-03,\n",
       "                       2.2492e-03, -1.4654e-04,  2.6893e-03, -8.7936e-04,  1.2294e-03,\n",
       "                      -2.8279e-03,  8.1687e-04,  6.6359e-04, -1.3449e-03, -1.4124e-03,\n",
       "                       2.3224e-04, -7.8085e-04,  9.7052e-05,  6.4210e-04, -2.5026e-03,\n",
       "                      -1.0217e-04,  9.9311e-04,  4.4849e-04, -4.5756e-04, -1.1067e-03,\n",
       "                       1.1891e-03,  1.3949e-03, -6.5191e-04, -4.2500e-03,  3.9984e-03,\n",
       "                       6.3836e-04,  1.2628e-03, -2.7076e-03,  9.6188e-04, -1.7600e-03,\n",
       "                       4.6412e-04, -1.0400e-03, -1.2973e-03,  2.6590e-03,  1.8573e-03,\n",
       "                       2.0951e-03,  1.4639e-03,  2.0185e-04,  2.2188e-03, -4.8153e-04,\n",
       "                      -1.5704e-04,  3.1894e-03, -8.1496e-04,  9.8084e-04,  1.6591e-03,\n",
       "                       1.8875e-03, -2.3979e-04, -5.1527e-03,  1.7658e-03, -7.4259e-05,\n",
       "                       2.4204e-03,  2.0443e-03, -2.7879e-03,  1.8248e-03,  3.9985e-03,\n",
       "                      -3.3943e-04,  1.6649e-03, -1.6594e-04,  2.3369e-03,  2.4625e-03,\n",
       "                      -1.0390e-03, -1.6769e-03, -1.0758e-03, -5.6790e-04, -1.6491e-03,\n",
       "                      -2.0464e-03, -1.2535e-03, -1.6091e-03, -1.6253e-03, -8.6510e-04,\n",
       "                       1.4642e-03,  1.4168e-03, -2.0091e-03,  3.4634e-04, -1.5091e-03,\n",
       "                       3.3973e-04,  1.0238e-03, -9.4573e-04, -1.0709e-03, -2.1163e-03,\n",
       "                       2.2447e-03,  1.6946e-04,  1.2379e-03,  5.7993e-04,  1.6542e-04,\n",
       "                      -7.4752e-04, -1.7476e-03, -3.1356e-03,  2.0542e-03, -8.7382e-04,\n",
       "                      -4.2603e-03,  2.2911e-03,  1.7790e-03, -1.6629e-03, -3.2431e-03,\n",
       "                       1.7960e-03,  3.0434e-03,  8.3475e-04, -1.4316e-03,  2.3107e-03,\n",
       "                      -2.2884e-03,  2.1465e-03,  2.6664e-03,  3.4323e-03, -7.5847e-04,\n",
       "                       2.5583e-03,  1.5556e-03,  1.1213e-03, -6.5651e-04,  2.7309e-04,\n",
       "                       3.3566e-04, -2.1626e-05,  2.0112e-03,  2.3110e-03,  3.9042e-03,\n",
       "                      -2.2869e-03, -3.3517e-03, -2.5319e-03,  2.2599e-04, -1.2749e-03,\n",
       "                      -3.3921e-03, -8.9471e-04,  2.3843e-03, -5.3710e-04, -2.9563e-03,\n",
       "                       1.8377e-03,  5.9428e-04, -5.4416e-04, -9.3552e-04, -2.5393e-04,\n",
       "                      -3.0510e-03, -1.5706e-03,  8.1608e-05, -8.0651e-04,  1.1588e-03,\n",
       "                       2.2490e-03, -2.5602e-03,  7.1557e-04,  2.0686e-04, -1.3769e-03,\n",
       "                       3.9268e-03,  5.4945e-04, -3.3831e-03,  4.9991e-04, -2.4357e-04,\n",
       "                       2.2505e-03, -3.4344e-04,  1.3841e-03, -1.4356e-03,  1.9845e-03,\n",
       "                      -1.0486e-03, -2.7889e-03,  9.1332e-04,  9.1723e-04,  1.2476e-03,\n",
       "                      -2.5754e-04,  1.1894e-03,  2.0392e-03,  2.8620e-03, -1.6320e-03,\n",
       "                      -2.4359e-03,  3.2563e-04,  1.2412e-03, -3.0449e-03, -7.0253e-05,\n",
       "                       2.9002e-03,  1.4470e-03,  6.0920e-04,  4.0709e-04, -7.1472e-04,\n",
       "                       1.2106e-03,  1.6938e-03,  3.3165e-03,  3.2144e-03, -3.2466e-03,\n",
       "                      -2.7413e-03,  1.2048e-04, -2.8466e-03, -8.9163e-04, -1.3058e-03,\n",
       "                       2.4201e-03, -1.3207e-03,  1.5327e-03,  1.1767e-03, -1.4485e-03,\n",
       "                      -8.8482e-04, -2.5928e-03, -1.8662e-03, -3.2500e-03,  1.1747e-03,\n",
       "                      -2.7313e-03, -2.6191e-03,  1.1064e-04,  9.0555e-04, -3.1835e-03,\n",
       "                       4.3827e-03,  2.0708e-03, -1.3679e-03, -3.4938e-04, -1.9056e-03,\n",
       "                       1.8381e-03, -9.5876e-04, -3.6873e-03, -9.2817e-04,  3.0870e-03,\n",
       "                      -2.8279e-03, -1.0478e-03,  9.4719e-04, -1.4136e-04,  1.4410e-03,\n",
       "                       1.7226e-03,  3.3660e-03, -2.0384e-03, -1.3067e-03,  2.0609e-03,\n",
       "                      -1.1750e-03, -2.0138e-03,  5.4624e-03, -8.7758e-04,  2.0777e-03,\n",
       "                      -8.6850e-05, -1.1002e-03, -2.8342e-03, -2.5244e-04, -9.7124e-04,\n",
       "                      -3.4271e-04,  1.2077e-03,  2.6651e-03,  2.5385e-03,  3.4484e-03,\n",
       "                      -1.6260e-03,  1.6510e-03, -1.9364e-04], device='cuda:0')),\n",
       "             ('decoder.layers.0.self_attn.out_proj.weight',\n",
       "              tensor([[ 1.9499e-02, -9.5900e-04, -3.9178e-02,  ...,  4.5738e-03,\n",
       "                        2.8622e-02,  5.7922e-02],\n",
       "                      [-4.4211e-02, -2.4076e-03, -2.6390e-02,  ..., -4.8832e-02,\n",
       "                       -4.1841e-02, -4.4535e-02],\n",
       "                      [ 4.7374e-02, -1.4975e-02, -1.0133e-02,  ...,  8.7812e-03,\n",
       "                        3.0057e-02,  3.1899e-02],\n",
       "                      ...,\n",
       "                      [ 3.2520e-02, -6.1405e-02, -1.1343e-02,  ..., -5.8835e-02,\n",
       "                       -5.2783e-02, -4.1332e-02],\n",
       "                      [ 4.0353e-02,  6.1379e-02,  6.0621e-02,  ...,  5.8422e-02,\n",
       "                       -2.1005e-02,  2.2097e-02],\n",
       "                      [ 1.6756e-02, -1.2811e-02,  5.9477e-02,  ...,  1.9850e-02,\n",
       "                       -4.4328e-05, -1.0048e-02]], device='cuda:0')),\n",
       "             ('decoder.layers.0.self_attn.out_proj.bias',\n",
       "              tensor([ 2.1019e-03, -6.8651e-04,  5.7555e-03,  1.6196e-03, -1.0233e-03,\n",
       "                      -2.4368e-04, -2.0950e-03,  3.5660e-03,  6.2655e-03,  2.1971e-03,\n",
       "                      -1.3174e-03,  1.3027e-03,  9.6369e-04, -8.4869e-05,  2.9354e-03,\n",
       "                      -1.6086e-05, -2.7691e-03, -6.1954e-04,  2.8449e-05,  1.4849e-03,\n",
       "                       1.4326e-03,  7.8108e-04,  1.0038e-03,  2.6725e-03,  1.6964e-03,\n",
       "                      -2.7049e-03,  2.3963e-03, -9.2497e-04, -6.6294e-04,  3.7199e-03,\n",
       "                       3.2608e-05, -1.9174e-03,  2.7138e-03,  5.5744e-04,  8.7720e-04,\n",
       "                      -2.8996e-03,  1.4633e-03,  3.1587e-03, -4.8989e-04, -3.5193e-03,\n",
       "                      -3.0656e-03,  2.7879e-03, -7.1397e-04,  1.9584e-03,  1.0028e-03,\n",
       "                       1.4967e-03,  5.0439e-03,  5.7489e-04,  1.2740e-03,  5.0682e-03,\n",
       "                       1.6148e-03, -2.7298e-03,  9.9134e-04,  1.2146e-03,  1.5222e-03,\n",
       "                       1.8436e-03, -1.2482e-03, -3.4102e-03,  2.4090e-04, -3.3654e-05,\n",
       "                       1.5489e-03,  2.8561e-03,  2.4176e-04, -3.8999e-03,  1.4076e-03,\n",
       "                       3.6650e-04, -1.7150e-03, -2.4703e-03,  1.4794e-03, -1.2262e-03,\n",
       "                       1.2441e-04,  4.4999e-03, -1.0295e-04, -2.3401e-03,  1.4809e-04,\n",
       "                      -4.1507e-04, -1.4762e-03,  7.7354e-04,  3.1415e-03,  2.5424e-03,\n",
       "                       9.1796e-04, -1.2314e-04, -1.6250e-03,  1.3234e-03, -7.1783e-03,\n",
       "                       2.4576e-03, -3.3472e-03,  1.7093e-03, -5.6845e-04,  1.5927e-03,\n",
       "                      -3.5429e-03,  2.6169e-03, -5.6595e-03,  1.6874e-03, -3.8953e-03,\n",
       "                      -8.2346e-04, -1.3188e-03,  4.0159e-03,  3.1012e-05,  3.8734e-03,\n",
       "                       3.1983e-03, -7.3406e-04,  2.2487e-03, -3.9208e-04, -2.9521e-03,\n",
       "                      -2.0464e-04,  1.0371e-03, -2.4222e-03, -1.1467e-04, -2.2772e-04,\n",
       "                       8.2331e-04, -3.7498e-03,  8.9374e-07, -9.6349e-04, -2.1564e-03,\n",
       "                      -7.4404e-04,  5.2682e-04, -2.0611e-03,  9.7800e-04, -1.6686e-03,\n",
       "                      -2.8572e-03,  1.9607e-03,  3.2156e-03, -9.7333e-04,  1.6760e-04,\n",
       "                      -2.4098e-03, -3.4972e-03,  5.7620e-04,  1.0687e-03, -5.0231e-03,\n",
       "                      -6.3599e-04,  1.3230e-03, -2.3612e-03,  6.2167e-03,  1.5660e-03,\n",
       "                      -1.7415e-03,  8.7908e-04,  3.3946e-03,  1.2841e-03, -1.9528e-03,\n",
       "                      -3.5725e-03,  2.2709e-03, -5.3705e-04, -4.3046e-04,  4.0608e-03,\n",
       "                      -3.3883e-03, -6.0858e-04,  6.4420e-04, -1.6204e-04,  1.5395e-03,\n",
       "                      -1.3733e-03, -1.6436e-03,  3.9864e-03,  2.9120e-03, -3.9308e-04,\n",
       "                      -4.9862e-03,  1.8128e-04, -2.8177e-03, -1.2538e-03, -1.3747e-03,\n",
       "                      -7.6007e-04,  2.1745e-03,  3.6886e-03, -1.1834e-03, -2.5409e-03,\n",
       "                       3.7313e-03,  6.1757e-04, -1.0552e-03, -1.3377e-03, -1.4228e-03,\n",
       "                       1.4016e-03,  1.2980e-04, -2.4330e-03, -6.1962e-04, -9.7301e-04,\n",
       "                      -1.6317e-03, -2.3689e-03, -1.1068e-03, -2.9290e-03,  2.4566e-03,\n",
       "                      -1.1599e-03, -4.6856e-03, -3.5274e-03, -4.3862e-03,  1.9576e-03,\n",
       "                       4.9689e-03, -2.1498e-03, -1.2312e-03, -3.4121e-03, -2.5480e-03,\n",
       "                      -3.7309e-03, -4.4497e-03, -1.2304e-03,  1.6619e-03, -2.5988e-03,\n",
       "                       1.4433e-03, -2.9902e-03,  1.2110e-04,  9.5377e-05, -4.1280e-03,\n",
       "                      -2.5770e-03, -3.5254e-03, -1.2638e-03,  3.3903e-03, -1.1455e-03,\n",
       "                      -4.3406e-03, -2.2604e-03,  5.0328e-03,  2.2448e-03, -2.0556e-03,\n",
       "                       5.9170e-03,  1.0622e-03,  2.6305e-03,  4.2678e-04,  3.3221e-04,\n",
       "                       4.4219e-04, -2.5849e-03,  8.1676e-04, -1.5324e-03, -2.7611e-03,\n",
       "                       3.8327e-03, -4.3003e-03,  1.8268e-03,  2.8815e-03,  4.9033e-03,\n",
       "                       1.9501e-03, -9.9688e-04,  2.7196e-05,  1.7085e-03, -2.4392e-03,\n",
       "                      -9.7137e-05,  8.8320e-04, -3.0993e-03,  1.7025e-03, -3.6090e-03,\n",
       "                      -1.3765e-03,  2.2331e-03,  3.0646e-03,  7.6168e-04,  1.4586e-03,\n",
       "                       3.8918e-03,  3.4145e-03,  2.9104e-03, -1.1943e-03,  2.9047e-03,\n",
       "                      -3.1071e-03, -1.5113e-04, -1.1893e-03,  1.2120e-03, -4.0279e-03,\n",
       "                       2.6320e-03,  9.8094e-04,  1.1151e-03,  1.0810e-03, -7.7439e-04,\n",
       "                      -2.6017e-03], device='cuda:0')),\n",
       "             ('decoder.layers.0.multihead_attn.in_proj_weight',\n",
       "              tensor([[-0.0145, -0.0322, -0.0185,  ...,  0.0529, -0.0196, -0.0392],\n",
       "                      [-0.0402,  0.0072, -0.0517,  ...,  0.0847, -0.0589, -0.0675],\n",
       "                      [-0.0122, -0.0033,  0.0476,  ...,  0.0350,  0.0190, -0.0352],\n",
       "                      ...,\n",
       "                      [-0.0606,  0.0138, -0.0790,  ...,  0.0678, -0.0651, -0.0139],\n",
       "                      [-0.0621,  0.0638,  0.0683,  ..., -0.0383, -0.0410,  0.0031],\n",
       "                      [-0.0108,  0.0349, -0.0642,  ..., -0.0167, -0.0677, -0.0481]],\n",
       "                     device='cuda:0')),\n",
       "             ('decoder.layers.0.multihead_attn.in_proj_bias',\n",
       "              tensor([-7.7772e-04, -4.7992e-03,  3.3140e-03,  2.8480e-03, -3.4348e-03,\n",
       "                      -7.6266e-04, -8.1256e-04, -1.0636e-03, -1.8293e-03, -1.9601e-03,\n",
       "                       5.6493e-03, -2.6790e-03,  1.2592e-03,  2.2747e-03,  3.3796e-03,\n",
       "                       8.4862e-04,  5.6638e-03, -3.4521e-04, -5.2034e-03, -6.1719e-03,\n",
       "                      -1.0846e-03, -2.5898e-04,  2.3923e-03,  3.6965e-03,  1.9187e-03,\n",
       "                      -3.5603e-03,  8.1781e-03, -2.1135e-03, -4.9490e-03, -9.5192e-04,\n",
       "                       6.5992e-04, -3.8059e-03, -4.1782e-03,  5.8102e-03,  1.1657e-03,\n",
       "                       2.5276e-03, -6.3508e-03, -7.9554e-03, -1.6729e-03, -1.6326e-03,\n",
       "                       1.7700e-03, -8.8156e-04, -4.3314e-03,  7.3173e-05, -7.1091e-03,\n",
       "                      -4.9418e-03, -6.7832e-03, -6.0679e-04, -4.3312e-03, -3.2372e-04,\n",
       "                      -7.1455e-03, -4.5902e-04, -2.7214e-03, -2.8279e-03, -3.7844e-03,\n",
       "                       4.5194e-03,  6.9477e-03, -3.9659e-03, -8.1265e-04, -4.1485e-03,\n",
       "                      -5.0460e-03, -2.4114e-03,  7.8272e-05, -4.1567e-03, -4.2553e-03,\n",
       "                      -2.8529e-03, -5.0157e-03,  7.2439e-03, -1.3562e-03, -8.8826e-04,\n",
       "                      -2.9649e-03, -2.6811e-03, -6.6977e-03, -4.0373e-03, -5.8596e-03,\n",
       "                       8.9729e-04, -2.3243e-03,  2.4630e-04, -4.7092e-03,  9.0897e-04,\n",
       "                      -1.9367e-03, -8.8236e-03,  4.5625e-03,  2.0463e-03,  1.6568e-03,\n",
       "                       3.2238e-03, -3.9466e-03, -9.3286e-04, -1.1182e-03,  5.8935e-04,\n",
       "                      -1.4151e-03, -1.2015e-03,  6.0397e-03,  2.4064e-03,  1.6152e-03,\n",
       "                       1.2699e-03, -1.8806e-03, -7.8811e-03,  2.8226e-04, -1.8446e-03,\n",
       "                       5.7122e-04, -2.1014e-03, -1.2337e-03, -5.0075e-03, -4.7374e-04,\n",
       "                       3.0280e-03, -1.4597e-03, -5.9657e-04, -4.1522e-04, -5.8654e-04,\n",
       "                      -1.0770e-03,  6.5308e-03, -1.2622e-03,  6.3902e-03,  1.3942e-03,\n",
       "                      -2.0897e-03, -1.2063e-03,  3.5899e-03, -4.4870e-03, -1.0334e-02,\n",
       "                      -1.0611e-03, -2.2920e-03,  7.6944e-03, -9.7748e-03, -1.9612e-05,\n",
       "                      -6.6817e-03,  3.5192e-04, -5.8041e-03,  5.9928e-03, -3.1821e-03,\n",
       "                      -7.4648e-03, -1.2369e-04,  1.3849e-03,  1.4935e-03,  1.6997e-03,\n",
       "                      -4.2104e-04,  3.3615e-04, -6.9513e-03,  3.3074e-04,  4.0597e-03,\n",
       "                       6.1950e-03, -6.3134e-03, -8.9668e-04,  2.7274e-03,  8.3386e-04,\n",
       "                       1.7727e-04,  2.6914e-03,  7.6274e-04,  1.2031e-03,  5.5318e-03,\n",
       "                      -9.5138e-04, -9.6148e-03,  1.3176e-03,  2.1873e-03,  7.2360e-04,\n",
       "                      -6.7259e-03,  5.7169e-03,  2.2218e-03,  2.4278e-03,  2.9600e-03,\n",
       "                       6.9534e-03,  4.5990e-03,  1.9880e-03, -3.8871e-03, -4.2533e-03,\n",
       "                      -4.1710e-03, -8.7583e-04, -5.7923e-03, -5.7048e-03, -5.0604e-03,\n",
       "                      -3.4827e-03,  3.3909e-03, -2.3426e-03, -5.8656e-03,  1.1955e-02,\n",
       "                       9.0218e-04, -1.3166e-03,  1.1008e-03, -1.6921e-03,  3.5117e-03,\n",
       "                       1.0804e-03, -7.9233e-03, -2.0857e-03, -5.7586e-03,  3.7823e-03,\n",
       "                      -2.1957e-04,  6.7664e-03, -1.3546e-03,  6.2797e-03,  6.4080e-04,\n",
       "                       1.2552e-03, -6.4988e-03,  7.7100e-03,  1.7879e-03,  1.3043e-03,\n",
       "                      -6.0759e-04,  1.7093e-03,  1.6159e-06,  4.5933e-03,  6.8294e-03,\n",
       "                      -2.7193e-03, -1.5805e-03, -6.0029e-03, -3.8271e-03, -4.7462e-03,\n",
       "                       2.8368e-03, -1.4688e-03, -2.5191e-03,  3.4477e-03, -4.0232e-03,\n",
       "                      -4.9086e-03, -3.0359e-03, -3.2183e-03,  6.2580e-03, -5.1223e-03,\n",
       "                      -1.2155e-03, -1.4527e-03, -6.5888e-04, -5.1264e-03,  9.2860e-04,\n",
       "                       7.6734e-03,  2.7631e-03, -5.7695e-03,  8.7927e-03,  1.9611e-03,\n",
       "                       2.3025e-03,  1.8164e-04, -1.4153e-03, -7.5310e-03,  8.3627e-04,\n",
       "                      -4.4448e-03, -4.0313e-03, -4.0763e-03,  1.1883e-03,  6.4968e-03,\n",
       "                      -2.3091e-03,  7.6223e-03,  4.7273e-03, -2.9800e-03,  1.6091e-04,\n",
       "                      -3.0669e-03,  2.0683e-03, -1.1967e-03,  3.6174e-03, -5.0906e-03,\n",
       "                       6.6398e-03,  3.5431e-03, -6.2213e-03, -5.5078e-03,  4.7223e-03,\n",
       "                       3.3473e-03,  1.6250e-03, -1.7045e-03,  3.5603e-03, -1.6110e-03,\n",
       "                      -5.8650e-03,  2.9750e-07, -1.4700e-06, -9.1424e-07,  5.8214e-07,\n",
       "                      -9.9261e-07, -1.1809e-07,  1.0000e-06, -3.4855e-07,  1.8460e-06,\n",
       "                      -2.9307e-07, -2.0908e-07,  8.3654e-08,  4.3124e-07, -5.0296e-07,\n",
       "                       2.2705e-07,  2.8909e-07, -6.9957e-07,  8.5642e-07,  2.2013e-07,\n",
       "                       3.5114e-07, -7.8794e-07,  4.7308e-07,  2.0011e-07,  1.4867e-06,\n",
       "                      -9.4936e-08,  1.0606e-06, -2.2526e-07, -1.0107e-06, -1.6953e-06,\n",
       "                       1.2301e-06,  2.7429e-07,  7.1111e-07,  3.0971e-07, -1.0599e-06,\n",
       "                       8.2951e-07, -7.5974e-07, -6.1794e-08,  1.3621e-07,  2.8331e-07,\n",
       "                      -6.5856e-07,  4.0808e-07, -1.7426e-06,  2.4727e-07,  1.3218e-06,\n",
       "                      -2.1598e-06,  3.3656e-07, -1.6114e-06, -5.7070e-07, -3.0181e-07,\n",
       "                       2.8872e-07,  1.3197e-06, -6.8851e-07, -7.7123e-08,  1.5537e-06,\n",
       "                       5.0443e-07,  1.2048e-06,  7.6606e-07, -8.8363e-07,  1.3873e-06,\n",
       "                      -2.4020e-06,  4.9405e-07,  1.6775e-06,  6.4188e-07,  2.2083e-07,\n",
       "                       1.1065e-04,  3.9179e-05, -7.0138e-05, -1.1558e-04, -9.5941e-05,\n",
       "                       9.0148e-05,  3.8698e-05, -6.3853e-05,  6.9169e-05, -8.6001e-05,\n",
       "                      -4.8033e-05,  4.5922e-05, -7.6515e-05,  5.7183e-05, -6.7019e-05,\n",
       "                      -4.2993e-05,  4.0831e-05,  7.9814e-06,  6.3213e-05,  1.0566e-04,\n",
       "                      -7.2818e-05,  3.3323e-05,  3.7314e-05, -4.3141e-05,  8.5090e-05,\n",
       "                       3.0179e-05,  7.1080e-05,  8.2477e-05,  9.6304e-05,  8.8666e-05,\n",
       "                       6.3993e-05,  6.1573e-05,  6.4254e-05, -6.9684e-05,  8.2312e-05,\n",
       "                      -5.8794e-05,  1.5333e-05, -8.5298e-07, -5.7070e-05, -2.4961e-05,\n",
       "                      -4.0807e-05, -8.5156e-05, -5.9105e-05,  7.3908e-05,  7.2563e-05,\n",
       "                       7.7143e-05,  9.5276e-05,  8.7871e-05, -1.0098e-04,  1.0917e-04,\n",
       "                       3.8794e-05, -5.6072e-05,  5.2117e-05, -7.9219e-05, -5.4142e-05,\n",
       "                      -5.5544e-05, -1.0677e-04,  4.5917e-05, -8.1550e-05, -7.2796e-05,\n",
       "                      -1.8013e-05, -7.8720e-05,  1.2399e-04,  2.7523e-05,  1.5535e-04,\n",
       "                      -1.7539e-04, -1.3650e-04, -1.6673e-04, -1.6509e-04,  9.6579e-05,\n",
       "                      -1.0112e-04,  5.6151e-05, -1.1836e-04,  1.7948e-04,  5.3770e-05,\n",
       "                       7.9608e-05,  1.5795e-04, -4.3110e-05,  1.0314e-04, -5.7572e-05,\n",
       "                       1.2825e-04,  7.4510e-05, -2.0335e-05,  1.4391e-04,  7.3025e-05,\n",
       "                       1.4117e-04, -1.5888e-04, -7.3293e-05, -1.5970e-04,  6.6981e-05,\n",
       "                       7.5849e-05,  1.6452e-04,  1.2440e-04,  9.6514e-05,  5.9656e-06,\n",
       "                       1.4487e-04,  9.6984e-05,  5.1101e-05,  4.3027e-05,  1.6222e-04,\n",
       "                       1.4933e-04, -9.7897e-05, -4.7776e-05, -1.4396e-04, -1.4524e-04,\n",
       "                      -6.6602e-05, -1.8002e-04,  9.1927e-05, -1.2608e-04, -4.1816e-05,\n",
       "                       1.2953e-04,  1.0411e-04, -7.0728e-05, -1.5893e-04, -1.0802e-04,\n",
       "                       1.8646e-04, -2.7556e-04, -1.2236e-04, -1.7439e-04, -1.6261e-04,\n",
       "                      -1.5109e-04, -9.2151e-05, -5.2898e-05, -1.6005e-04,  4.6395e-05,\n",
       "                       1.0837e-04,  1.1072e-04, -1.9585e-04, -2.4891e-04,  1.9511e-04,\n",
       "                       2.2033e-04, -6.6730e-05,  3.3129e-04, -3.0253e-04, -1.5915e-04,\n",
       "                      -2.0842e-04, -2.4452e-04,  2.4241e-04,  1.8721e-04,  2.5431e-04,\n",
       "                       2.0431e-04,  2.0812e-04, -2.0818e-04,  1.7030e-04,  2.3917e-04,\n",
       "                      -2.4172e-04, -2.6806e-04, -2.2935e-04,  1.0492e-04,  3.2806e-04,\n",
       "                      -1.9659e-04,  2.7743e-04,  2.6214e-04,  1.5270e-04, -2.8158e-04,\n",
       "                      -1.2486e-04,  2.5946e-04, -1.4607e-05, -2.7271e-04,  6.4573e-05,\n",
       "                      -2.2215e-04, -1.5727e-04, -2.9877e-04,  3.9011e-04, -2.3877e-04,\n",
       "                       2.8288e-04, -1.4701e-04,  1.5950e-04,  1.9589e-04, -2.2246e-04,\n",
       "                      -2.4608e-04, -2.3700e-04,  2.0254e-04, -1.5546e-04,  2.1306e-04,\n",
       "                       1.1902e-04,  2.5625e-04,  1.1639e-04, -1.5957e-04, -1.8165e-04,\n",
       "                      -2.6010e-04, -1.7186e-04, -1.0495e-04, -3.3139e-04,  2.0299e-04,\n",
       "                      -2.2367e-04,  1.6851e-04,  1.6491e-04, -2.0104e-04, -2.0489e-04,\n",
       "                       2.0961e-04,  2.3305e-04, -9.0228e-05,  1.7677e-03,  3.0629e-04,\n",
       "                       9.4963e-04, -8.5013e-05, -6.1498e-04, -1.4584e-03,  1.0755e-03,\n",
       "                       2.1677e-03, -3.3033e-03, -1.7900e-03, -8.8887e-04,  3.5700e-04,\n",
       "                      -5.3945e-04,  2.0964e-04, -1.8065e-03,  6.8758e-04,  1.1830e-03,\n",
       "                       2.6477e-03, -1.5894e-03,  2.9910e-04, -3.4513e-03, -1.5817e-04,\n",
       "                      -1.7023e-03,  2.5345e-03,  1.2305e-03, -2.5879e-03,  2.3752e-04,\n",
       "                      -1.6636e-04, -4.0591e-04,  1.0882e-03, -2.4218e-03, -2.8925e-03,\n",
       "                      -1.8671e-03, -1.0025e-03,  1.7767e-03,  9.1044e-04,  7.8761e-04,\n",
       "                      -1.9918e-03, -7.0797e-04,  8.0383e-04, -1.0674e-04,  4.0991e-04,\n",
       "                       2.8209e-03,  1.3075e-03,  1.1402e-03, -2.3092e-04,  5.3760e-03,\n",
       "                      -7.7968e-04,  3.2072e-03,  2.4050e-03,  3.6948e-04, -7.0780e-04,\n",
       "                       9.3598e-04,  1.5820e-03,  1.8738e-03,  1.8527e-03,  2.9330e-03,\n",
       "                      -8.2502e-04, -8.5803e-04,  9.3681e-04,  2.2065e-03, -1.8472e-03,\n",
       "                       1.8879e-04,  1.1208e-03, -1.4647e-03,  1.0661e-03,  3.8038e-03,\n",
       "                       1.2354e-04, -8.8820e-04, -2.4783e-03,  5.2464e-04, -5.8648e-04,\n",
       "                      -7.7260e-04, -1.5798e-03, -6.7146e-04,  2.1829e-04,  2.9963e-03,\n",
       "                       4.8145e-04, -1.2428e-03, -5.4190e-04, -7.7734e-04,  2.4558e-04,\n",
       "                       1.9339e-03,  6.6102e-03,  1.5340e-03, -3.4045e-03,  1.7993e-03,\n",
       "                       3.6835e-04,  1.5089e-05, -1.7804e-03, -4.0614e-04, -3.4770e-04,\n",
       "                      -5.0531e-04,  5.7002e-04,  1.8568e-03,  1.3753e-03,  8.5943e-05,\n",
       "                       3.8571e-03, -2.7139e-03, -1.0429e-03, -2.2862e-03, -1.5299e-04,\n",
       "                      -2.6023e-04, -1.6948e-03,  2.1120e-03, -1.4948e-03, -3.0956e-03,\n",
       "                      -3.6438e-04,  1.3659e-03,  4.1184e-05, -4.4999e-04,  1.3312e-03,\n",
       "                      -2.9003e-03, -3.5531e-04,  1.2695e-04, -2.5528e-03,  4.2704e-04,\n",
       "                       7.6153e-04,  8.9897e-04, -1.9593e-03, -1.7334e-03,  2.8279e-03,\n",
       "                      -7.8405e-04, -1.7274e-03, -3.2099e-03,  1.9381e-03,  5.4101e-04,\n",
       "                       4.0650e-04,  1.8757e-03, -3.2956e-04,  2.8641e-03, -1.1813e-03,\n",
       "                       4.0248e-03, -3.6484e-04, -3.0770e-04,  4.6590e-03,  6.5696e-05,\n",
       "                       1.4387e-05, -2.2504e-03, -5.2034e-04,  4.1235e-03,  2.7586e-04,\n",
       "                       1.6372e-03, -7.3880e-05, -1.9749e-03, -1.4280e-04,  2.0615e-03,\n",
       "                      -2.8480e-03,  2.2476e-03, -2.6514e-04,  2.4272e-03, -1.9027e-03,\n",
       "                      -1.4927e-04,  1.4480e-03,  2.0570e-03,  1.4981e-03, -2.1464e-05,\n",
       "                       2.3910e-03,  1.1800e-03, -2.4336e-03, -1.2138e-03,  1.3496e-03,\n",
       "                      -4.3480e-04, -7.8869e-04, -3.3945e-03,  2.8244e-04,  1.4024e-03,\n",
       "                      -2.3287e-03,  1.7921e-03, -6.2335e-04,  2.2375e-04, -2.1143e-03,\n",
       "                       7.6838e-04,  2.2944e-03,  7.3262e-04,  1.9904e-03, -1.4066e-03,\n",
       "                       1.4659e-03, -7.7740e-04,  6.9895e-04,  4.6102e-03,  3.2055e-04,\n",
       "                       2.5040e-04,  1.8492e-03, -8.0932e-04,  1.4720e-03, -2.1185e-03,\n",
       "                       1.6048e-04, -1.9986e-04, -2.0700e-04, -1.8219e-03, -1.0879e-03,\n",
       "                       4.7641e-04, -6.5754e-04,  2.3322e-03, -1.9695e-04, -6.1772e-04,\n",
       "                      -1.8447e-03, -1.1295e-03, -2.8812e-04,  1.6216e-03,  2.8233e-04,\n",
       "                       5.4522e-04,  8.4562e-04,  6.3261e-04,  5.0998e-03, -8.4656e-04,\n",
       "                      -6.6873e-04, -1.9347e-03, -2.9562e-03,  1.1602e-03,  1.4395e-03,\n",
       "                       2.5848e-03,  1.5877e-03, -3.8118e-05,  7.2594e-04, -4.8680e-05,\n",
       "                      -2.0903e-03,  1.4561e-03,  1.2204e-03, -2.6579e-03,  2.3347e-03,\n",
       "                      -4.2779e-03, -1.6939e-03,  1.3427e-03, -4.9474e-04, -1.5249e-03,\n",
       "                       2.3705e-03, -1.3237e-03,  1.8353e-03, -8.7840e-04,  2.8183e-03,\n",
       "                       1.7247e-04, -2.7743e-03, -1.7557e-03, -4.4792e-03,  1.5115e-03,\n",
       "                      -2.3232e-03, -3.4627e-03, -1.1200e-03,  2.0646e-03, -4.3696e-05,\n",
       "                      -5.0260e-03,  1.1985e-03,  2.7817e-04, -2.9489e-03,  2.0770e-03,\n",
       "                       4.8049e-03, -5.5510e-04, -1.5456e-03,  1.6816e-03, -1.3284e-04,\n",
       "                       4.4150e-04,  1.7648e-03, -6.5788e-04], device='cuda:0')),\n",
       "             ('decoder.layers.0.multihead_attn.out_proj.weight',\n",
       "              tensor([[ 0.0257, -0.0012, -0.0077,  ..., -0.0363, -0.0477, -0.0186],\n",
       "                      [-0.0212, -0.0072, -0.0134,  ..., -0.0209,  0.0075, -0.0168],\n",
       "                      [-0.0099, -0.0324,  0.0494,  ...,  0.0263, -0.0536,  0.0207],\n",
       "                      ...,\n",
       "                      [ 0.0290, -0.0299, -0.0108,  ..., -0.0241,  0.0329, -0.0197],\n",
       "                      [ 0.0267, -0.0040, -0.0097,  ..., -0.0602,  0.0546,  0.0149],\n",
       "                      [-0.0243,  0.0542, -0.0008,  ...,  0.0180, -0.0096, -0.0490]],\n",
       "                     device='cuda:0')),\n",
       "             ('decoder.layers.0.multihead_attn.out_proj.bias',\n",
       "              tensor([ 3.6295e-04,  4.6779e-04,  1.5012e-03,  1.4093e-03, -9.1927e-04,\n",
       "                       2.5505e-03, -3.0513e-03, -1.6000e-03,  2.7581e-03, -6.4874e-05,\n",
       "                      -1.5662e-03,  3.3476e-03, -3.2240e-04, -5.1953e-05,  1.9211e-04,\n",
       "                       7.0882e-06,  6.0284e-04, -1.2183e-03,  1.6033e-03,  3.6477e-03,\n",
       "                      -3.6781e-04,  2.9899e-03,  1.4558e-03,  3.4536e-03,  1.8723e-03,\n",
       "                      -2.0209e-04,  6.0166e-03, -1.0171e-03, -3.3101e-03, -2.9519e-04,\n",
       "                      -1.7780e-03, -1.7182e-03,  2.9359e-03, -2.3397e-04, -1.2031e-03,\n",
       "                      -2.4680e-03,  1.8766e-03,  1.5876e-03, -1.8350e-03,  5.7818e-04,\n",
       "                      -1.9218e-03,  3.5680e-03,  7.8626e-04, -1.3982e-03,  7.4404e-04,\n",
       "                       1.9389e-04,  2.5384e-03,  1.9309e-03,  1.3977e-04,  3.5903e-03,\n",
       "                      -5.7107e-04,  1.3183e-03, -1.0528e-04,  5.4717e-04, -1.0617e-03,\n",
       "                      -1.0267e-03, -3.1090e-03, -4.0314e-03,  1.9913e-03,  1.9393e-03,\n",
       "                      -1.0813e-03,  4.7514e-03, -9.1137e-04, -3.0298e-03,  2.8251e-03,\n",
       "                      -2.9015e-03, -1.4830e-03, -1.1478e-03, -2.2985e-03,  1.5007e-03,\n",
       "                       2.8265e-03,  2.7449e-03, -1.2312e-03, -1.5511e-03,  2.4327e-03,\n",
       "                      -2.2371e-04, -3.3666e-04, -1.0406e-03,  8.7457e-04,  2.2876e-04,\n",
       "                       1.0858e-03, -5.4952e-04, -3.8897e-03,  5.1979e-04, -2.3045e-03,\n",
       "                      -2.5520e-03, -3.6027e-03,  3.2406e-03, -1.7724e-03,  1.3977e-03,\n",
       "                      -9.1182e-04,  1.9437e-03, -1.5848e-03,  3.0230e-03, -2.1229e-03,\n",
       "                       1.3138e-03, -5.6494e-04,  3.5149e-03,  7.0002e-04,  2.8917e-03,\n",
       "                       2.4857e-03,  7.9225e-04, -2.2803e-03, -9.1255e-04, -7.7333e-04,\n",
       "                      -2.3655e-03,  1.3676e-04, -3.5739e-03,  1.4553e-03, -1.4774e-03,\n",
       "                       5.1649e-05, -7.0058e-04, -1.9055e-04,  1.4205e-03, -3.0386e-04,\n",
       "                      -2.3995e-03,  2.1101e-04,  3.6055e-04, -1.3846e-03, -2.9588e-03,\n",
       "                      -1.0019e-03,  2.2962e-03,  1.1889e-03, -2.4014e-04,  3.5260e-04,\n",
       "                      -2.4738e-03, -1.9921e-03, -7.6262e-04,  1.0616e-03, -2.9301e-03,\n",
       "                      -1.6142e-04,  2.6944e-03,  1.4763e-04,  4.5530e-04, -1.5536e-03,\n",
       "                      -1.8605e-03,  3.1118e-03,  1.8590e-03,  3.1024e-04, -1.7278e-03,\n",
       "                      -3.1551e-03,  1.6651e-03, -3.7943e-03, -1.2051e-03,  1.5597e-03,\n",
       "                      -1.6367e-03, -3.5043e-03, -4.8042e-03, -3.4644e-03, -7.6140e-04,\n",
       "                       1.4294e-04,  2.1578e-04,  3.1047e-03, -1.9917e-03,  1.3405e-04,\n",
       "                      -3.6627e-03, -2.4720e-03, -4.1177e-03,  6.2035e-04,  2.1171e-03,\n",
       "                      -1.9634e-03,  3.7448e-03,  3.7730e-03, -2.0540e-03, -4.8845e-03,\n",
       "                       5.2827e-03,  2.2830e-04,  1.2367e-03, -3.0060e-03,  4.6426e-03,\n",
       "                       3.9752e-03,  1.9793e-03,  3.6288e-05,  7.7009e-04, -1.7833e-03,\n",
       "                      -1.7512e-03, -1.7987e-03, -2.7824e-03, -1.8574e-03,  1.5798e-03,\n",
       "                      -2.5528e-03, -6.0438e-03, -9.1306e-04, -4.2049e-03,  2.0241e-03,\n",
       "                       1.4755e-03,  1.7497e-04,  2.3119e-04, -3.3546e-03, -1.9225e-03,\n",
       "                      -2.2567e-03, -5.3957e-03,  1.1716e-03, -8.9081e-04, -2.3778e-03,\n",
       "                       2.3225e-03, -3.1984e-03,  1.5734e-03, -1.1894e-03, -2.4175e-03,\n",
       "                      -2.5970e-03, -8.9599e-04,  2.2984e-04,  1.2437e-03, -1.3417e-04,\n",
       "                       1.7375e-03,  2.2060e-04, -4.8117e-04,  1.6101e-03, -4.0385e-03,\n",
       "                       6.4935e-03,  3.1289e-03,  1.4177e-03,  1.3758e-03,  2.7613e-03,\n",
       "                       1.8070e-03, -7.7621e-04, -2.6338e-04, -2.9780e-03, -7.9062e-04,\n",
       "                      -9.0546e-04,  7.4130e-04,  2.1225e-03,  4.3720e-03,  3.5198e-03,\n",
       "                       1.5261e-04, -1.5303e-03,  4.4637e-03,  2.0462e-03, -2.2861e-03,\n",
       "                      -9.4668e-04,  2.4990e-03, -1.7334e-04,  1.0124e-03, -2.4409e-03,\n",
       "                       3.7994e-04,  4.1387e-03,  1.8162e-03, -3.3621e-04, -8.4368e-05,\n",
       "                       3.4322e-03,  5.0278e-03, -1.9396e-03, -3.8570e-04,  3.2059e-04,\n",
       "                      -3.7121e-04, -9.3538e-04, -9.0088e-04,  1.1305e-03,  1.7696e-04,\n",
       "                       2.6393e-03,  1.2386e-04,  3.4675e-03,  5.2133e-04,  2.1861e-03,\n",
       "                      -2.0210e-03], device='cuda:0')),\n",
       "             ('decoder.layers.0.linear1.weight',\n",
       "              tensor([[-4.6995e-02,  4.8815e-02,  4.3768e-02,  ...,  2.3785e-02,\n",
       "                        1.0326e-02,  5.0684e-04],\n",
       "                      [-3.2870e-03,  9.8835e-03, -4.3784e-02,  ...,  4.6585e-02,\n",
       "                        1.3979e-03,  6.5167e-02],\n",
       "                      [-1.4262e-02,  2.2850e-02,  1.1070e-02,  ..., -1.4521e-02,\n",
       "                       -3.2596e-02,  1.9515e-02],\n",
       "                      ...,\n",
       "                      [-1.9164e-02, -5.0610e-05, -2.8418e-02,  ...,  7.6695e-03,\n",
       "                       -3.3731e-02, -2.0916e-02],\n",
       "                      [-1.9417e-02, -4.2319e-03,  4.1414e-02,  ..., -3.2802e-02,\n",
       "                        7.3863e-03,  2.0919e-02],\n",
       "                      [ 3.1057e-02, -4.0991e-02,  4.6139e-02,  ...,  7.0961e-02,\n",
       "                       -4.5821e-02,  3.0041e-02]], device='cuda:0')),\n",
       "             ('decoder.layers.0.linear1.bias',\n",
       "              tensor([ 0.0629, -0.0068, -0.0021,  ...,  0.0209,  0.0213, -0.0345],\n",
       "                     device='cuda:0')),\n",
       "             ('decoder.layers.0.linear2.weight',\n",
       "              tensor([[ 3.8064e-02, -3.3192e-03, -8.3478e-03,  ..., -9.7205e-03,\n",
       "                        2.3960e-02, -1.0064e-02],\n",
       "                      [-1.1771e-03, -8.7264e-04, -3.5216e-03,  ..., -6.6206e-04,\n",
       "                       -2.9099e-02, -1.9473e-03],\n",
       "                      [-1.7676e-02, -1.8379e-02, -1.3887e-03,  ..., -1.6499e-02,\n",
       "                        1.3382e-02,  4.9935e-03],\n",
       "                      ...,\n",
       "                      [ 1.2304e-02,  1.2393e-02, -3.3300e-03,  ..., -2.8242e-03,\n",
       "                        1.4109e-02, -2.4518e-02],\n",
       "                      [ 2.8645e-02, -1.5448e-02,  3.1862e-05,  ...,  2.0655e-02,\n",
       "                       -2.0170e-02,  8.3578e-03],\n",
       "                      [-4.6974e-03, -1.3269e-02,  9.5957e-03,  ..., -7.5764e-04,\n",
       "                        4.2387e-03, -2.3693e-02]], device='cuda:0')),\n",
       "             ('decoder.layers.0.linear2.bias',\n",
       "              tensor([ 2.1320e-02, -1.2227e-02,  2.5006e-03,  9.6946e-03,  1.7779e-02,\n",
       "                      -7.3774e-03,  1.8725e-02,  1.2833e-02,  1.4936e-02, -1.8611e-02,\n",
       "                      -2.3319e-02, -1.1926e-02, -1.5976e-02, -7.9775e-03, -1.6747e-02,\n",
       "                       1.5163e-02,  1.9125e-02,  1.2863e-03, -1.0159e-02, -1.1352e-02,\n",
       "                      -9.8317e-03,  2.1872e-02, -7.8997e-03,  2.1668e-02,  1.3825e-02,\n",
       "                      -1.9183e-02,  1.1793e-02,  9.8515e-03, -1.5705e-02,  4.2540e-03,\n",
       "                       2.0175e-02, -8.8537e-03,  1.8229e-02,  2.0242e-02, -4.4076e-03,\n",
       "                      -1.4292e-02, -8.5424e-03,  6.4826e-03, -1.6823e-02,  4.7114e-04,\n",
       "                       6.5291e-03, -2.2974e-03, -9.1666e-03, -1.2945e-02, -1.4237e-02,\n",
       "                       9.3705e-03, -2.5901e-03, -6.5839e-03,  7.4177e-03, -9.1217e-03,\n",
       "                      -1.9885e-02,  7.7351e-03,  3.6239e-03,  1.7833e-02, -1.7186e-02,\n",
       "                       5.0490e-03,  1.2212e-02,  4.5992e-03,  4.2101e-03, -1.5536e-02,\n",
       "                      -1.5822e-02, -2.0659e-02, -2.7109e-03,  1.9589e-04,  1.9340e-03,\n",
       "                       1.1225e-02, -7.0501e-03,  6.0265e-03, -1.9405e-02,  9.5512e-03,\n",
       "                      -8.1328e-03, -1.8379e-02, -1.5352e-03,  1.2344e-02, -1.6416e-02,\n",
       "                       1.6222e-02,  1.5354e-02,  2.0960e-02, -6.9081e-03,  1.6445e-02,\n",
       "                      -5.3548e-03, -2.7179e-03,  4.9555e-03,  1.9881e-02, -1.8873e-02,\n",
       "                       4.3611e-03,  1.1894e-02, -3.6951e-03,  4.8305e-03, -1.9415e-02,\n",
       "                       1.2983e-02,  6.9352e-03,  1.1656e-02,  6.7839e-03,  4.1211e-03,\n",
       "                       1.9922e-02,  3.4673e-04,  1.1758e-02, -4.1654e-03,  1.8922e-02,\n",
       "                      -6.3684e-03, -1.5674e-02, -1.5962e-02, -1.1450e-02, -4.3784e-03,\n",
       "                      -1.6588e-02,  2.0047e-02,  3.8270e-03, -1.1646e-02,  1.6473e-02,\n",
       "                       1.9168e-02,  2.0487e-03, -1.9283e-02, -2.5941e-03, -1.4655e-02,\n",
       "                       3.2019e-03,  1.7716e-03, -2.7255e-03, -3.9024e-03,  8.3958e-04,\n",
       "                       6.0229e-03,  1.6913e-02, -4.4666e-04,  1.8055e-02,  1.6030e-02,\n",
       "                       9.5371e-03, -4.3535e-03, -1.5259e-02,  4.8812e-03,  1.2425e-02,\n",
       "                      -1.5338e-02, -1.3804e-02, -8.4345e-03,  4.6514e-04,  1.5986e-03,\n",
       "                      -2.3077e-02, -1.9534e-02,  1.8407e-02,  4.9706e-05,  5.8991e-03,\n",
       "                      -1.4870e-02, -8.3675e-03, -1.5775e-02,  8.5549e-03, -9.2880e-03,\n",
       "                      -1.2909e-02, -3.9702e-03,  1.0400e-02,  2.2492e-02,  6.3919e-03,\n",
       "                      -1.2354e-02, -3.2629e-03, -8.7884e-03,  1.5670e-02, -1.4594e-04,\n",
       "                      -1.1872e-02,  1.9223e-02,  9.2086e-03,  1.5162e-02, -1.5717e-02,\n",
       "                       6.5247e-03, -1.8066e-04, -1.8363e-02, -2.3605e-02,  4.0125e-03,\n",
       "                      -9.8496e-03,  1.3380e-02, -1.0359e-03,  1.6535e-02,  1.5521e-02,\n",
       "                       1.9605e-02,  7.6165e-04, -2.7110e-03, -7.5580e-03, -2.6849e-03,\n",
       "                       4.1093e-03,  1.5545e-02, -2.0887e-02, -1.0031e-02, -1.2165e-02,\n",
       "                      -4.9844e-03,  1.5098e-02, -5.0340e-03, -4.3355e-04,  5.4395e-03,\n",
       "                      -3.8310e-03,  1.2640e-02,  7.5090e-04, -1.1030e-02, -5.2943e-04,\n",
       "                       2.0177e-02,  9.5140e-04,  1.1916e-02, -3.6646e-03,  9.5147e-04,\n",
       "                      -1.8769e-02,  1.2131e-02,  1.5580e-02, -1.7290e-02,  1.5418e-03,\n",
       "                       1.2668e-02, -1.7944e-02, -1.6050e-02,  1.5268e-02, -8.5654e-03,\n",
       "                      -1.2972e-02, -2.1940e-02, -1.0125e-02, -1.7933e-02,  1.8644e-02,\n",
       "                      -1.2486e-02,  1.1878e-02, -1.6760e-02,  1.8576e-02, -1.8628e-02,\n",
       "                       3.6644e-03,  2.1378e-02,  1.3341e-02,  2.2023e-02,  1.8126e-02,\n",
       "                      -1.6001e-03, -6.2030e-03,  1.7221e-02, -1.6424e-02,  1.6149e-02,\n",
       "                       1.0764e-02,  1.9301e-02,  2.1351e-02,  2.8833e-03,  5.2099e-03,\n",
       "                       2.0229e-02,  9.1043e-04,  1.4733e-02,  1.4595e-02, -9.0049e-03,\n",
       "                       1.8653e-02, -1.4924e-02,  1.8616e-03, -7.6801e-03, -1.5252e-02,\n",
       "                       9.8561e-03, -1.6123e-02, -1.3817e-03,  4.9322e-03,  1.5245e-02,\n",
       "                      -1.3596e-02,  1.5158e-02, -3.5252e-03,  1.7607e-02,  1.2648e-03,\n",
       "                      -1.9815e-02,  6.1991e-03,  2.4649e-03,  1.1064e-02,  5.7787e-03,\n",
       "                       2.0911e-02], device='cuda:0')),\n",
       "             ('decoder.layers.0.norm1.weight',\n",
       "              tensor([0.9845, 0.9869, 0.9837, 0.9913, 0.9870, 0.9854, 0.9837, 0.9782, 0.9867,\n",
       "                      0.9871, 0.9865, 0.9795, 0.9843, 0.9871, 0.9947, 0.9911, 1.0017, 0.9839,\n",
       "                      0.9889, 0.9909, 0.9829, 0.9901, 0.9763, 0.9853, 0.9933, 0.9903, 0.9802,\n",
       "                      0.9872, 1.0012, 0.9982, 0.9838, 1.0095, 0.9871, 1.0045, 1.0023, 0.9997,\n",
       "                      0.9948, 0.9928, 0.9898, 0.9877, 0.9934, 0.9911, 1.0024, 0.9873, 0.9945,\n",
       "                      0.9899, 0.9871, 1.0038, 1.0044, 0.9930, 1.0004, 0.9901, 1.0000, 0.9938,\n",
       "                      0.9950, 0.9982, 0.9975, 0.9994, 0.9977, 1.0073, 1.0046, 0.9898, 0.9960,\n",
       "                      0.9962, 0.9956, 1.0127, 0.9930, 0.9924, 1.0075, 0.9990, 0.9997, 0.9963,\n",
       "                      0.9922, 0.9993, 0.9952, 0.9978, 1.0139, 1.0045, 1.0013, 1.0031, 0.9982,\n",
       "                      1.0027, 1.0005, 1.0050, 0.9977, 1.0070, 1.0052, 1.0041, 1.0087, 1.0009,\n",
       "                      1.0075, 0.9991, 0.9971, 1.0055, 0.9864, 1.0161, 1.0060, 1.0034, 0.9980,\n",
       "                      1.0110, 1.0031, 1.0027, 0.9968, 1.0120, 1.0091, 1.0030, 1.0086, 1.0062,\n",
       "                      1.0015, 1.0130, 1.0084, 1.0038, 1.0133, 1.0078, 1.0216, 1.0121, 1.0099,\n",
       "                      0.9990, 1.0030, 1.0038, 1.0072, 1.0040, 1.0155, 1.0026, 0.9972, 1.0018,\n",
       "                      1.0042, 1.0038, 1.0113, 0.9948, 1.0082, 1.0031, 1.0092, 1.0123, 1.0117,\n",
       "                      1.0083, 1.0141, 1.0186, 1.0142, 1.0084, 1.0124, 1.0023, 1.0059, 1.0084,\n",
       "                      1.0036, 0.9992, 1.0175, 1.0060, 0.9983, 1.0022, 0.9998, 1.0095, 1.0163,\n",
       "                      1.0086, 0.9987, 1.0004, 1.0119, 1.0027, 1.0117, 1.0046, 1.0153, 1.0173,\n",
       "                      1.0157, 0.9949, 1.0068, 0.9986, 1.0128, 0.9979, 1.0175, 1.0029, 1.0009,\n",
       "                      1.0021, 1.0215, 1.0044, 1.0014, 0.9992, 1.0175, 0.9916, 1.0162, 1.0134,\n",
       "                      1.0090, 1.0038, 1.0070, 0.9974, 1.0072, 1.0163, 1.0108, 1.0021, 1.0012,\n",
       "                      0.9957, 1.0110, 1.0050, 1.0315, 1.0028, 1.0227, 0.9912, 1.0029, 1.0006,\n",
       "                      1.0121, 0.9939, 1.0057, 1.0009, 1.0217, 1.0138, 1.0053, 1.0067, 1.0114,\n",
       "                      1.0038, 1.0078, 1.0030, 1.0124, 1.0040, 0.9984, 0.9979, 1.0084, 1.0025,\n",
       "                      1.0051, 0.9886, 1.0016, 0.9968, 1.0102, 1.0033, 0.9943, 1.0089, 1.0132,\n",
       "                      1.0010, 1.0081, 0.9936, 1.0136, 1.0082, 1.0121, 1.0033, 1.0152, 1.0019,\n",
       "                      1.0133, 1.0004, 1.0045, 1.0027, 0.9944, 0.9958, 1.0138, 1.0026, 1.0146,\n",
       "                      0.9987, 1.0091, 0.9972, 1.0148, 0.9949, 1.0248, 0.9996, 0.9906, 1.0053,\n",
       "                      1.0280, 0.9939, 0.9939, 1.0024], device='cuda:0')),\n",
       "             ('decoder.layers.0.norm1.bias',\n",
       "              tensor([ 4.1743e-03, -3.2175e-03,  4.5170e-03,  2.4484e-03, -2.3435e-03,\n",
       "                      -8.3417e-04, -3.2258e-03,  2.4807e-03,  4.8004e-03,  6.2398e-03,\n",
       "                      -3.1112e-03,  2.6895e-03, -1.9649e-03, -3.6774e-04,  4.4870e-03,\n",
       "                      -2.1366e-03, -8.2728e-04, -9.2450e-04,  2.1282e-03,  6.4032e-05,\n",
       "                       3.0940e-03,  3.8289e-03,  4.5860e-03,  5.1754e-03,  3.9182e-03,\n",
       "                      -2.7199e-03,  7.0590e-03, -2.9817e-03, -2.6811e-03,  2.2774e-03,\n",
       "                       1.8108e-03, -5.3253e-03,  6.1164e-03,  2.8954e-04, -6.3743e-04,\n",
       "                      -5.3847e-03,  1.1506e-03,  4.1972e-03, -4.1590e-03, -3.5058e-03,\n",
       "                      -4.8481e-03,  4.2596e-03, -1.9295e-03,  1.6877e-03,  2.3773e-03,\n",
       "                       4.4131e-03,  4.1349e-03,  4.1627e-03,  2.1781e-03,  4.0685e-03,\n",
       "                       2.0265e-03, -4.1244e-03, -2.3128e-03,  4.5795e-03, -2.0377e-03,\n",
       "                       2.7632e-03, -3.2196e-03, -4.5392e-03,  1.4637e-03,  2.9935e-04,\n",
       "                      -8.7175e-04,  4.8561e-03, -9.2614e-04, -5.3457e-03,  2.4719e-03,\n",
       "                      -3.2227e-03, -3.8678e-03, -2.8416e-03,  4.4923e-03,  4.2237e-03,\n",
       "                       4.4606e-03,  5.1141e-03, -3.1698e-03, -3.7024e-03,  2.0304e-03,\n",
       "                       1.2490e-03, -2.4739e-03,  1.0553e-03,  3.0232e-03, -7.6781e-04,\n",
       "                       2.4557e-03, -1.8068e-03, -3.5538e-03,  3.6400e-03, -4.5461e-03,\n",
       "                       2.3902e-03, -4.5766e-03,  5.0723e-03, -3.1348e-03,  2.6826e-03,\n",
       "                       2.0330e-05,  4.4754e-03, -4.5698e-03,  4.0493e-03, -6.6892e-03,\n",
       "                       4.1654e-03,  1.5132e-03,  9.1833e-03,  4.4446e-04,  7.2941e-03,\n",
       "                      -6.6175e-04,  1.5732e-05,  3.7720e-03, -2.7887e-03, -4.0019e-03,\n",
       "                      -5.8058e-03, -4.4452e-04, -2.8659e-03,  1.4258e-03, -1.2516e-03,\n",
       "                      -7.5104e-04, -6.2457e-03, -4.1114e-03,  2.1126e-03, -2.9629e-03,\n",
       "                      -5.3606e-03, -2.0513e-04,  1.1623e-04, -6.4953e-04, -3.3752e-03,\n",
       "                      -4.9571e-03,  5.1856e-03,  5.8287e-03, -2.6902e-03,  9.7161e-04,\n",
       "                      -6.7737e-03, -2.2850e-03,  1.7719e-03,  5.5104e-03, -5.7575e-03,\n",
       "                      -1.3947e-03,  4.3521e-03,  1.9637e-03,  5.0257e-03, -1.3077e-03,\n",
       "                      -6.7352e-03,  1.4421e-03,  3.7951e-03, -5.0923e-04, -5.1550e-03,\n",
       "                      -3.4696e-03,  5.1097e-03, -6.0448e-03, -1.8674e-03,  1.0822e-03,\n",
       "                      -2.0490e-03, -5.6122e-03, -7.1356e-04, -2.3745e-03,  3.6045e-03,\n",
       "                       2.5140e-05, -2.0327e-03,  1.7925e-03,  4.2028e-03,  4.9921e-03,\n",
       "                      -5.0989e-03, -5.2130e-03, -4.9273e-03, -2.2024e-04, -2.1724e-03,\n",
       "                      -5.4026e-03,  3.5781e-03,  7.5474e-03, -6.2512e-04, -6.5458e-03,\n",
       "                       7.2744e-03,  3.9681e-03, -4.4722e-04, -4.3412e-03,  4.9993e-03,\n",
       "                       4.7214e-03,  1.2647e-03, -7.0071e-04,  3.2645e-03, -2.4041e-03,\n",
       "                      -4.8675e-03, -7.1802e-03, -6.3748e-03, -3.4070e-03,  6.5345e-03,\n",
       "                      -3.9388e-03, -5.2970e-03, -3.4729e-03, -5.7939e-03,  4.9803e-03,\n",
       "                       7.5920e-03, -1.9479e-03, -3.7204e-05, -1.8134e-03, -3.2883e-03,\n",
       "                      -5.6552e-03, -1.2239e-03, -5.8533e-04, -6.2514e-04, -5.7808e-03,\n",
       "                       6.8046e-03, -6.1452e-03,  1.1365e-03, -7.0855e-04, -7.0759e-03,\n",
       "                      -5.5214e-03, -6.2512e-05, -2.1129e-03,  5.1004e-03,  2.5781e-03,\n",
       "                      -3.3267e-03, -7.0782e-04,  6.5684e-03,  2.8200e-03, -7.2140e-03,\n",
       "                       1.0642e-02,  4.8220e-03,  2.1323e-03,  3.2266e-03, -1.1901e-03,\n",
       "                       2.3911e-03, -4.1122e-03, -8.8171e-05, -4.0766e-03, -3.7890e-03,\n",
       "                       1.6432e-03, -6.8421e-03,  5.9845e-04,  6.0650e-03,  6.8065e-03,\n",
       "                       2.8236e-03,  3.1607e-04,  5.0074e-03,  3.7239e-03, -4.9397e-03,\n",
       "                      -9.9225e-04,  6.7201e-03, -5.5443e-03,  3.9343e-03, -6.2101e-03,\n",
       "                       1.3094e-03,  5.9454e-03,  3.0231e-03, -1.8126e-03,  2.7451e-03,\n",
       "                       4.5546e-03,  5.4395e-03, -1.5220e-03,  1.6203e-03,  1.1445e-04,\n",
       "                      -3.5217e-03, -1.7440e-03, -3.4273e-03,  4.8302e-04,  3.9877e-04,\n",
       "                       5.8908e-03, -2.8195e-03,  6.8105e-03,  1.1136e-03,  3.4322e-03,\n",
       "                      -4.0299e-03], device='cuda:0')),\n",
       "             ('decoder.layers.0.norm2.weight',\n",
       "              tensor([0.9798, 0.9858, 0.9812, 0.9909, 0.9857, 0.9881, 0.9835, 0.9733, 0.9819,\n",
       "                      0.9828, 0.9847, 0.9794, 0.9858, 0.9863, 0.9917, 0.9917, 1.0022, 0.9853,\n",
       "                      0.9866, 0.9923, 0.9886, 0.9862, 0.9776, 0.9850, 0.9917, 0.9903, 0.9786,\n",
       "                      0.9877, 0.9950, 0.9953, 0.9845, 1.0069, 0.9851, 1.0047, 1.0003, 0.9999,\n",
       "                      0.9951, 0.9955, 0.9901, 0.9850, 0.9927, 0.9889, 0.9989, 0.9853, 0.9951,\n",
       "                      0.9889, 0.9856, 1.0004, 1.0001, 0.9945, 0.9981, 0.9919, 0.9984, 0.9920,\n",
       "                      0.9938, 0.9939, 0.9964, 0.9990, 0.9944, 1.0036, 1.0036, 0.9836, 0.9950,\n",
       "                      0.9956, 0.9938, 1.0099, 0.9949, 0.9948, 1.0016, 0.9972, 0.9981, 0.9933,\n",
       "                      0.9932, 0.9964, 0.9943, 0.9984, 1.0110, 1.0070, 1.0004, 1.0010, 0.9978,\n",
       "                      0.9994, 0.9963, 1.0039, 0.9965, 1.0039, 1.0031, 1.0035, 1.0044, 0.9984,\n",
       "                      1.0062, 0.9974, 0.9952, 1.0019, 0.9845, 1.0117, 1.0031, 1.0041, 0.9944,\n",
       "                      1.0088, 1.0006, 0.9992, 0.9968, 1.0068, 1.0072, 1.0030, 1.0073, 1.0047,\n",
       "                      1.0008, 1.0104, 1.0075, 1.0005, 1.0094, 1.0062, 1.0192, 1.0091, 1.0072,\n",
       "                      0.9980, 1.0015, 1.0024, 1.0050, 1.0016, 1.0091, 1.0009, 0.9986, 0.9992,\n",
       "                      1.0030, 1.0035, 1.0098, 0.9933, 1.0042, 1.0012, 1.0071, 1.0091, 1.0089,\n",
       "                      1.0068, 1.0079, 1.0170, 1.0100, 1.0086, 1.0089, 1.0009, 1.0022, 1.0059,\n",
       "                      1.0002, 0.9987, 1.0156, 1.0015, 0.9957, 1.0013, 0.9967, 1.0095, 1.0130,\n",
       "                      1.0053, 0.9963, 1.0006, 1.0100, 1.0005, 1.0107, 1.0028, 1.0104, 1.0190,\n",
       "                      1.0106, 0.9942, 1.0068, 0.9944, 1.0083, 0.9950, 1.0091, 1.0012, 0.9985,\n",
       "                      1.0034, 1.0281, 1.0023, 1.0007, 0.9982, 1.0130, 0.9923, 1.0116, 1.0078,\n",
       "                      1.0078, 0.9976, 1.0030, 0.9960, 1.0063, 1.0092, 1.0074, 0.9999, 0.9976,\n",
       "                      0.9948, 1.0097, 1.0027, 1.0243, 0.9981, 1.0156, 0.9918, 1.0015, 0.9948,\n",
       "                      1.0097, 0.9926, 1.0024, 0.9998, 1.0095, 1.0100, 1.0031, 1.0048, 1.0149,\n",
       "                      1.0024, 1.0059, 1.0034, 1.0115, 1.0037, 0.9970, 0.9944, 1.0061, 1.0025,\n",
       "                      1.0036, 0.9891, 1.0001, 0.9948, 1.0088, 1.0012, 0.9933, 1.0068, 1.0124,\n",
       "                      1.0000, 1.0068, 0.9923, 1.0120, 1.0072, 1.0099, 1.0017, 1.0090, 1.0012,\n",
       "                      1.0110, 0.9985, 1.0026, 1.0001, 0.9942, 0.9962, 1.0120, 0.9985, 1.0137,\n",
       "                      0.9968, 1.0119, 0.9914, 1.0125, 0.9974, 1.0216, 0.9983, 0.9921, 1.0039,\n",
       "                      1.0258, 0.9939, 0.9980, 1.0007], device='cuda:0')),\n",
       "             ('decoder.layers.0.norm2.bias',\n",
       "              tensor([ 4.4966e-03, -3.6919e-03,  4.0051e-03,  2.1076e-03, -3.3374e-03,\n",
       "                      -3.5566e-05, -3.8269e-03,  3.1475e-03,  6.5641e-03,  4.7028e-03,\n",
       "                      -3.4467e-03,  2.7709e-03, -1.6090e-03, -1.1019e-03,  4.3182e-03,\n",
       "                      -1.8914e-03, -4.8777e-04, -1.8102e-03,  2.0009e-03, -2.6596e-04,\n",
       "                       2.9914e-03,  3.6996e-03,  3.6800e-03,  5.3619e-03,  4.3060e-03,\n",
       "                      -2.9451e-03,  6.5560e-03, -3.3846e-03, -2.9074e-03,  2.5524e-03,\n",
       "                       1.5899e-03, -4.5331e-03,  6.2291e-03, -8.8869e-04,  1.2490e-04,\n",
       "                      -4.9853e-03,  2.5332e-03,  4.3716e-03, -3.8996e-03, -2.1339e-03,\n",
       "                      -4.4378e-03,  3.5407e-03, -1.8370e-03,  2.0509e-03,  3.1423e-03,\n",
       "                       4.6982e-03,  4.7771e-03,  4.1711e-03,  2.1013e-03,  4.7580e-03,\n",
       "                       2.3895e-03, -4.1235e-03, -3.5157e-03,  4.1112e-03, -1.6591e-03,\n",
       "                       3.4016e-03, -3.7071e-03, -4.1047e-03,  1.5958e-03, -6.2007e-04,\n",
       "                      -1.1460e-03,  4.9704e-03, -1.0504e-04, -5.7235e-03,  2.6341e-03,\n",
       "                      -3.6681e-03, -3.4072e-03, -3.0968e-03,  4.1190e-03,  5.3585e-03,\n",
       "                       4.1218e-03,  5.6608e-03, -3.2842e-03, -3.7533e-03,  1.6331e-03,\n",
       "                       2.1451e-03, -3.3022e-03,  1.8662e-03,  3.3750e-03, -1.3371e-03,\n",
       "                       1.6234e-03, -2.2242e-03, -1.2783e-03,  3.1217e-03, -4.1450e-03,\n",
       "                       2.1567e-03, -4.7312e-03,  5.5594e-03, -4.3468e-03,  1.9434e-03,\n",
       "                       7.2379e-04,  4.0497e-03, -4.5280e-03,  4.9126e-03, -6.8084e-03,\n",
       "                       3.8137e-03,  2.0963e-03,  8.6464e-03,  2.9741e-04,  6.5735e-03,\n",
       "                      -4.7701e-04, -9.7905e-04,  2.0225e-03, -2.2014e-03, -4.0199e-03,\n",
       "                      -5.3977e-03, -8.7925e-04, -3.3184e-03,  2.5020e-03, -2.5505e-03,\n",
       "                      -3.7779e-04, -6.2210e-03, -5.1902e-03,  2.0809e-03, -2.2882e-03,\n",
       "                      -6.7828e-03,  1.5999e-05, -1.4822e-03, -1.0746e-03, -4.1491e-03,\n",
       "                      -3.9992e-03,  5.0195e-03,  5.5129e-03, -2.8514e-03,  1.9275e-03,\n",
       "                      -8.5432e-03, -2.0255e-03,  2.6080e-03,  4.6741e-03, -5.2341e-03,\n",
       "                      -1.1609e-03,  3.4813e-03,  2.5785e-03,  4.5419e-03, -2.9894e-03,\n",
       "                      -6.5082e-03,  2.0583e-03,  2.8356e-03, -6.5026e-04, -5.3905e-03,\n",
       "                      -3.6061e-03,  4.1082e-03, -5.8379e-03, -2.7930e-03,  2.3786e-04,\n",
       "                      -2.0168e-03, -5.3492e-03, -9.6857e-04, -3.0652e-05,  3.7781e-03,\n",
       "                       2.5908e-04, -2.1653e-03,  1.9724e-03,  2.7415e-03,  4.9568e-03,\n",
       "                      -4.9562e-03, -5.5469e-03, -5.0152e-03, -1.6452e-03, -1.3206e-03,\n",
       "                      -4.9997e-03,  3.3803e-03,  7.0367e-03, -9.5842e-04, -6.8213e-03,\n",
       "                       6.3025e-03,  4.1714e-03, -1.3026e-03, -3.9526e-03,  4.6060e-03,\n",
       "                       4.5791e-03,  1.6708e-03,  1.8648e-04,  3.1855e-03, -2.3087e-03,\n",
       "                      -4.7231e-03, -7.5959e-03, -6.5221e-03, -3.3136e-03,  6.0455e-03,\n",
       "                      -4.4340e-03, -5.3820e-03, -3.1461e-03, -5.5589e-03,  3.8806e-03,\n",
       "                       6.5951e-03, -1.7093e-03,  8.4692e-04, -2.0540e-03, -3.9056e-03,\n",
       "                      -5.5927e-03, -1.6816e-03, -3.5979e-04, -1.6731e-03, -4.9536e-03,\n",
       "                       5.7436e-03, -6.0537e-03, -2.6791e-04, -1.3303e-03, -6.8375e-03,\n",
       "                      -5.2592e-03, -2.3621e-04, -2.0285e-03,  4.1286e-03,  3.0567e-03,\n",
       "                      -1.7673e-03, -6.6003e-04,  6.0687e-03,  3.4030e-03, -6.5673e-03,\n",
       "                       1.0241e-02,  4.1939e-03,  2.7132e-03,  1.4520e-03, -3.8562e-04,\n",
       "                       2.5441e-03, -3.3917e-03, -2.4499e-04, -4.5632e-03, -3.4215e-03,\n",
       "                       2.8392e-03, -7.1618e-03,  1.0007e-03,  6.3041e-03,  6.4342e-03,\n",
       "                       2.7712e-03,  4.6211e-04,  5.6266e-03,  4.1492e-03, -5.1020e-03,\n",
       "                       2.5988e-04,  5.6876e-03, -4.8905e-03,  4.4512e-03, -5.0182e-03,\n",
       "                       1.4085e-03,  6.9152e-03,  3.3347e-03, -1.0444e-03,  3.0483e-03,\n",
       "                       5.6645e-03,  5.5218e-03, -2.0927e-03,  9.9520e-04,  5.0116e-04,\n",
       "                      -4.3354e-03, -8.5774e-04, -3.4964e-03,  9.3682e-04,  7.2738e-05,\n",
       "                       6.0844e-03, -3.6041e-03,  6.5735e-03,  1.4606e-03,  3.0179e-03,\n",
       "                      -3.6072e-03], device='cuda:0')),\n",
       "             ('decoder.layers.0.norm3.weight',\n",
       "              tensor([0.9863, 0.9961, 0.9861, 0.9973, 0.9888, 0.9963, 0.9903, 0.9809, 0.9829,\n",
       "                      0.9837, 0.9934, 0.9912, 0.9969, 0.9866, 1.0019, 0.9908, 1.0073, 1.0018,\n",
       "                      0.9905, 0.9894, 0.9936, 0.9911, 0.9935, 0.9934, 0.9844, 1.0065, 0.9936,\n",
       "                      0.9933, 0.9991, 1.0048, 0.9936, 0.9985, 0.9842, 1.0044, 0.9918, 0.9999,\n",
       "                      0.9914, 0.9946, 1.0023, 0.9929, 1.0015, 0.9913, 1.0027, 0.9923, 1.0005,\n",
       "                      0.9852, 0.9904, 1.0039, 1.0044, 1.0026, 0.9978, 0.9995, 1.0005, 0.9894,\n",
       "                      1.0016, 0.9878, 1.0025, 1.0054, 0.9902, 1.0007, 1.0059, 0.9951, 0.9843,\n",
       "                      1.0021, 1.0014, 1.0141, 0.9979, 1.0039, 0.9996, 0.9956, 0.9919, 0.9882,\n",
       "                      1.0000, 0.9988, 0.9974, 1.0027, 1.0172, 1.0135, 1.0049, 1.0058, 0.9987,\n",
       "                      1.0002, 0.9989, 1.0189, 0.9938, 0.9973, 0.9956, 1.0018, 0.9961, 1.0007,\n",
       "                      1.0027, 1.0026, 1.0045, 0.9998, 0.9959, 1.0105, 0.9995, 1.0017, 0.9910,\n",
       "                      1.0001, 0.9991, 0.9967, 0.9986, 1.0062, 1.0059, 1.0064, 1.0039, 1.0128,\n",
       "                      0.9986, 1.0106, 1.0019, 0.9964, 1.0045, 1.0089, 1.0050, 1.0031, 1.0027,\n",
       "                      1.0030, 1.0006, 1.0052, 1.0007, 1.0056, 1.0024, 0.9957, 0.9865, 0.9990,\n",
       "                      0.9911, 0.9993, 0.9981, 0.9993, 0.9905, 0.9977, 1.0106, 1.0029, 1.0127,\n",
       "                      1.0099, 0.9969, 1.0195, 0.9975, 1.0063, 1.0052, 1.0016, 1.0158, 0.9985,\n",
       "                      1.0112, 1.0023, 1.0072, 0.9963, 0.9943, 1.0025, 1.0155, 1.0149, 1.0158,\n",
       "                      1.0033, 1.0038, 0.9961, 1.0123, 0.9884, 1.0065, 0.9973, 1.0033, 1.0065,\n",
       "                      1.0018, 0.9921, 1.0055, 0.9988, 1.0032, 0.9952, 0.9970, 0.9987, 1.0000,\n",
       "                      1.0054, 1.0137, 1.0067, 1.0045, 1.0018, 1.0232, 0.9966, 1.0029, 0.9987,\n",
       "                      1.0068, 1.0092, 1.0055, 0.9879, 1.0101, 1.0024, 1.0024, 1.0056, 1.0123,\n",
       "                      1.0025, 1.0032, 0.9996, 1.0199, 0.9925, 1.0091, 0.9955, 1.0056, 1.0053,\n",
       "                      1.0023, 0.9981, 0.9962, 0.9994, 1.0099, 1.0049, 0.9983, 0.9949, 1.0217,\n",
       "                      1.0016, 0.9952, 0.9956, 0.9982, 1.0009, 1.0062, 0.9847, 1.0042, 1.0001,\n",
       "                      1.0082, 1.0033, 1.0145, 0.9916, 1.0043, 1.0039, 0.9919, 1.0030, 1.0114,\n",
       "                      0.9929, 1.0121, 0.9955, 0.9999, 1.0080, 1.0084, 1.0023, 1.0053, 1.0037,\n",
       "                      1.0114, 1.0006, 0.9990, 0.9928, 1.0013, 0.9904, 1.0084, 0.9960, 1.0122,\n",
       "                      0.9979, 1.0102, 0.9916, 0.9962, 0.9917, 1.0111, 0.9858, 0.9949, 0.9984,\n",
       "                      1.0184, 1.0026, 0.9926, 1.0029], device='cuda:0')),\n",
       "             ('decoder.layers.0.norm3.bias',\n",
       "              tensor([ 0.0031, -0.0084,  0.0052,  0.0009, -0.0039, -0.0003, -0.0056,  0.0089,\n",
       "                       0.0082,  0.0044, -0.0075,  0.0090,  0.0005, -0.0027,  0.0021, -0.0056,\n",
       "                      -0.0032, -0.0038,  0.0053, -0.0020,  0.0036,  0.0037,  0.0051,  0.0074,\n",
       "                       0.0058, -0.0026,  0.0044, -0.0032, -0.0039,  0.0006,  0.0017, -0.0014,\n",
       "                       0.0057, -0.0020, -0.0010, -0.0035,  0.0043,  0.0021, -0.0026, -0.0026,\n",
       "                      -0.0037,  0.0052, -0.0033,  0.0029,  0.0040,  0.0064,  0.0053,  0.0035,\n",
       "                       0.0041,  0.0043,  0.0038, -0.0013, -0.0062,  0.0043, -0.0031,  0.0045,\n",
       "                      -0.0042, -0.0019,  0.0060, -0.0040, -0.0024,  0.0059,  0.0067, -0.0058,\n",
       "                       0.0071, -0.0031, -0.0007, -0.0058,  0.0045,  0.0052,  0.0043,  0.0077,\n",
       "                      -0.0041, -0.0031,  0.0048,  0.0045, -0.0040,  0.0061,  0.0044, -0.0090,\n",
       "                       0.0060, -0.0031, -0.0081,  0.0056, -0.0050,  0.0058, -0.0052,  0.0047,\n",
       "                      -0.0050,  0.0041, -0.0018,  0.0042, -0.0040,  0.0069, -0.0038,  0.0049,\n",
       "                       0.0043,  0.0055, -0.0052,  0.0046, -0.0032, -0.0027,  0.0055,  0.0012,\n",
       "                      -0.0029, -0.0041, -0.0041, -0.0040,  0.0048, -0.0059, -0.0007, -0.0041,\n",
       "                      -0.0063,  0.0023, -0.0090, -0.0062,  0.0052, -0.0058,  0.0023, -0.0083,\n",
       "                      -0.0028,  0.0010,  0.0036, -0.0036,  0.0081, -0.0035, -0.0061,  0.0026,\n",
       "                       0.0019, -0.0043, -0.0047,  0.0039,  0.0029,  0.0050, -0.0071, -0.0019,\n",
       "                       0.0055,  0.0001, -0.0060, -0.0026, -0.0038,  0.0016, -0.0038, -0.0069,\n",
       "                      -0.0041, -0.0041, -0.0037,  0.0019, -0.0020,  0.0027,  0.0029, -0.0035,\n",
       "                       0.0055,  0.0024,  0.0034, -0.0035, -0.0064, -0.0060, -0.0031, -0.0004,\n",
       "                      -0.0038,  0.0036,  0.0065, -0.0001, -0.0069,  0.0060,  0.0024, -0.0040,\n",
       "                      -0.0050,  0.0042,  0.0050,  0.0034,  0.0082,  0.0030,  0.0064, -0.0042,\n",
       "                      -0.0061, -0.0075, -0.0044,  0.0040, -0.0026, -0.0045, -0.0048, -0.0042,\n",
       "                       0.0021,  0.0080, -0.0038,  0.0066, -0.0057, -0.0043, -0.0042, -0.0055,\n",
       "                       0.0032, -0.0071, -0.0037,  0.0039, -0.0047, -0.0074, -0.0047, -0.0052,\n",
       "                      -0.0034,  0.0005, -0.0014,  0.0022,  0.0053, -0.0069, -0.0029,  0.0031,\n",
       "                       0.0036, -0.0050,  0.0068,  0.0033,  0.0036, -0.0036, -0.0016,  0.0043,\n",
       "                      -0.0002, -0.0070, -0.0043, -0.0049,  0.0068, -0.0071, -0.0070,  0.0062,\n",
       "                       0.0049,  0.0048,  0.0006,  0.0056,  0.0070, -0.0069,  0.0068,  0.0033,\n",
       "                      -0.0043,  0.0039, -0.0030,  0.0039,  0.0035,  0.0047,  0.0027,  0.0028,\n",
       "                       0.0056,  0.0067, -0.0025,  0.0009, -0.0045, -0.0037, -0.0026, -0.0040,\n",
       "                       0.0072, -0.0059,  0.0064, -0.0037,  0.0065,  0.0032,  0.0037, -0.0055],\n",
       "                     device='cuda:0')),\n",
       "             ('decoder.layers.1.self_attn.in_proj_weight',\n",
       "              tensor([[ 0.0619, -0.0454, -0.0461,  ..., -0.0353, -0.0568,  0.0213],\n",
       "                      [ 0.0708,  0.0661,  0.0610,  ...,  0.0484,  0.0026,  0.0713],\n",
       "                      [-0.0549,  0.0067,  0.0133,  ...,  0.0606,  0.0377, -0.0454],\n",
       "                      ...,\n",
       "                      [-0.0118,  0.0655,  0.0446,  ...,  0.0456,  0.0092,  0.0450],\n",
       "                      [-0.0306,  0.0029, -0.0672,  ...,  0.0376, -0.0532,  0.0029],\n",
       "                      [-0.0034,  0.0282, -0.0242,  ...,  0.0692,  0.0632,  0.0573]],\n",
       "                     device='cuda:0')),\n",
       "             ('decoder.layers.1.self_attn.in_proj_bias',\n",
       "              tensor([-7.9905e-03, -6.0540e-03, -1.3461e-03,  3.5196e-03, -4.2169e-03,\n",
       "                      -3.4413e-04, -2.3194e-03,  3.5876e-03,  4.4256e-03, -4.5041e-03,\n",
       "                      -5.9982e-03, -8.8954e-04, -4.7005e-03, -9.8998e-04,  3.2785e-03,\n",
       "                      -4.5310e-03, -7.9017e-03,  4.6765e-04,  3.9687e-03,  3.7417e-03,\n",
       "                      -4.3406e-03,  5.6816e-03,  1.2708e-03,  7.2661e-03, -3.9205e-03,\n",
       "                       7.1286e-03,  2.6174e-03,  3.9822e-03,  9.9571e-04, -2.6202e-03,\n",
       "                      -3.7621e-03, -2.6286e-03, -1.7588e-04, -1.2505e-03,  2.2714e-03,\n",
       "                      -5.2058e-03, -2.6701e-03, -4.7683e-04, -1.6687e-05, -3.2637e-04,\n",
       "                      -4.7766e-05, -5.5875e-03, -2.3022e-03, -2.5678e-03, -6.4324e-04,\n",
       "                      -1.5952e-03,  8.6284e-03,  3.5006e-03,  3.7477e-03, -3.0780e-03,\n",
       "                       5.4830e-04, -2.3909e-03, -4.2802e-03,  1.1049e-03,  4.0801e-03,\n",
       "                      -1.2013e-03, -1.7046e-03,  5.6199e-03,  6.2191e-03, -3.6155e-03,\n",
       "                       2.2996e-03, -2.8991e-03,  7.5651e-04, -2.2235e-03,  3.0239e-03,\n",
       "                      -6.9848e-03,  3.0962e-03,  3.9933e-03, -4.1732e-03,  1.4135e-03,\n",
       "                      -5.9279e-04, -5.5150e-03, -2.5003e-03, -2.7030e-03,  1.4496e-03,\n",
       "                       2.5254e-03,  7.5512e-04,  3.6062e-04,  4.7882e-03, -2.6218e-03,\n",
       "                       2.7480e-03,  2.4897e-03, -1.4980e-03, -5.3950e-03,  2.8761e-03,\n",
       "                       1.9615e-03, -6.1035e-03, -3.3135e-03,  3.4310e-03, -1.7299e-03,\n",
       "                      -7.3668e-04,  1.2452e-03,  2.6015e-04,  3.9562e-03, -3.5117e-03,\n",
       "                       7.1867e-03, -2.9386e-03, -4.7674e-03, -3.1052e-03,  2.7662e-03,\n",
       "                      -1.3188e-03,  2.0156e-03,  1.6900e-04,  5.6327e-03, -2.7318e-03,\n",
       "                      -1.9410e-03,  3.8787e-03, -2.7885e-03, -3.0831e-03, -9.2012e-04,\n",
       "                      -4.2853e-03,  1.0620e-03,  1.4356e-03, -5.7333e-04,  2.6401e-03,\n",
       "                       4.3985e-03, -4.2263e-03,  2.3276e-03,  4.8802e-03, -2.8033e-03,\n",
       "                       3.5805e-03, -5.3746e-03,  1.1832e-03,  1.7177e-03,  3.1838e-03,\n",
       "                       2.0723e-03, -1.2122e-03, -8.4548e-05, -8.6801e-04, -3.7848e-03,\n",
       "                       1.0602e-03,  6.3344e-03, -2.6290e-04,  4.6836e-04,  6.0698e-03,\n",
       "                      -3.0215e-03,  1.0936e-04,  8.5431e-03,  6.9368e-03,  1.1714e-03,\n",
       "                      -3.6207e-03,  1.3085e-03,  5.2358e-03,  4.9613e-03,  4.2755e-03,\n",
       "                      -8.1785e-04,  1.8445e-03,  3.5754e-03, -2.3781e-03,  6.6760e-06,\n",
       "                       4.7024e-03,  5.9608e-03, -2.3331e-03, -2.2307e-03, -5.2901e-03,\n",
       "                       2.9669e-03, -4.7429e-03, -1.5630e-03,  6.9538e-03, -8.3345e-03,\n",
       "                      -1.3846e-05,  7.5559e-03,  3.8341e-03,  2.8619e-03, -2.7079e-03,\n",
       "                      -5.0986e-03, -5.6249e-03, -4.8709e-04,  3.8869e-03, -3.9945e-03,\n",
       "                      -3.9757e-03,  2.7453e-03,  4.7488e-04,  1.4242e-03,  3.2089e-03,\n",
       "                      -5.3025e-03,  7.3340e-03,  8.6211e-04,  8.7809e-03,  2.6006e-03,\n",
       "                      -1.1834e-03,  1.7810e-03, -8.4426e-03, -3.2705e-03,  3.8375e-03,\n",
       "                      -2.5355e-03, -3.1982e-03, -1.6867e-03,  3.3353e-03, -1.8391e-03,\n",
       "                       3.6100e-03, -3.2571e-03,  2.8198e-03,  3.1305e-03, -5.5438e-03,\n",
       "                      -3.5964e-03, -2.6179e-04, -6.8407e-03,  4.3850e-03,  5.0428e-03,\n",
       "                      -4.4669e-04,  6.1731e-03, -4.7114e-03, -1.9804e-03, -1.9688e-03,\n",
       "                       4.7693e-03, -3.9357e-03, -2.9537e-03,  1.0709e-03,  3.1974e-03,\n",
       "                       2.1648e-03,  1.0866e-02,  1.7526e-03, -3.8128e-03, -2.1119e-04,\n",
       "                       6.6092e-03,  1.7693e-03,  6.8540e-04,  2.8140e-03, -4.7071e-03,\n",
       "                      -5.1627e-03, -2.7169e-03,  4.5195e-03, -2.0966e-03, -6.8491e-04,\n",
       "                       5.3109e-03,  2.5055e-03, -5.0439e-03, -2.5412e-04,  4.9750e-03,\n",
       "                      -9.2973e-04, -9.4698e-03,  6.3774e-03, -4.3779e-03,  2.7058e-03,\n",
       "                      -1.2804e-04, -1.8453e-04,  2.4269e-03,  7.8511e-03,  4.5560e-03,\n",
       "                       6.6222e-03, -5.6827e-04, -8.2438e-03,  6.2311e-03, -5.8568e-05,\n",
       "                      -8.0700e-04, -1.3831e-03,  2.5222e-03, -5.5140e-03,  6.0670e-03,\n",
       "                       5.6599e-03, -2.4291e-03,  2.4985e-03, -5.5140e-03, -5.2917e-03,\n",
       "                       2.2689e-03,  1.4677e-06, -1.0316e-06,  1.9558e-07,  1.0250e-06,\n",
       "                      -1.0263e-06, -8.5763e-07,  6.4688e-07, -2.4402e-07, -7.0846e-07,\n",
       "                       1.7298e-07, -2.8558e-07, -9.1055e-07,  1.2771e-06,  4.8476e-07,\n",
       "                       1.1649e-07,  2.8917e-07, -3.8664e-07,  1.0850e-07, -1.2001e-07,\n",
       "                       5.2357e-08,  1.1824e-06,  3.1679e-07,  4.4216e-07,  9.5032e-08,\n",
       "                      -6.4300e-07, -6.4875e-07,  7.7757e-07,  6.6427e-07,  1.0277e-07,\n",
       "                      -3.4869e-07,  5.2712e-07, -1.4402e-06,  2.3700e-07,  1.3355e-06,\n",
       "                      -2.9684e-07,  8.0499e-07, -7.2711e-08,  1.8664e-07,  8.1749e-07,\n",
       "                       4.4083e-07,  3.7086e-07,  7.2684e-07,  1.8376e-06,  1.4242e-06,\n",
       "                       1.0887e-06,  1.5008e-06,  3.9497e-07, -3.3340e-07, -1.3049e-06,\n",
       "                       3.2609e-07, -2.2590e-06,  7.7365e-07,  4.4187e-07,  2.0624e-06,\n",
       "                      -2.5866e-06, -1.6154e-06, -5.8658e-07,  6.5187e-07, -5.2415e-07,\n",
       "                       1.7140e-07, -2.1262e-07, -7.4117e-07, -7.3424e-07,  6.1371e-07,\n",
       "                       2.6558e-06, -5.2423e-07, -7.8829e-07, -1.0001e-06,  1.0628e-07,\n",
       "                       7.5297e-07, -1.9838e-07,  2.5941e-07,  1.5238e-06, -4.3109e-07,\n",
       "                       1.0259e-06, -3.1621e-07, -1.1814e-07, -2.1947e-07, -3.3661e-07,\n",
       "                       3.9658e-07, -1.6484e-07,  7.9511e-07, -1.8757e-07, -1.9834e-06,\n",
       "                      -2.1615e-06, -1.4270e-08, -3.4802e-07, -6.4613e-07, -7.6858e-07,\n",
       "                      -5.0611e-07,  3.4843e-07, -3.9787e-07,  8.0910e-07, -1.8610e-06,\n",
       "                       4.4031e-07,  2.0416e-07, -2.9490e-06, -2.2071e-08,  2.3819e-07,\n",
       "                      -2.6984e-07, -2.6298e-06,  3.5346e-07,  1.2809e-07,  1.8423e-06,\n",
       "                       4.2269e-07,  4.4755e-07,  4.2068e-07, -1.8219e-07,  9.2514e-09,\n",
       "                       1.0377e-06,  1.3163e-07, -8.8152e-08,  6.3893e-07,  3.2894e-08,\n",
       "                       1.3889e-06, -5.5370e-08, -6.1915e-07, -5.1428e-08, -1.4677e-06,\n",
       "                       6.6464e-08,  3.1769e-07, -3.3545e-08, -2.1637e-07,  5.5061e-08,\n",
       "                      -1.0229e-06, -1.6515e-07, -7.7943e-07, -4.2332e-07,  2.0235e-04,\n",
       "                      -2.0900e-04,  1.7716e-04,  1.2601e-04,  1.0022e-04,  7.9744e-05,\n",
       "                       2.8430e-04,  1.0222e-04, -1.9601e-04,  2.3984e-04,  2.4526e-04,\n",
       "                       2.6333e-04,  2.6221e-04, -5.6615e-05,  2.0595e-04,  2.4850e-04,\n",
       "                       3.3024e-04,  1.1963e-04,  3.4272e-04,  2.1155e-04,  1.0987e-04,\n",
       "                      -4.2873e-04,  2.2672e-04, -2.0324e-04,  3.1359e-04, -1.4243e-04,\n",
       "                      -5.3266e-04,  1.3233e-04, -2.3509e-04, -1.0615e-04,  2.6032e-04,\n",
       "                      -1.6253e-04,  1.0888e-04,  1.8302e-04,  1.5091e-04,  1.7366e-04,\n",
       "                      -2.1562e-04, -1.3722e-04, -1.4543e-04, -1.7722e-04,  4.1299e-04,\n",
       "                      -2.5871e-04, -1.1477e-04,  2.7297e-04,  1.5462e-04, -2.1503e-04,\n",
       "                       2.0081e-04, -1.5681e-04,  2.0696e-04,  2.5414e-04,  1.2108e-04,\n",
       "                       1.5862e-04, -1.3886e-04,  1.8924e-04, -2.3520e-04, -3.1666e-04,\n",
       "                       1.3293e-04, -2.8445e-04, -1.2213e-04, -3.1303e-05,  2.1525e-04,\n",
       "                       2.0707e-04,  1.3463e-04, -1.1984e-04,  3.4381e-07,  1.5755e-07,\n",
       "                      -8.4851e-07,  5.9551e-07,  7.5201e-07,  1.2728e-06, -6.8412e-07,\n",
       "                       2.3081e-07,  3.3587e-07, -7.9649e-07,  7.4063e-07, -4.7160e-07,\n",
       "                      -2.6145e-07, -6.1278e-07,  1.0212e-08, -1.0426e-06, -2.7267e-07,\n",
       "                      -1.0579e-07, -2.8474e-07, -1.0946e-06, -1.2376e-06, -1.8766e-06,\n",
       "                      -4.5995e-07,  4.1574e-07, -6.7048e-07,  1.9594e-07, -1.0279e-06,\n",
       "                       5.5839e-07,  1.4570e-06, -6.4548e-07,  1.4981e-06,  1.4938e-06,\n",
       "                      -1.8783e-07, -3.5624e-07,  2.1360e-06, -2.7954e-07,  7.8746e-07,\n",
       "                       2.2884e-07,  7.7925e-07, -2.1113e-07, -2.0833e-07, -5.5530e-07,\n",
       "                      -1.1158e-06,  1.2153e-06, -5.5049e-07,  2.5142e-06,  1.0447e-08,\n",
       "                       8.2423e-07, -7.2823e-07,  9.9151e-07,  1.6104e-06, -1.9145e-06,\n",
       "                      -4.2666e-07,  2.2162e-06, -7.5270e-07, -2.9308e-07, -4.8401e-07,\n",
       "                       7.8614e-07,  7.5651e-08,  1.0656e-06, -6.3503e-07, -4.3664e-07,\n",
       "                       1.4302e-06,  2.4157e-07,  5.0374e-04, -2.2777e-03, -8.5333e-04,\n",
       "                      -7.7297e-04, -1.9875e-03, -4.8363e-04, -1.5995e-03, -1.3059e-03,\n",
       "                       1.4145e-03,  1.9491e-03,  1.2664e-03, -6.9495e-04,  5.3479e-04,\n",
       "                      -2.9034e-04, -2.9737e-04, -1.1770e-03, -3.0283e-03,  3.0303e-03,\n",
       "                       1.9282e-03, -5.6716e-04, -9.7015e-04,  1.8985e-03,  9.0600e-04,\n",
       "                      -2.9790e-04, -1.9280e-03,  1.7725e-03,  7.2076e-04, -5.3127e-04,\n",
       "                      -2.6638e-03, -2.9621e-04,  1.7783e-04, -4.0887e-03, -1.0361e-03,\n",
       "                       2.6501e-03, -1.9120e-03, -1.5305e-03, -9.0208e-05, -2.1155e-03,\n",
       "                       2.3243e-03,  3.8204e-04,  2.6719e-03,  1.3125e-03, -3.1061e-03,\n",
       "                       3.6483e-04,  1.1794e-03,  2.8365e-04, -2.5398e-03,  1.1763e-03,\n",
       "                      -2.0424e-04,  1.0200e-03, -3.2583e-04,  4.6950e-04, -7.9452e-04,\n",
       "                      -1.0877e-03, -1.3368e-03,  8.9231e-04, -3.1941e-03, -7.2835e-04,\n",
       "                       8.1402e-04, -2.1948e-03, -3.7698e-03,  1.1914e-03,  1.0949e-03,\n",
       "                      -5.4983e-04,  6.8443e-04, -1.4524e-03,  9.2115e-04,  1.0599e-03,\n",
       "                       8.1463e-04, -1.2302e-03, -5.4375e-04,  2.7952e-04,  8.1791e-04,\n",
       "                      -6.3539e-04,  1.7007e-04, -1.7588e-03,  1.7228e-03, -9.9315e-04,\n",
       "                       1.3903e-03,  1.5799e-03,  1.0614e-03,  4.7912e-04,  1.5333e-03,\n",
       "                       1.7540e-03, -1.4842e-03, -1.0526e-03, -2.6778e-03, -3.2839e-03,\n",
       "                      -3.4615e-03, -1.1904e-03,  1.8960e-03, -2.3780e-03, -1.9437e-03,\n",
       "                       1.4862e-03,  1.2780e-03, -1.7623e-03,  1.1010e-03,  2.4284e-03,\n",
       "                       9.6447e-04,  2.0557e-04,  2.7795e-03,  1.0918e-03, -1.8161e-03,\n",
       "                       7.2875e-04,  1.3470e-03, -9.4960e-04,  1.1386e-03, -8.1286e-04,\n",
       "                       8.2842e-05,  1.4533e-03, -1.0123e-03,  2.5406e-03, -2.7088e-03,\n",
       "                      -1.5288e-03,  2.0685e-03,  5.7597e-04, -4.6669e-04, -1.6478e-03,\n",
       "                       1.6353e-03,  1.5978e-04, -1.1436e-04, -1.7304e-03,  1.0069e-03,\n",
       "                      -2.3665e-03,  2.5155e-03, -1.2204e-03, -1.1741e-03, -5.5297e-04,\n",
       "                       4.4604e-04,  4.6613e-04,  9.0737e-04, -6.0327e-04,  2.2905e-03,\n",
       "                      -1.1551e-03, -1.4198e-03,  2.1781e-04,  1.6062e-03, -3.4625e-03,\n",
       "                      -8.7697e-04, -2.2143e-03, -2.1268e-03, -4.5237e-04,  2.4149e-03,\n",
       "                      -2.4687e-03,  1.1072e-03,  1.1336e-03,  3.1043e-03, -3.1791e-03,\n",
       "                       6.4562e-04,  2.2161e-03,  8.2064e-05, -1.8469e-03, -1.9914e-03,\n",
       "                      -1.3211e-03, -3.9697e-04, -1.4944e-03, -1.6212e-03, -2.3781e-03,\n",
       "                       8.6937e-04, -1.0026e-04,  1.0483e-03,  1.4575e-03, -2.9883e-03,\n",
       "                       1.6379e-03, -5.7643e-04, -1.1783e-03, -1.7251e-04,  1.7943e-03,\n",
       "                       1.7797e-04,  2.1483e-03,  7.9658e-04,  1.0481e-03,  1.0195e-04,\n",
       "                      -1.3137e-03, -2.4237e-03,  2.0657e-03,  4.3419e-04,  2.8054e-03,\n",
       "                       2.7014e-03,  5.5189e-04,  1.4166e-03,  1.2588e-03, -4.0774e-03,\n",
       "                      -1.8210e-03,  1.4969e-03,  9.8036e-04, -2.5546e-03, -1.7194e-03,\n",
       "                       3.0580e-04,  2.1905e-03, -1.0879e-03, -9.5054e-04, -2.4824e-03,\n",
       "                       9.7362e-05,  4.6544e-04,  1.1288e-03,  4.7047e-04, -1.6004e-03,\n",
       "                      -1.1985e-06, -1.8632e-03, -1.3562e-03, -8.2889e-04, -2.7409e-03,\n",
       "                       1.9589e-04, -1.1535e-03,  1.5242e-04,  1.7311e-03,  1.1353e-03,\n",
       "                       1.5378e-03, -1.6989e-03,  9.3274e-04,  8.6034e-04, -5.3678e-04,\n",
       "                      -9.3400e-04,  1.7300e-04,  1.8947e-03,  1.4411e-03, -1.0610e-03,\n",
       "                       1.6261e-03,  1.1889e-03, -2.2755e-03, -3.5292e-03, -1.7191e-04,\n",
       "                       8.8399e-04,  2.7925e-03, -3.7124e-03, -2.4608e-04,  9.1441e-04,\n",
       "                      -1.9657e-03, -9.2735e-04, -1.6738e-05,  2.5510e-03, -4.2754e-04,\n",
       "                      -4.0479e-04,  2.0415e-03, -5.7731e-04, -3.6931e-04,  2.8247e-03,\n",
       "                      -1.8075e-03, -2.0362e-03,  2.4365e-04, -6.9683e-04,  2.4269e-04,\n",
       "                       8.2891e-04, -2.0252e-03, -4.0369e-03,  1.7542e-03, -1.3048e-03,\n",
       "                      -1.9614e-03,  1.4837e-03,  1.8822e-03, -2.9192e-03,  1.7994e-04,\n",
       "                       9.2458e-04, -6.3426e-04,  1.6348e-03], device='cuda:0')),\n",
       "             ('decoder.layers.1.self_attn.out_proj.weight',\n",
       "              tensor([[ 0.0190, -0.0016, -0.0384,  ...,  0.0039,  0.0274,  0.0612],\n",
       "                      [-0.0460, -0.0181, -0.0225,  ..., -0.0515, -0.0412, -0.0362],\n",
       "                      [ 0.0593, -0.0084, -0.0077,  ...,  0.0087,  0.0363,  0.0235],\n",
       "                      ...,\n",
       "                      [ 0.0385, -0.0594, -0.0176,  ..., -0.0572, -0.0598, -0.0451],\n",
       "                      [ 0.0435,  0.0588,  0.0622,  ...,  0.0576, -0.0323,  0.0246],\n",
       "                      [ 0.0066, -0.0100,  0.0633,  ...,  0.0203,  0.0013, -0.0035]],\n",
       "                     device='cuda:0')),\n",
       "             ('decoder.layers.1.self_attn.out_proj.bias',\n",
       "              tensor([ 7.7744e-04, -2.4463e-03,  3.1553e-03, -9.5688e-05, -1.9500e-03,\n",
       "                      -6.9010e-05, -1.8416e-03,  3.4833e-03,  2.2602e-03,  7.5944e-04,\n",
       "                      -5.0707e-03,  7.8543e-04,  2.7845e-04, -1.8078e-04,  1.7787e-03,\n",
       "                      -2.7060e-03,  1.3942e-03, -2.9268e-03,  2.6885e-03, -2.1047e-03,\n",
       "                       2.3080e-03,  2.1347e-04,  5.1821e-04,  5.7816e-03,  1.8545e-03,\n",
       "                      -6.5825e-04,  1.2564e-03,  6.7601e-04, -4.7789e-05,  1.5201e-03,\n",
       "                       1.4989e-03,  1.2649e-03,  2.0101e-03, -7.6859e-04, -1.4621e-04,\n",
       "                      -2.2452e-03, -2.7471e-05,  1.1607e-03, -1.2253e-03, -2.8494e-04,\n",
       "                      -1.7704e-03,  1.3215e-03, -6.9332e-04, -6.9647e-04,  7.6466e-04,\n",
       "                       1.4813e-03,  2.6985e-03,  1.4822e-03,  7.2412e-04, -5.6935e-04,\n",
       "                       8.7893e-04, -6.8216e-04, -2.5197e-03,  3.1445e-03, -1.8613e-03,\n",
       "                       2.5624e-03, -1.2210e-03, -1.0264e-03,  1.4799e-03, -2.0364e-03,\n",
       "                      -4.1953e-04, -2.1329e-04,  3.3848e-03, -1.7216e-03,  2.5555e-03,\n",
       "                       3.8278e-06, -1.9984e-03, -1.5320e-03,  1.9407e-03,  5.7404e-04,\n",
       "                      -8.6366e-04,  2.2909e-03, -1.3295e-03, -8.7625e-04,  6.7482e-04,\n",
       "                       1.2907e-03, -2.4872e-03,  2.2364e-03,  3.0267e-03, -2.3120e-03,\n",
       "                       1.8078e-03, -3.0575e-03, -1.0725e-03,  2.3960e-03, -9.5054e-04,\n",
       "                       2.4131e-03, -1.0419e-03,  1.8106e-03, -2.7142e-03,  1.7683e-03,\n",
       "                      -1.9642e-03,  3.7181e-04, -1.2254e-03,  1.2091e-03, -2.6092e-04,\n",
       "                       2.8936e-03,  1.0716e-03,  2.5328e-03, -1.6405e-03,  2.1057e-03,\n",
       "                      -1.8207e-04, -6.5990e-04,  2.3749e-03,  4.6524e-04, -1.5373e-03,\n",
       "                      -6.3899e-04, -2.1028e-03, -8.6081e-04,  2.4449e-03, -2.1001e-03,\n",
       "                      -4.8908e-04, -3.7242e-03, -4.7950e-03,  2.3667e-03, -6.5466e-03,\n",
       "                      -2.5533e-03,  1.5222e-03, -1.9187e-03, -5.3318e-05, -1.4694e-03,\n",
       "                      -1.2347e-03,  3.2952e-04,  2.2129e-03, -1.5372e-03,  4.7601e-03,\n",
       "                       1.1692e-03, -2.1305e-03,  8.8352e-04,  2.4660e-05, -2.4390e-03,\n",
       "                      -4.3953e-04,  1.2193e-03,  2.3256e-03,  2.3095e-03, -1.8345e-03,\n",
       "                      -6.9724e-04,  3.0282e-03, -2.6150e-04, -8.6464e-04, -2.6737e-04,\n",
       "                      -1.8123e-03,  1.4091e-03, -7.1703e-04,  5.2125e-05, -3.0011e-03,\n",
       "                      -1.4035e-03, -2.5310e-03,  1.8150e-03,  6.2652e-04, -1.0521e-03,\n",
       "                       2.6073e-04, -1.7147e-03,  2.1403e-03, -5.6401e-04,  2.7730e-03,\n",
       "                      -1.8100e-03, -7.3392e-06, -1.3667e-03,  6.0597e-04,  6.3429e-04,\n",
       "                       7.9083e-05, -4.2915e-04,  1.6932e-03,  2.7071e-04, -1.6591e-03,\n",
       "                       1.8121e-03,  5.9777e-04, -2.7119e-03, -1.1107e-03,  1.3731e-04,\n",
       "                       2.4608e-03,  1.4235e-03,  9.1291e-04,  1.5137e-03,  2.3749e-03,\n",
       "                      -1.3057e-03, -1.4359e-03, -4.1208e-03, -7.8826e-04,  1.9878e-03,\n",
       "                      -6.1761e-04, -1.4151e-03, -2.2086e-03, -3.6512e-03,  7.3925e-04,\n",
       "                       4.3013e-03, -7.3745e-04,  1.3630e-03, -8.9317e-04, -1.8451e-03,\n",
       "                      -2.3257e-03, -5.3833e-05,  2.4842e-03, -2.3785e-03, -1.7975e-03,\n",
       "                      -1.8923e-04, -1.2789e-03, -9.1629e-04, -1.4030e-03, -2.1189e-03,\n",
       "                       1.1779e-03, -7.3923e-04, -1.0870e-03,  1.6234e-03,  3.2242e-04,\n",
       "                      -1.8751e-05, -9.1774e-04,  1.6419e-03,  4.5276e-04, -1.2896e-03,\n",
       "                       4.6141e-04,  1.6925e-03,  2.2392e-03, -1.8519e-03,  1.4103e-03,\n",
       "                       2.1314e-03, -6.2150e-04, -1.6929e-03, -1.3767e-03, -1.5949e-03,\n",
       "                       3.3449e-03, -4.5201e-03,  1.5049e-03,  2.8036e-03,  2.0726e-03,\n",
       "                       1.7505e-03,  8.5079e-04,  3.7343e-03,  2.3489e-03, -1.4514e-03,\n",
       "                       1.0809e-03, -7.1772e-04, -1.2759e-03,  2.6411e-03, -8.9589e-04,\n",
       "                       2.0308e-03,  1.2566e-03,  3.9232e-05,  1.7550e-03,  3.0600e-03,\n",
       "                       3.3646e-03,  3.8929e-04,  1.4450e-03, -2.4159e-04, -4.4385e-03,\n",
       "                      -1.8083e-03, -8.0603e-04, -1.3120e-03,  2.4574e-03, -2.1923e-03,\n",
       "                       3.7825e-03, -2.2775e-03,  3.9641e-03,  1.0376e-03,  1.7225e-04,\n",
       "                      -1.8360e-03], device='cuda:0')),\n",
       "             ('decoder.layers.1.multihead_attn.in_proj_weight',\n",
       "              tensor([[-0.0014, -0.0410, -0.0081,  ...,  0.0544, -0.0233, -0.0343],\n",
       "                      [-0.0361,  0.0083, -0.0476,  ...,  0.0815, -0.0579, -0.0670],\n",
       "                      [-0.0129, -0.0045,  0.0495,  ...,  0.0280,  0.0213, -0.0399],\n",
       "                      ...,\n",
       "                      [-0.0613,  0.0133, -0.0743,  ...,  0.0644, -0.0606, -0.0165],\n",
       "                      [-0.0597,  0.0632,  0.0754,  ..., -0.0417, -0.0479,  0.0004],\n",
       "                      [-0.0066,  0.0293, -0.0659,  ..., -0.0061, -0.0510, -0.0421]],\n",
       "                     device='cuda:0')),\n",
       "             ('decoder.layers.1.multihead_attn.in_proj_bias',\n",
       "              tensor([ 6.0322e-03, -4.9029e-04,  2.2082e-04,  2.3306e-04, -1.0643e-04,\n",
       "                      -3.3944e-03, -1.4376e-03, -3.7671e-03,  3.1956e-03, -5.8231e-03,\n",
       "                      -1.8149e-03,  5.1927e-05,  2.8325e-03,  1.0407e-03, -1.0409e-02,\n",
       "                      -5.9065e-03, -2.1315e-04, -2.4775e-03, -4.4278e-03, -3.2997e-03,\n",
       "                      -1.0501e-03, -9.0482e-04, -1.7335e-03, -5.1540e-03,  6.4803e-03,\n",
       "                      -4.1179e-03,  4.5899e-03,  8.4121e-04,  3.4768e-03,  4.1943e-03,\n",
       "                      -9.4963e-03,  3.2619e-03, -6.7755e-03,  1.1178e-03, -2.8059e-03,\n",
       "                      -5.9040e-04, -4.3318e-03, -2.3133e-03, -6.8522e-04,  4.3968e-03,\n",
       "                      -1.3302e-03, -3.6226e-03, -1.0731e-03, -5.7615e-03, -6.2259e-03,\n",
       "                       7.8806e-04,  5.8009e-04, -7.3348e-04,  1.6828e-04,  4.8555e-04,\n",
       "                       5.1539e-03, -8.6832e-03, -3.6508e-03, -1.9280e-03, -1.8248e-03,\n",
       "                       6.5970e-04, -6.5146e-03, -2.4446e-03, -1.5496e-03,  7.2013e-03,\n",
       "                       1.7870e-03,  2.3547e-03,  6.0711e-03, -3.7316e-03, -7.4127e-04,\n",
       "                      -6.2689e-04, -1.5234e-03,  2.6799e-04, -7.7241e-03, -1.1709e-03,\n",
       "                      -6.5701e-03, -6.9000e-03, -3.5630e-03, -1.3640e-03, -3.4231e-03,\n",
       "                       5.0141e-03, -1.0216e-03,  5.1470e-03, -7.3181e-03,  2.3421e-04,\n",
       "                       4.1179e-03, -3.0253e-03,  4.2172e-03, -2.0700e-03,  4.4864e-03,\n",
       "                       5.4689e-03, -3.9568e-03,  1.3070e-03, -1.0620e-02, -2.0527e-03,\n",
       "                       8.8651e-03,  4.2380e-04, -1.6555e-03,  2.1905e-04,  5.5473e-03,\n",
       "                      -7.1323e-03, -3.3865e-03, -4.6538e-03,  4.6754e-04,  2.8310e-04,\n",
       "                       4.7240e-04,  5.3271e-04,  1.7768e-03, -8.6881e-03, -4.0305e-03,\n",
       "                      -4.8562e-03,  7.7925e-04, -2.5459e-03, -6.8243e-04,  3.1197e-04,\n",
       "                       1.9300e-03,  1.2004e-03,  4.8058e-03,  8.6638e-03, -1.9232e-03,\n",
       "                      -4.4688e-03, -2.9900e-03,  2.6047e-03, -1.5157e-03, -5.4773e-03,\n",
       "                       4.0221e-04, -2.0915e-03,  7.9901e-04, -5.1122e-03, -1.3351e-03,\n",
       "                      -1.0516e-02,  7.6190e-04, -1.0663e-03,  1.8556e-03, -2.9858e-04,\n",
       "                       4.5228e-03,  4.5333e-03, -3.2911e-04, -7.6233e-03,  4.8854e-04,\n",
       "                       5.8077e-03, -5.0480e-03, -2.1785e-03,  2.4157e-03, -1.4530e-03,\n",
       "                       4.9296e-03, -1.6386e-03, -6.9685e-04,  6.3923e-03, -3.0322e-03,\n",
       "                       1.5279e-03,  4.8909e-04,  1.5417e-03,  4.1692e-03,  1.0757e-02,\n",
       "                      -5.5416e-04, -1.3610e-03, -2.4578e-03, -3.8456e-03,  7.1436e-03,\n",
       "                      -3.9993e-03,  6.6253e-03,  1.6494e-03,  5.9607e-03,  1.0692e-03,\n",
       "                       1.3836e-03, -3.2932e-03, -4.6551e-03, -2.3831e-03, -3.9914e-03,\n",
       "                      -7.9930e-03,  1.0517e-03,  4.3584e-05,  3.4028e-03,  4.8606e-03,\n",
       "                       5.7272e-03, -9.1534e-03, -2.4108e-04,  2.9058e-03, -1.7262e-03,\n",
       "                      -4.2086e-03,  6.0868e-04,  5.2768e-03,  6.1812e-03,  2.3757e-03,\n",
       "                      -2.8997e-03, -2.5654e-04,  1.8577e-03, -2.8108e-03,  4.0364e-03,\n",
       "                      -2.3623e-03,  1.8026e-03, -4.0000e-03,  3.2644e-03,  2.0542e-03,\n",
       "                       6.0320e-03, -4.3666e-03, -1.7843e-03,  5.4233e-03,  2.5852e-03,\n",
       "                      -7.6889e-04,  6.5375e-04, -5.9233e-03,  1.0423e-04, -8.9684e-03,\n",
       "                      -3.3734e-03, -4.2099e-04,  1.1306e-03, -6.6954e-03, -7.2670e-03,\n",
       "                       2.6643e-03,  7.2440e-03,  3.7430e-03, -1.3837e-03,  2.9135e-03,\n",
       "                      -6.9557e-03, -2.5273e-04, -9.7842e-03,  1.0176e-03,  1.9944e-03,\n",
       "                       9.0466e-04, -3.6582e-03, -3.0659e-04, -1.2525e-03, -5.4341e-03,\n",
       "                       1.1976e-03, -9.1096e-03,  1.8185e-03,  6.7371e-03,  1.1003e-03,\n",
       "                      -5.0854e-03,  2.8613e-03, -3.8929e-03,  1.4493e-04, -5.8082e-03,\n",
       "                       2.6433e-03,  1.4545e-03,  1.3772e-03,  6.6220e-03,  6.6550e-03,\n",
       "                       1.8856e-03, -8.0369e-04, -5.4946e-03, -1.4106e-03,  4.3702e-03,\n",
       "                      -5.5820e-04, -7.8979e-03, -3.9801e-03, -6.1310e-03,  3.4755e-04,\n",
       "                       3.9572e-03, -2.2899e-03, -1.0913e-03,  2.5701e-03, -2.2229e-03,\n",
       "                       3.8983e-03,  3.5779e-03, -3.0041e-03, -1.5369e-04,  1.3408e-03,\n",
       "                       4.8029e-03,  3.9220e-07, -1.6917e-06, -9.8103e-07, -1.0293e-06,\n",
       "                       3.9798e-07,  5.7455e-07,  9.8831e-07, -7.4743e-07, -6.0070e-07,\n",
       "                       7.5857e-07, -5.0842e-07, -1.3222e-07,  1.0761e-07, -9.4281e-08,\n",
       "                       1.0409e-06, -7.0240e-07, -1.1006e-06, -1.0351e-06, -1.6862e-07,\n",
       "                       6.5793e-07,  5.5515e-07,  4.9124e-07,  1.8092e-06,  3.6451e-07,\n",
       "                      -6.5210e-07,  2.2883e-06,  7.0685e-07,  1.8260e-06,  2.9429e-06,\n",
       "                      -6.7771e-07, -7.5792e-07,  9.0238e-07,  1.9562e-06, -1.1000e-07,\n",
       "                      -3.8144e-07,  1.5202e-06,  1.1363e-06,  3.3984e-07,  4.4578e-07,\n",
       "                       2.5442e-06,  9.0890e-07, -2.9352e-07, -6.7682e-07,  1.9613e-06,\n",
       "                       7.8969e-07, -8.7636e-07, -2.8000e-06, -5.5422e-07,  1.3452e-08,\n",
       "                       6.7371e-07, -1.4662e-07,  9.1214e-07, -1.2696e-06,  1.4705e-06,\n",
       "                      -3.2556e-07, -4.6120e-07,  2.3385e-06, -1.0474e-06,  1.4451e-06,\n",
       "                       2.3259e-07, -2.4725e-07, -1.4278e-06,  2.9745e-06, -2.0950e-07,\n",
       "                       3.6432e-06,  9.2324e-06, -1.5530e-05, -2.0175e-05, -1.4426e-05,\n",
       "                       4.8803e-05, -6.5177e-05, -4.6921e-05, -2.5624e-05, -2.2202e-05,\n",
       "                      -1.3254e-05,  4.1844e-05, -2.8523e-05,  1.6415e-05, -3.2812e-06,\n",
       "                      -2.0399e-05, -4.0278e-05, -9.6044e-06, -2.9162e-05, -5.9401e-05,\n",
       "                       9.7331e-05,  2.9300e-05, -1.8478e-06,  8.5976e-05, -4.0195e-05,\n",
       "                       7.2205e-06,  2.1381e-05,  7.3218e-05, -2.3792e-05, -1.1918e-05,\n",
       "                       5.5419e-06, -1.3077e-04, -2.7939e-05, -2.3550e-05, -3.7742e-05,\n",
       "                      -3.4507e-05,  1.1666e-05,  2.9673e-05, -2.8326e-05, -1.1761e-04,\n",
       "                      -1.0679e-05,  5.2692e-05, -1.4296e-05,  1.2961e-05, -1.0896e-05,\n",
       "                       1.1962e-05, -1.1218e-05,  1.1040e-05,  4.2074e-05,  7.7296e-05,\n",
       "                      -1.0566e-06, -4.1025e-05, -6.3502e-05, -1.5495e-05, -4.3704e-06,\n",
       "                       3.0171e-05,  2.9550e-05,  7.9074e-06, -1.9488e-05, -3.7452e-05,\n",
       "                      -7.9680e-06,  1.0556e-04,  2.2602e-05,  2.8375e-06,  1.5064e-06,\n",
       "                       1.3513e-07,  1.4007e-06, -5.0259e-08, -2.8651e-07,  5.2386e-07,\n",
       "                       1.4023e-06, -9.9024e-07,  1.7369e-06,  1.6995e-06, -1.2441e-06,\n",
       "                       1.6868e-08,  1.4169e-07, -2.2254e-06, -4.5079e-08, -3.6070e-07,\n",
       "                      -2.0041e-08,  4.4411e-07,  1.1081e-06, -1.0766e-06,  2.1679e-06,\n",
       "                       9.9653e-07, -5.0004e-07, -5.4895e-08,  9.9607e-08, -2.7932e-06,\n",
       "                       6.9714e-07,  1.0934e-06, -3.9477e-07,  6.1954e-07,  6.3616e-07,\n",
       "                      -5.4107e-07,  5.0012e-07,  6.5744e-07,  6.1652e-07, -4.5382e-06,\n",
       "                       2.5124e-06,  1.3869e-07, -8.7556e-07,  3.8408e-07, -4.3488e-07,\n",
       "                      -1.1129e-06, -1.1834e-06,  2.6790e-06, -3.1236e-07,  7.1094e-08,\n",
       "                      -8.2377e-07, -3.9220e-07,  2.2089e-06,  1.3127e-07,  6.5275e-07,\n",
       "                      -1.5274e-06, -2.0407e-06, -1.7155e-06,  7.7525e-07,  7.7172e-07,\n",
       "                       2.5521e-06, -4.2694e-07,  3.0903e-07, -5.6856e-07,  5.1085e-08,\n",
       "                      -1.0922e-06,  2.8377e-06,  2.3467e-07, -8.2825e-05,  5.7276e-05,\n",
       "                       9.0546e-05, -2.2698e-04,  2.0113e-05, -1.3857e-04, -1.4144e-04,\n",
       "                      -3.6120e-04,  1.4864e-04,  8.2904e-05, -8.6735e-05,  1.2665e-04,\n",
       "                      -2.0138e-04,  8.9003e-05, -4.8173e-04,  5.1374e-05,  6.3272e-05,\n",
       "                       2.5799e-04,  2.7129e-04, -9.6927e-05, -1.1966e-04,  2.1883e-04,\n",
       "                       1.2757e-04,  8.9250e-05,  1.3052e-04, -2.6491e-04, -2.1630e-04,\n",
       "                      -9.0508e-05, -1.5882e-04, -3.0080e-04,  2.0047e-04,  1.7417e-04,\n",
       "                      -1.2457e-04, -5.7521e-05, -7.6268e-05, -6.5766e-05, -1.4162e-04,\n",
       "                       1.8985e-04, -1.2249e-04,  9.0907e-05,  6.5357e-05,  8.4450e-05,\n",
       "                      -2.2079e-04, -3.8609e-04,  2.5783e-05, -1.4421e-04, -1.4421e-04,\n",
       "                       1.0591e-04,  1.7444e-04, -1.0094e-04, -1.2757e-04, -3.2187e-05,\n",
       "                      -9.7200e-05, -4.2464e-05, -8.4716e-05,  4.9763e-05,  4.5563e-05,\n",
       "                      -3.4811e-05,  1.8897e-04, -2.8129e-04, -2.7563e-05, -9.0416e-05,\n",
       "                       1.0523e-04,  1.7248e-04, -1.4448e-03,  3.2491e-03,  1.1098e-03,\n",
       "                       5.9560e-04,  4.2221e-04,  6.1924e-04, -1.5912e-03,  1.5905e-03,\n",
       "                       2.2430e-03, -3.4662e-03, -2.1127e-03, -1.9037e-03,  1.3840e-03,\n",
       "                      -1.8258e-04,  1.1882e-03, -2.4040e-03, -1.9376e-04,  1.2240e-03,\n",
       "                       1.3046e-03, -2.0870e-03,  3.3679e-04, -2.2648e-03,  3.9487e-03,\n",
       "                      -4.8870e-04,  3.5012e-03,  1.5788e-03, -1.7221e-03, -6.7836e-04,\n",
       "                       1.7151e-03,  5.5198e-04,  2.2475e-03, -3.1821e-03, -3.3235e-03,\n",
       "                      -8.0304e-04, -2.3723e-03,  1.8532e-03,  6.4278e-04,  2.5593e-03,\n",
       "                      -2.4499e-03, -1.6918e-03,  3.3077e-04, -3.1938e-03, -2.3508e-03,\n",
       "                       2.0251e-03,  2.5735e-03,  1.3321e-03,  1.1637e-03,  1.4012e-03,\n",
       "                       7.0842e-04, -1.3552e-04,  3.1756e-03, -2.5674e-04,  5.1152e-04,\n",
       "                       9.0704e-04,  4.2863e-03,  2.4474e-03,  1.8360e-03,  2.5010e-03,\n",
       "                      -1.5446e-03, -2.5714e-04,  5.3234e-04,  2.0975e-03, -3.0847e-03,\n",
       "                       1.0637e-03, -1.7164e-03, -2.5929e-03,  1.2404e-03,  2.3747e-03,\n",
       "                      -2.4233e-04,  5.5949e-04, -5.0891e-03, -8.1436e-04, -1.1154e-03,\n",
       "                      -1.0571e-03,  1.0309e-03, -1.3601e-03, -1.5725e-03,  2.4460e-03,\n",
       "                      -1.3881e-03, -5.0168e-04, -1.4711e-03, -5.8465e-04,  6.6844e-04,\n",
       "                       2.9640e-04,  7.6356e-03,  7.6541e-04, -4.0536e-03,  1.7892e-03,\n",
       "                      -1.8499e-03, -1.4288e-03, -1.8187e-03,  2.6960e-03, -7.8901e-04,\n",
       "                       1.1354e-03,  1.0308e-03,  6.9865e-04,  5.4177e-04,  6.9932e-04,\n",
       "                       3.9402e-03, -5.0255e-03, -1.1535e-03, -4.0101e-03, -2.6075e-03,\n",
       "                      -6.0371e-05, -3.6010e-04,  1.7917e-03, -1.6257e-03, -3.0403e-03,\n",
       "                      -2.8065e-03, -1.8058e-04, -3.3157e-03, -2.5761e-04,  1.7149e-03,\n",
       "                      -3.1327e-03,  1.8047e-03,  3.8633e-03, -2.6369e-03,  2.0623e-04,\n",
       "                      -5.7648e-05, -6.1707e-04, -1.9415e-03, -9.6225e-04,  2.4632e-03,\n",
       "                      -1.3181e-03, -7.3693e-04, -7.1309e-04,  2.4344e-03,  1.1437e-05,\n",
       "                       4.1299e-03,  1.3176e-03,  3.2449e-04,  6.0471e-04, -1.3129e-04,\n",
       "                       4.5613e-03, -5.8401e-04, -1.2696e-04,  3.8690e-03,  1.0439e-03,\n",
       "                       3.8568e-04, -1.1720e-03, -1.5536e-03,  4.4473e-03,  1.3292e-03,\n",
       "                       7.3135e-04, -5.5128e-06, -1.0005e-03,  1.0500e-04,  8.3292e-04,\n",
       "                      -2.6413e-03,  1.9312e-03, -5.2132e-05,  3.0320e-03, -2.3010e-03,\n",
       "                       8.3795e-04,  4.3604e-04,  2.7325e-03,  1.7900e-03, -7.0708e-04,\n",
       "                       2.0082e-03,  2.7579e-03, -1.6163e-03,  1.5246e-04,  3.4288e-03,\n",
       "                      -2.4944e-03, -4.3658e-03, -4.6608e-03,  1.8718e-03, -1.4381e-03,\n",
       "                      -6.2240e-04,  1.1207e-03, -1.5702e-03, -2.3622e-03, -1.8774e-03,\n",
       "                      -1.3375e-03,  2.0801e-03, -6.6976e-04,  4.0662e-03, -4.3189e-04,\n",
       "                      -1.2048e-03, -8.7868e-04,  7.1460e-05,  1.4712e-03, -1.2244e-04,\n",
       "                      -1.0388e-03,  1.1633e-03, -2.0955e-03, -1.6339e-04, -3.1257e-03,\n",
       "                      -2.2909e-04,  1.7127e-04,  9.2165e-04, -2.5691e-03,  3.3841e-04,\n",
       "                       2.2537e-03, -9.0488e-04,  2.7092e-03,  2.3197e-03, -6.0828e-04,\n",
       "                      -1.5182e-03, -1.8965e-03, -6.0609e-04,  8.1394e-04,  5.4753e-04,\n",
       "                      -7.7948e-04,  2.7257e-03,  7.6721e-04,  3.5199e-03, -3.9431e-03,\n",
       "                      -1.0118e-03, -2.2351e-04, -2.2484e-03,  5.2042e-04,  3.9249e-04,\n",
       "                       9.6775e-04,  2.9953e-03,  1.6106e-04, -5.1923e-04, -1.1188e-03,\n",
       "                      -1.9173e-03,  1.0381e-03,  3.2005e-03, -1.8814e-03,  3.0907e-03,\n",
       "                      -2.3458e-03, -1.5121e-03,  1.5203e-03, -1.1045e-03, -5.5571e-04,\n",
       "                       2.3763e-03, -4.2824e-03,  3.2685e-04, -4.0426e-03,  9.6498e-04,\n",
       "                       1.4818e-03, -2.5023e-03, -1.5723e-04, -4.3418e-03,  2.1941e-03,\n",
       "                      -5.4315e-04, -2.9083e-03, -1.5836e-03,  1.4320e-03, -6.4202e-04,\n",
       "                      -3.6473e-03,  2.3643e-03,  4.4666e-04, -2.3859e-03,  2.7120e-03,\n",
       "                       5.0643e-03, -8.4885e-04, -3.0649e-03,  3.8132e-04, -2.0871e-04,\n",
       "                      -6.8443e-04, -1.3741e-03,  7.8197e-03], device='cuda:0')),\n",
       "             ('decoder.layers.1.multihead_attn.out_proj.weight',\n",
       "              tensor([[ 0.0258, -0.0035, -0.0067,  ..., -0.0386, -0.0435, -0.0164],\n",
       "                      [-0.0187, -0.0210, -0.0173,  ..., -0.0158,  0.0121, -0.0143],\n",
       "                      [-0.0100, -0.0383,  0.0553,  ...,  0.0299, -0.0514,  0.0279],\n",
       "                      ...,\n",
       "                      [ 0.0254, -0.0275, -0.0087,  ..., -0.0251,  0.0362, -0.0159],\n",
       "                      [ 0.0256, -0.0044, -0.0109,  ..., -0.0622,  0.0537,  0.0149],\n",
       "                      [-0.0150,  0.0533, -0.0048,  ...,  0.0138, -0.0097, -0.0553]],\n",
       "                     device='cuda:0')),\n",
       "             ('decoder.layers.1.multihead_attn.out_proj.bias',\n",
       "              tensor([ 6.8515e-04, -1.9890e-03,  3.0842e-03,  4.8412e-04, -1.5088e-03,\n",
       "                       2.3589e-03, -3.9766e-03,  2.0686e-03,  2.6691e-03, -3.2124e-04,\n",
       "                      -3.7894e-03,  3.8473e-03,  2.3400e-04, -3.8853e-04, -1.0351e-03,\n",
       "                      -1.7542e-03,  8.9672e-04, -1.2680e-03,  1.6829e-03,  1.5748e-03,\n",
       "                      -7.5606e-04,  1.3005e-03,  2.3974e-03,  4.0803e-03,  2.9445e-03,\n",
       "                      -6.7729e-04,  3.4477e-03,  2.7605e-04, -4.3773e-03, -3.2227e-03,\n",
       "                      -1.2726e-03,  6.3351e-04,  2.7313e-03, -1.6560e-04, -4.1974e-03,\n",
       "                      -1.1817e-03,  3.6289e-03,  4.0831e-04, -2.1659e-03, -1.4360e-04,\n",
       "                      -4.7432e-04,  5.0175e-03, -9.0382e-04, -1.9358e-03,  8.9186e-04,\n",
       "                       2.0917e-03,  1.8542e-03,  8.6015e-04,  1.2576e-03,  3.2352e-03,\n",
       "                       2.5389e-04,  1.2249e-03, -4.2286e-03,  1.8049e-03, -2.0599e-03,\n",
       "                      -8.6232e-04, -2.5355e-03, -1.7481e-03,  5.2569e-03,  5.5308e-04,\n",
       "                      -2.4671e-03,  4.1973e-03,  2.6224e-03, -6.5784e-04,  3.8786e-03,\n",
       "                      -2.1879e-03,  1.1194e-03, -2.8473e-03, -3.6492e-03,  2.8137e-03,\n",
       "                       2.8306e-03,  3.8139e-03, -2.4142e-03, -5.6817e-04,  3.7917e-03,\n",
       "                       4.9885e-04, -8.7635e-04,  1.7209e-03,  1.4549e-03, -2.3009e-03,\n",
       "                       3.5130e-03, -1.0359e-03, -6.1467e-03,  1.7221e-03, -2.7001e-04,\n",
       "                       4.4415e-04, -3.9104e-03,  3.1154e-03, -1.2214e-03,  4.0446e-03,\n",
       "                      -2.5648e-03,  2.0963e-03, -7.1098e-04,  5.5306e-03, -1.9202e-04,\n",
       "                       3.2612e-03,  6.8863e-05,  1.2409e-03, -2.4121e-03,  2.0943e-03,\n",
       "                       7.8599e-04,  2.0593e-04, -1.0033e-03,  1.1700e-03, -7.3826e-05,\n",
       "                      -1.5779e-03, -2.3207e-03, -3.2845e-03,  2.9900e-03, -2.3832e-03,\n",
       "                      -3.0241e-04,  1.0467e-03, -2.4205e-03,  1.3342e-03, -3.8380e-03,\n",
       "                      -2.8452e-03,  4.3450e-03, -3.6654e-04,  5.6397e-05, -5.6411e-03,\n",
       "                      -9.1455e-04, -7.5376e-05,  9.8604e-04, -1.8259e-03,  1.7351e-03,\n",
       "                       4.1134e-04, -4.6043e-03,  1.0250e-03, -2.1900e-04, -1.7316e-03,\n",
       "                      -2.5884e-03,  2.8395e-03, -4.4740e-04, -2.4257e-04, -3.1035e-03,\n",
       "                       3.2353e-05,  4.4697e-03,  1.5837e-04, -2.2727e-03, -1.6312e-03,\n",
       "                      -2.9696e-03, -2.9362e-04, -2.1753e-03, -3.1260e-03, -9.5721e-04,\n",
       "                      -1.4971e-03, -3.1786e-03, -6.6259e-04, -5.7609e-03, -3.1145e-03,\n",
       "                       1.7716e-04,  4.5918e-04,  4.4455e-03, -1.4889e-03,  8.3717e-04,\n",
       "                      -1.3390e-03, -1.6690e-03, -3.2944e-03, -4.1657e-04,  1.8234e-03,\n",
       "                      -2.0022e-03,  3.7080e-03,  1.5260e-03, -1.2419e-03, -3.2110e-03,\n",
       "                       3.5401e-03, -1.3758e-03, -1.0139e-03, -4.0190e-03,  3.8535e-03,\n",
       "                       4.5390e-03,  2.8765e-03,  3.4055e-03, -6.9647e-04,  2.9862e-03,\n",
       "                      -2.5584e-03, -1.9596e-03, -2.4481e-03, -1.2995e-03,  1.5532e-03,\n",
       "                      -9.6760e-04, -3.7286e-03, -1.8137e-03, -4.7739e-03,  1.1658e-03,\n",
       "                      -1.4015e-04, -9.0002e-04,  3.9070e-03, -3.3709e-03, -2.8049e-03,\n",
       "                      -1.6853e-03, -6.0015e-03,  3.7153e-03, -4.6634e-03, -2.1639e-03,\n",
       "                      -4.9878e-04, -2.8813e-03, -2.6828e-04, -2.8754e-03, -1.5070e-03,\n",
       "                      -1.8760e-04,  2.6651e-04, -1.6541e-05,  8.6243e-04,  1.8092e-03,\n",
       "                       7.5062e-04, -5.9647e-04, -3.5218e-03,  7.5769e-04, -3.6627e-03,\n",
       "                       3.6670e-03,  3.3050e-03,  1.6693e-03, -3.4154e-03,  1.0291e-03,\n",
       "                       3.3173e-03,  2.8934e-04, -4.5812e-03, -3.7338e-03, -7.1776e-04,\n",
       "                       1.1171e-03,  1.0854e-04, -1.6609e-03,  4.6178e-03,  6.0624e-04,\n",
       "                       2.1718e-03, -1.4614e-03,  6.2659e-03,  3.3642e-03,  3.4241e-04,\n",
       "                       1.4787e-03,  1.5404e-03,  5.9131e-04,  8.1829e-04, -3.5041e-04,\n",
       "                       1.8489e-03,  2.5240e-03,  3.1282e-03,  7.4298e-04, -1.3696e-04,\n",
       "                       1.5326e-03,  3.2652e-03, -2.2881e-03, -4.6938e-04, -4.8150e-03,\n",
       "                       1.5282e-04, -1.1876e-05, -6.7776e-04,  3.0846e-03, -3.1048e-03,\n",
       "                       2.5359e-03, -1.1167e-03,  4.7472e-03,  1.4890e-03,  3.0939e-03,\n",
       "                      -1.9621e-03], device='cuda:0')),\n",
       "             ('decoder.layers.1.linear1.weight',\n",
       "              tensor([[-0.0387,  0.0452,  0.0365,  ...,  0.0303,  0.0124,  0.0034],\n",
       "                      [-0.0087,  0.0035, -0.0431,  ...,  0.0407,  0.0001,  0.0609],\n",
       "                      [-0.0176,  0.0213,  0.0100,  ..., -0.0206, -0.0171,  0.0144],\n",
       "                      ...,\n",
       "                      [-0.0268, -0.0093, -0.0278,  ...,  0.0023, -0.0411, -0.0134],\n",
       "                      [-0.0213, -0.0073,  0.0402,  ..., -0.0309,  0.0050,  0.0175],\n",
       "                      [ 0.0325, -0.0372,  0.0459,  ...,  0.0627, -0.0343,  0.0267]],\n",
       "                     device='cuda:0')),\n",
       "             ('decoder.layers.1.linear1.bias',\n",
       "              tensor([ 0.0586, -0.0072, -0.0010,  ...,  0.0193,  0.0202, -0.0436],\n",
       "                     device='cuda:0')),\n",
       "             ('decoder.layers.1.linear2.weight',\n",
       "              tensor([[ 2.0489e-02, -4.2724e-03, -5.4987e-03,  ..., -7.7574e-03,\n",
       "                        2.1768e-02, -1.2509e-02],\n",
       "                      [-4.9634e-03,  5.0198e-03, -1.1895e-03,  ..., -4.2146e-03,\n",
       "                       -1.9771e-02, -3.3381e-03],\n",
       "                      [-9.9688e-03, -2.1223e-02,  1.4311e-03,  ..., -1.8533e-02,\n",
       "                        7.0849e-03, -3.5560e-03],\n",
       "                      ...,\n",
       "                      [ 1.8076e-02,  1.1517e-02, -3.7529e-03,  ..., -9.8766e-04,\n",
       "                        1.2570e-02, -2.4750e-02],\n",
       "                      [ 2.6749e-02, -1.7023e-02,  6.8301e-04,  ...,  2.5010e-02,\n",
       "                       -1.9915e-02,  1.0200e-02],\n",
       "                      [-5.7976e-05, -1.3206e-02,  7.7967e-03,  ..., -4.0973e-03,\n",
       "                       -1.1015e-03, -1.3423e-02]], device='cuda:0')),\n",
       "             ('decoder.layers.1.linear2.bias',\n",
       "              tensor([ 1.9965e-02, -1.2848e-02,  1.3626e-03,  9.2797e-03,  1.8658e-02,\n",
       "                      -7.9597e-03,  1.9986e-02,  1.1654e-02,  1.4588e-02, -1.9599e-02,\n",
       "                      -2.0337e-02, -1.4676e-02, -1.5514e-02, -8.1960e-03, -1.7339e-02,\n",
       "                       1.4848e-02,  1.8581e-02,  8.2515e-04, -1.0138e-02, -1.1599e-02,\n",
       "                      -1.0267e-02,  2.0549e-02, -7.4346e-03,  2.0906e-02,  1.4257e-02,\n",
       "                      -1.7945e-02,  1.0364e-02,  9.6281e-03, -1.5124e-02,  3.6750e-03,\n",
       "                       1.9847e-02, -8.3798e-03,  1.7385e-02,  2.0205e-02, -4.7857e-03,\n",
       "                      -1.2922e-02, -9.0029e-03,  5.8342e-03, -1.5532e-02,  7.1359e-04,\n",
       "                       6.8464e-03, -2.8009e-03, -8.8280e-03, -1.2976e-02, -1.5368e-02,\n",
       "                       8.3804e-03, -3.1409e-03, -8.3498e-03,  7.8303e-03, -1.0257e-02,\n",
       "                      -2.0359e-02,  9.1188e-03,  2.9891e-03,  1.7176e-02, -1.6394e-02,\n",
       "                       4.3950e-03,  1.2563e-02,  5.3196e-03,  4.2088e-03, -1.4152e-02,\n",
       "                      -1.6313e-02, -2.1380e-02, -2.4318e-03,  2.6411e-03,  3.2595e-04,\n",
       "                       1.1803e-02, -6.6954e-03,  6.0412e-03, -2.0550e-02,  8.8224e-03,\n",
       "                      -8.5125e-03, -1.8194e-02, -1.1942e-03,  1.2600e-02, -1.6474e-02,\n",
       "                       1.6111e-02,  1.6565e-02,  2.2152e-02, -6.9494e-03,  1.6396e-02,\n",
       "                      -5.2141e-03, -2.2926e-03,  5.7985e-03,  1.9932e-02, -1.8199e-02,\n",
       "                       4.3205e-03,  1.2491e-02, -4.6975e-03,  5.4326e-03, -1.9443e-02,\n",
       "                       1.3386e-02,  5.6606e-03,  1.2986e-02,  6.4989e-03,  4.1675e-03,\n",
       "                       2.1116e-02, -6.0859e-04,  1.0656e-02, -4.0923e-03,  1.8766e-02,\n",
       "                      -6.3893e-03, -1.5545e-02, -1.5426e-02, -1.1034e-02, -3.2383e-03,\n",
       "                      -1.5771e-02,  2.0438e-02,  4.8912e-03, -1.1615e-02,  1.5356e-02,\n",
       "                       1.9535e-02,  2.8092e-03, -1.8825e-02, -2.5908e-03, -1.5560e-02,\n",
       "                       4.1121e-03,  1.6672e-03, -4.0235e-03, -3.0793e-03,  9.2070e-04,\n",
       "                       7.7901e-03,  1.4326e-02, -2.0133e-03,  1.9330e-02,  1.6820e-02,\n",
       "                       9.9210e-03, -4.5907e-03, -1.5443e-02,  4.2361e-03,  1.3110e-02,\n",
       "                      -1.5166e-02, -1.3594e-02, -8.8233e-03,  4.0784e-04,  1.8339e-03,\n",
       "                      -2.1279e-02, -2.0849e-02,  1.7537e-02,  9.2518e-04,  6.9002e-03,\n",
       "                      -1.3582e-02, -9.4595e-03, -1.3729e-02,  8.2472e-03, -1.1527e-02,\n",
       "                      -1.1979e-02, -3.1149e-03,  1.1814e-02,  2.2165e-02,  5.8586e-03,\n",
       "                      -1.2270e-02, -3.5788e-03, -9.0561e-03,  1.4939e-02, -6.0314e-04,\n",
       "                      -1.1178e-02,  1.8428e-02,  1.0377e-02,  1.6321e-02, -1.5362e-02,\n",
       "                       5.9950e-03, -2.9483e-06, -1.8549e-02, -2.2678e-02,  4.3240e-03,\n",
       "                      -1.1104e-02,  1.1929e-02, -1.4723e-03,  1.6239e-02,  1.5197e-02,\n",
       "                       1.8130e-02,  1.9030e-04, -1.2676e-03, -7.6973e-03, -2.0760e-03,\n",
       "                       5.2359e-03,  1.7328e-02, -2.1559e-02, -9.8104e-03, -1.2980e-02,\n",
       "                      -4.1294e-03,  1.6626e-02, -4.8020e-03,  1.5832e-04,  4.6235e-03,\n",
       "                      -3.6986e-03,  1.3728e-02,  8.4903e-04, -1.0792e-02, -7.3083e-04,\n",
       "                       2.0442e-02,  9.7515e-04,  1.1746e-02, -4.7545e-03,  1.9796e-03,\n",
       "                      -1.9604e-02,  1.2459e-02,  1.6611e-02, -1.7038e-02,  1.8113e-03,\n",
       "                       1.3383e-02, -1.8164e-02, -1.4897e-02,  1.4914e-02, -9.0119e-03,\n",
       "                      -1.2911e-02, -2.1813e-02, -1.1516e-02, -1.8424e-02,  1.9070e-02,\n",
       "                      -1.4568e-02,  1.0685e-02, -1.6424e-02,  1.8794e-02, -1.8665e-02,\n",
       "                       3.1746e-03,  2.1236e-02,  1.2159e-02,  2.2090e-02,  1.9124e-02,\n",
       "                      -1.9400e-03, -6.2494e-03,  1.6337e-02, -1.6968e-02,  1.4509e-02,\n",
       "                       1.0632e-02,  1.9541e-02,  1.9934e-02,  2.2500e-03,  7.4073e-03,\n",
       "                       2.0112e-02, -1.4733e-03,  1.5960e-02,  1.3215e-02, -7.8184e-03,\n",
       "                       1.8245e-02, -1.6390e-02,  1.0135e-03, -6.8932e-03, -1.5676e-02,\n",
       "                       9.7361e-03, -1.7561e-02, -2.3374e-03,  5.1493e-03,  1.3775e-02,\n",
       "                      -1.2942e-02,  1.4528e-02, -2.9156e-03,  1.8159e-02,  1.3499e-03,\n",
       "                      -1.9992e-02,  6.1472e-03,  2.0936e-03,  1.0221e-02,  4.8541e-03,\n",
       "                       2.1453e-02], device='cuda:0')),\n",
       "             ('decoder.layers.1.norm1.weight',\n",
       "              tensor([0.9904, 1.0000, 0.9896, 0.9984, 0.9911, 0.9986, 0.9924, 0.9864, 0.9881,\n",
       "                      0.9873, 0.9953, 0.9942, 0.9989, 0.9888, 1.0035, 0.9935, 1.0066, 1.0039,\n",
       "                      0.9919, 0.9916, 0.9958, 0.9941, 0.9940, 0.9924, 0.9883, 1.0073, 0.9951,\n",
       "                      0.9939, 0.9999, 1.0062, 0.9982, 0.9965, 0.9876, 1.0041, 0.9924, 1.0006,\n",
       "                      0.9912, 0.9945, 1.0046, 0.9952, 1.0038, 0.9947, 1.0021, 0.9937, 1.0012,\n",
       "                      0.9904, 0.9925, 1.0046, 1.0066, 1.0038, 0.9998, 0.9995, 1.0021, 0.9903,\n",
       "                      1.0048, 0.9906, 1.0037, 1.0056, 0.9942, 1.0009, 1.0065, 0.9983, 0.9887,\n",
       "                      1.0040, 1.0060, 1.0136, 0.9979, 1.0041, 0.9999, 0.9982, 0.9944, 0.9912,\n",
       "                      1.0022, 1.0004, 0.9967, 1.0034, 1.0144, 1.0131, 1.0060, 1.0073, 1.0002,\n",
       "                      0.9977, 0.9996, 1.0170, 0.9956, 0.9976, 0.9994, 1.0046, 0.9976, 1.0039,\n",
       "                      1.0014, 1.0034, 1.0035, 0.9980, 0.9963, 1.0122, 1.0011, 1.0044, 0.9933,\n",
       "                      1.0008, 1.0035, 0.9979, 1.0008, 1.0095, 1.0064, 1.0054, 1.0035, 1.0111,\n",
       "                      0.9992, 1.0106, 1.0007, 0.9968, 1.0042, 1.0098, 1.0062, 1.0047, 1.0049,\n",
       "                      1.0051, 1.0016, 1.0050, 1.0018, 1.0079, 1.0025, 0.9962, 0.9886, 0.9988,\n",
       "                      0.9940, 0.9995, 1.0004, 0.9990, 0.9957, 1.0008, 1.0113, 1.0051, 1.0157,\n",
       "                      1.0105, 0.9991, 1.0191, 0.9987, 1.0063, 1.0040, 1.0016, 1.0118, 0.9975,\n",
       "                      1.0123, 1.0013, 1.0105, 0.9962, 0.9979, 1.0001, 1.0127, 1.0139, 1.0126,\n",
       "                      1.0046, 1.0061, 0.9963, 1.0132, 0.9939, 1.0051, 0.9989, 1.0033, 1.0068,\n",
       "                      1.0042, 0.9930, 1.0059, 1.0015, 1.0028, 0.9952, 1.0017, 1.0021, 1.0014,\n",
       "                      1.0047, 1.0119, 1.0074, 1.0061, 1.0026, 1.0202, 0.9994, 1.0033, 0.9998,\n",
       "                      1.0070, 1.0079, 1.0068, 0.9890, 1.0106, 1.0016, 1.0035, 1.0024, 1.0088,\n",
       "                      1.0052, 1.0040, 0.9982, 1.0211, 0.9971, 1.0114, 0.9979, 1.0061, 1.0058,\n",
       "                      1.0034, 0.9994, 0.9971, 1.0011, 1.0134, 1.0076, 1.0002, 0.9982, 1.0213,\n",
       "                      0.9999, 0.9963, 0.9980, 1.0008, 1.0019, 1.0067, 0.9835, 1.0071, 1.0019,\n",
       "                      1.0078, 1.0028, 1.0117, 0.9925, 1.0046, 1.0065, 1.0008, 1.0023, 1.0115,\n",
       "                      0.9964, 1.0104, 0.9982, 1.0003, 1.0100, 1.0077, 1.0066, 1.0091, 1.0071,\n",
       "                      1.0137, 1.0028, 1.0004, 0.9977, 1.0017, 0.9894, 1.0095, 1.0005, 1.0129,\n",
       "                      0.9986, 1.0109, 0.9937, 0.9994, 0.9967, 1.0117, 0.9900, 0.9955, 1.0015,\n",
       "                      1.0179, 1.0027, 0.9949, 1.0023], device='cuda:0')),\n",
       "             ('decoder.layers.1.norm1.bias',\n",
       "              tensor([ 0.0047, -0.0089,  0.0113,  0.0019, -0.0066, -0.0008, -0.0087,  0.0085,\n",
       "                       0.0094,  0.0063, -0.0085,  0.0076, -0.0009, -0.0078,  0.0032, -0.0072,\n",
       "                      -0.0042, -0.0051,  0.0067, -0.0078,  0.0057,  0.0048,  0.0068,  0.0094,\n",
       "                       0.0094, -0.0030,  0.0068, -0.0042, -0.0060, -0.0005,  0.0021, -0.0029,\n",
       "                       0.0091, -0.0027, -0.0067, -0.0042,  0.0058,  0.0042, -0.0043, -0.0060,\n",
       "                      -0.0049,  0.0079, -0.0052,  0.0069,  0.0047,  0.0093,  0.0059,  0.0051,\n",
       "                       0.0067,  0.0056,  0.0053, -0.0040, -0.0095,  0.0066, -0.0038,  0.0062,\n",
       "                      -0.0058, -0.0028,  0.0097, -0.0058, -0.0032,  0.0074,  0.0088, -0.0051,\n",
       "                       0.0079, -0.0036, -0.0017, -0.0062,  0.0079,  0.0081,  0.0074,  0.0105,\n",
       "                      -0.0056, -0.0046,  0.0072,  0.0057, -0.0047,  0.0073,  0.0064, -0.0081,\n",
       "                       0.0107, -0.0042, -0.0119,  0.0054, -0.0066,  0.0073, -0.0088,  0.0069,\n",
       "                      -0.0062,  0.0101, -0.0065,  0.0049, -0.0050,  0.0106, -0.0062,  0.0081,\n",
       "                       0.0069,  0.0088, -0.0116,  0.0080, -0.0046, -0.0099,  0.0062,  0.0005,\n",
       "                      -0.0040, -0.0047, -0.0059, -0.0054,  0.0069, -0.0080, -0.0019, -0.0056,\n",
       "                      -0.0089,  0.0030, -0.0123, -0.0080,  0.0082, -0.0066,  0.0028, -0.0124,\n",
       "                      -0.0034,  0.0033,  0.0060, -0.0058,  0.0103, -0.0034, -0.0076,  0.0044,\n",
       "                       0.0040, -0.0060, -0.0074,  0.0061,  0.0042,  0.0049, -0.0064, -0.0035,\n",
       "                       0.0100, -0.0006, -0.0089, -0.0041, -0.0051,  0.0037, -0.0047, -0.0074,\n",
       "                      -0.0045, -0.0051, -0.0056,  0.0081, -0.0071,  0.0020,  0.0049, -0.0036,\n",
       "                       0.0061,  0.0038,  0.0087, -0.0051, -0.0074, -0.0083, -0.0042, -0.0021,\n",
       "                      -0.0050,  0.0053,  0.0068,  0.0003, -0.0065,  0.0068,  0.0043, -0.0063,\n",
       "                      -0.0074,  0.0060,  0.0077,  0.0053,  0.0088,  0.0048,  0.0101, -0.0060,\n",
       "                      -0.0055, -0.0090, -0.0061,  0.0069, -0.0041, -0.0048, -0.0069, -0.0105,\n",
       "                       0.0042,  0.0100, -0.0059,  0.0067, -0.0064, -0.0051, -0.0055, -0.0085,\n",
       "                       0.0063, -0.0100, -0.0051,  0.0046, -0.0066, -0.0081, -0.0059, -0.0065,\n",
       "                      -0.0076,  0.0030, -0.0020,  0.0038,  0.0071, -0.0098, -0.0035,  0.0051,\n",
       "                       0.0059, -0.0069,  0.0083,  0.0060,  0.0042, -0.0100, -0.0039,  0.0051,\n",
       "                      -0.0013, -0.0115, -0.0071, -0.0058,  0.0078, -0.0094, -0.0086,  0.0075,\n",
       "                       0.0064,  0.0059,  0.0012,  0.0118,  0.0085, -0.0042,  0.0079,  0.0051,\n",
       "                      -0.0058,  0.0058, -0.0028,  0.0057,  0.0062,  0.0079,  0.0016,  0.0065,\n",
       "                       0.0066,  0.0073, -0.0048,  0.0020, -0.0112, -0.0050, -0.0051, -0.0051,\n",
       "                       0.0083, -0.0080,  0.0084, -0.0051,  0.0125,  0.0046,  0.0054, -0.0067],\n",
       "                     device='cuda:0')),\n",
       "             ('decoder.layers.1.norm2.weight',\n",
       "              tensor([0.9914, 0.9980, 0.9904, 0.9983, 0.9923, 0.9971, 0.9926, 0.9857, 0.9895,\n",
       "                      0.9906, 0.9958, 0.9940, 0.9995, 0.9884, 1.0009, 0.9928, 1.0038, 1.0018,\n",
       "                      0.9912, 0.9923, 0.9962, 0.9926, 0.9943, 0.9929, 0.9893, 1.0044, 0.9920,\n",
       "                      0.9944, 0.9948, 1.0050, 0.9977, 0.9951, 0.9873, 1.0035, 0.9936, 0.9977,\n",
       "                      0.9921, 0.9956, 1.0016, 0.9949, 1.0010, 0.9929, 0.9995, 0.9937, 1.0011,\n",
       "                      0.9911, 0.9928, 1.0020, 1.0031, 1.0040, 1.0004, 0.9992, 0.9999, 0.9914,\n",
       "                      1.0022, 0.9876, 1.0035, 1.0029, 0.9921, 0.9979, 1.0056, 0.9936, 0.9914,\n",
       "                      1.0018, 1.0013, 1.0102, 0.9980, 1.0034, 0.9976, 0.9972, 0.9940, 0.9924,\n",
       "                      1.0021, 0.9971, 0.9964, 1.0018, 1.0105, 1.0118, 1.0026, 1.0040, 0.9990,\n",
       "                      0.9967, 0.9971, 1.0153, 0.9961, 0.9943, 0.9981, 1.0042, 0.9968, 1.0010,\n",
       "                      0.9983, 1.0029, 1.0036, 0.9970, 0.9943, 1.0081, 0.9989, 1.0022, 0.9933,\n",
       "                      0.9987, 1.0012, 0.9953, 0.9984, 1.0057, 1.0059, 1.0037, 1.0031, 1.0088,\n",
       "                      0.9995, 1.0066, 0.9998, 0.9957, 1.0012, 1.0058, 1.0015, 1.0039, 1.0011,\n",
       "                      1.0019, 1.0004, 1.0024, 0.9998, 1.0049, 0.9994, 0.9945, 0.9915, 0.9969,\n",
       "                      0.9932, 0.9995, 0.9995, 0.9981, 0.9937, 1.0006, 1.0085, 1.0036, 1.0089,\n",
       "                      1.0035, 0.9959, 1.0187, 0.9972, 1.0047, 1.0007, 0.9990, 1.0059, 0.9974,\n",
       "                      1.0099, 1.0008, 1.0077, 0.9922, 0.9958, 0.9979, 1.0087, 1.0125, 1.0089,\n",
       "                      1.0010, 1.0025, 0.9953, 1.0124, 0.9925, 1.0032, 0.9981, 1.0015, 1.0042,\n",
       "                      1.0000, 0.9933, 1.0036, 0.9997, 1.0003, 0.9938, 0.9989, 0.9946, 1.0003,\n",
       "                      1.0044, 1.0076, 1.0038, 1.0054, 0.9976, 1.0164, 0.9989, 1.0006, 0.9978,\n",
       "                      1.0059, 1.0044, 1.0033, 0.9907, 1.0081, 0.9975, 1.0022, 1.0006, 1.0073,\n",
       "                      1.0052, 1.0009, 0.9969, 1.0140, 0.9958, 1.0081, 0.9975, 1.0022, 1.0001,\n",
       "                      0.9996, 0.9989, 0.9968, 0.9995, 1.0125, 1.0048, 0.9982, 0.9957, 1.0155,\n",
       "                      0.9976, 0.9960, 0.9994, 1.0026, 0.9999, 1.0059, 0.9871, 1.0049, 1.0010,\n",
       "                      1.0050, 0.9999, 1.0079, 0.9922, 1.0029, 1.0048, 1.0001, 0.9998, 1.0072,\n",
       "                      0.9950, 1.0071, 0.9977, 0.9957, 1.0059, 1.0038, 1.0045, 1.0062, 1.0044,\n",
       "                      1.0109, 1.0011, 0.9996, 0.9960, 0.9999, 0.9911, 1.0064, 0.9967, 1.0101,\n",
       "                      0.9966, 1.0074, 0.9946, 0.9985, 0.9973, 1.0073, 0.9917, 0.9947, 1.0002,\n",
       "                      1.0122, 1.0016, 0.9941, 0.9995], device='cuda:0')),\n",
       "             ('decoder.layers.1.norm2.bias',\n",
       "              tensor([ 0.0048, -0.0088,  0.0107,  0.0017, -0.0074, -0.0003, -0.0094,  0.0089,\n",
       "                       0.0100,  0.0052, -0.0086,  0.0078, -0.0009, -0.0082,  0.0033, -0.0074,\n",
       "                      -0.0039, -0.0057,  0.0062, -0.0086,  0.0061,  0.0050,  0.0073,  0.0094,\n",
       "                       0.0099, -0.0034,  0.0066, -0.0048, -0.0065, -0.0006,  0.0021, -0.0026,\n",
       "                       0.0082, -0.0031, -0.0078, -0.0041,  0.0061,  0.0044, -0.0049, -0.0050,\n",
       "                      -0.0051,  0.0073, -0.0049,  0.0062,  0.0053,  0.0092,  0.0058,  0.0051,\n",
       "                       0.0064,  0.0059,  0.0053, -0.0039, -0.0097,  0.0067, -0.0043,  0.0057,\n",
       "                      -0.0057, -0.0035,  0.0098, -0.0057, -0.0030,  0.0071,  0.0088, -0.0056,\n",
       "                       0.0086, -0.0044, -0.0013, -0.0067,  0.0080,  0.0082,  0.0074,  0.0113,\n",
       "                      -0.0062, -0.0045,  0.0072,  0.0057, -0.0052,  0.0069,  0.0062, -0.0075,\n",
       "                       0.0107, -0.0043, -0.0125,  0.0054, -0.0060,  0.0066, -0.0092,  0.0066,\n",
       "                      -0.0065,  0.0103, -0.0060,  0.0052, -0.0048,  0.0100, -0.0068,  0.0087,\n",
       "                       0.0069,  0.0084, -0.0122,  0.0078, -0.0042, -0.0105,  0.0057,  0.0007,\n",
       "                      -0.0038, -0.0048, -0.0055, -0.0056,  0.0070, -0.0081, -0.0016, -0.0066,\n",
       "                      -0.0097,  0.0030, -0.0145, -0.0084,  0.0081, -0.0063,  0.0024, -0.0128,\n",
       "                      -0.0036,  0.0034,  0.0056, -0.0059,  0.0115, -0.0038, -0.0076,  0.0043,\n",
       "                       0.0031, -0.0064, -0.0077,  0.0060,  0.0044,  0.0049, -0.0067, -0.0039,\n",
       "                       0.0101, -0.0001, -0.0091, -0.0047, -0.0053,  0.0035, -0.0049, -0.0075,\n",
       "                      -0.0042, -0.0059, -0.0059,  0.0077, -0.0067,  0.0014,  0.0051, -0.0040,\n",
       "                       0.0067,  0.0030,  0.0094, -0.0056, -0.0079, -0.0089, -0.0047, -0.0022,\n",
       "                      -0.0054,  0.0056,  0.0065, -0.0003, -0.0067,  0.0064,  0.0044, -0.0066,\n",
       "                      -0.0076,  0.0057,  0.0075,  0.0058,  0.0088,  0.0045,  0.0104, -0.0059,\n",
       "                      -0.0059, -0.0088, -0.0061,  0.0067, -0.0040, -0.0053, -0.0067, -0.0114,\n",
       "                       0.0042,  0.0092, -0.0055,  0.0072, -0.0065, -0.0055, -0.0051, -0.0084,\n",
       "                       0.0066, -0.0097, -0.0048,  0.0040, -0.0069, -0.0073, -0.0066, -0.0066,\n",
       "                      -0.0085,  0.0029, -0.0023,  0.0044,  0.0072, -0.0079, -0.0034,  0.0056,\n",
       "                       0.0058, -0.0070,  0.0090,  0.0054,  0.0040, -0.0111, -0.0031,  0.0055,\n",
       "                      -0.0009, -0.0122, -0.0072, -0.0055,  0.0081, -0.0092, -0.0076,  0.0079,\n",
       "                       0.0069,  0.0061,  0.0013,  0.0118,  0.0088, -0.0041,  0.0081,  0.0048,\n",
       "                      -0.0054,  0.0059, -0.0023,  0.0062,  0.0065,  0.0084,  0.0016,  0.0067,\n",
       "                       0.0070,  0.0069, -0.0052,  0.0017, -0.0113, -0.0052, -0.0045, -0.0053,\n",
       "                       0.0092, -0.0091,  0.0084, -0.0057,  0.0119,  0.0046,  0.0055, -0.0071],\n",
       "                     device='cuda:0')),\n",
       "             ('decoder.layers.1.norm3.weight',\n",
       "              tensor([1.0537, 1.0846, 1.0721, 1.0554, 1.0543, 1.0639, 1.0622, 1.0609, 1.0653,\n",
       "                      1.0532, 1.0689, 1.0521, 1.0698, 1.0702, 1.0549, 1.0636, 1.0793, 1.0783,\n",
       "                      1.0578, 1.0735, 1.0511, 1.0532, 1.0728, 1.0665, 1.0727, 1.0625, 1.0622,\n",
       "                      1.0594, 1.0635, 1.0643, 1.0561, 1.0606, 1.0618, 1.0584, 1.0668, 1.0500,\n",
       "                      1.0534, 1.0466, 1.0564, 1.0705, 1.0576, 1.0643, 1.0553, 1.0618, 1.0586,\n",
       "                      1.0625, 1.0531, 1.0592, 1.0629, 1.0537, 1.0542, 1.0526, 1.0849, 1.0562,\n",
       "                      1.0571, 1.0564, 1.0645, 1.0573, 1.0687, 1.0739, 1.0693, 1.0572, 1.0681,\n",
       "                      1.0647, 1.0689, 1.0490, 1.0583, 1.0742, 1.0610, 1.0644, 1.0635, 1.0734,\n",
       "                      1.0647, 1.0540, 1.0612, 1.0598, 1.0635, 1.0682, 1.0648, 1.0723, 1.0691,\n",
       "                      1.0579, 1.0689, 1.0763, 1.0611, 1.0646, 1.0717, 1.0575, 1.0586, 1.0784,\n",
       "                      1.0710, 1.0616, 1.0522, 1.0727, 1.0686, 1.0823, 1.0671, 1.0640, 1.0667,\n",
       "                      1.0639, 1.0818, 1.0662, 1.0624, 1.0592, 1.0570, 1.0630, 1.0605, 1.0682,\n",
       "                      1.0586, 1.0708, 1.0608, 1.0531, 1.0677, 1.0700, 1.0763, 1.0648, 1.0743,\n",
       "                      1.0605, 1.0611, 1.0834, 1.0578, 1.0582, 1.0472, 1.0568, 1.0772, 1.0681,\n",
       "                      1.0566, 1.0520, 1.0646, 1.0509, 1.0587, 1.0551, 1.0568, 1.0598, 1.0701,\n",
       "                      1.0568, 1.0591, 1.0701, 1.0664, 1.0542, 1.0556, 1.0539, 1.0551, 1.0621,\n",
       "                      1.0902, 1.0553, 1.0648, 1.0676, 1.0653, 1.0784, 1.0806, 1.0615, 1.0623,\n",
       "                      1.0727, 1.0716, 1.0567, 1.0832, 1.0624, 1.0510, 1.0620, 1.0611, 1.0540,\n",
       "                      1.0790, 1.0550, 1.0591, 1.0639, 1.0502, 1.0529, 1.0681, 1.0634, 1.0814,\n",
       "                      1.0646, 1.0738, 1.0718, 1.0883, 1.0584, 1.0845, 1.0785, 1.0642, 1.0640,\n",
       "                      1.0553, 1.0513, 1.0661, 1.0753, 1.0648, 1.0842, 1.0576, 1.0858, 1.0833,\n",
       "                      1.0613, 1.0569, 1.0662, 1.0700, 1.0561, 1.0561, 1.0692, 1.0637, 1.0716,\n",
       "                      1.0640, 1.0629, 1.0642, 1.0758, 1.0598, 1.0598, 1.0742, 1.0692, 1.0592,\n",
       "                      1.0727, 1.0518, 1.0582, 1.0670, 1.0573, 1.0635, 1.0753, 1.0716, 1.0544,\n",
       "                      1.0823, 1.0805, 1.0740, 1.0538, 1.0552, 1.0848, 1.0823, 1.0631, 1.0561,\n",
       "                      1.0532, 1.0599, 1.0603, 1.0722, 1.0680, 1.0663, 1.0743, 1.0810, 1.0590,\n",
       "                      1.0791, 1.0524, 1.0533, 1.0586, 1.0653, 1.0599, 1.0650, 1.0612, 1.0813,\n",
       "                      1.0746, 1.0748, 1.0495, 1.0766, 1.0590, 1.0724, 1.0628, 1.0654, 1.0606,\n",
       "                      1.0733, 1.0613, 1.0527, 1.0597], device='cuda:0')),\n",
       "             ('decoder.layers.1.norm3.bias',\n",
       "              tensor([ 0.0430, -0.0740,  0.0684, -0.0069, -0.0539, -0.0167, -0.0621,  0.0590,\n",
       "                       0.0575,  0.0537, -0.0557,  0.0517, -0.0026, -0.0664,  0.0386, -0.0586,\n",
       "                      -0.0374, -0.0631,  0.0531, -0.0640,  0.0504,  0.0457,  0.0605,  0.0524,\n",
       "                       0.0670, -0.0488,  0.0554, -0.0497, -0.0491,  0.0090,  0.0295, -0.0537,\n",
       "                       0.0583, -0.0459, -0.0376, -0.0481,  0.0537,  0.0451, -0.0484, -0.0653,\n",
       "                      -0.0527,  0.0441, -0.0505,  0.0620,  0.0529,  0.0632,  0.0505,  0.0492,\n",
       "                       0.0528,  0.0452,  0.0507, -0.0483, -0.0725,  0.0549, -0.0462,  0.0508,\n",
       "                      -0.0502, -0.0367,  0.0676, -0.0653, -0.0502,  0.0518,  0.0611, -0.0534,\n",
       "                       0.0575, -0.0416, -0.0105, -0.0622,  0.0558,  0.0632,  0.0610,  0.0680,\n",
       "                      -0.0597, -0.0522,  0.0501,  0.0479, -0.0543,  0.0557,  0.0530, -0.0606,\n",
       "                       0.0666, -0.0485, -0.0637,  0.0542, -0.0613,  0.0569, -0.0668,  0.0521,\n",
       "                      -0.0543,  0.0675, -0.0624,  0.0465, -0.0433,  0.0655, -0.0559,  0.0679,\n",
       "                       0.0616,  0.0563, -0.0572,  0.0638, -0.0502, -0.0611,  0.0570,  0.0132,\n",
       "                      -0.0375, -0.0546, -0.0528, -0.0488,  0.0555, -0.0601, -0.0080, -0.0516,\n",
       "                      -0.0633,  0.0445, -0.0662, -0.0593,  0.0494, -0.0546,  0.0080, -0.0674,\n",
       "                      -0.0481,  0.0425,  0.0484, -0.0501,  0.0690, -0.0603, -0.0510,  0.0452,\n",
       "                       0.0395, -0.0491, -0.0555,  0.0533,  0.0499,  0.0522, -0.0577, -0.0395,\n",
       "                       0.0581,  0.0201, -0.0611, -0.0449, -0.0505,  0.0460, -0.0438, -0.0570,\n",
       "                      -0.0693, -0.0439, -0.0565,  0.0639, -0.0343,  0.0533,  0.0562, -0.0384,\n",
       "                       0.0487,  0.0479,  0.0623, -0.0408, -0.0720, -0.0556, -0.0473, -0.0154,\n",
       "                      -0.0528,  0.0529,  0.0617, -0.0017, -0.0558,  0.0558,  0.0507, -0.0510,\n",
       "                      -0.0622,  0.0587,  0.0641,  0.0515,  0.0643,  0.0620,  0.0585, -0.0458,\n",
       "                      -0.0585, -0.0661, -0.0602,  0.0597, -0.0467, -0.0403, -0.0557, -0.0632,\n",
       "                       0.0171,  0.0745, -0.0529,  0.0711, -0.0625, -0.0481, -0.0490, -0.0416,\n",
       "                       0.0203, -0.0566, -0.0510,  0.0593, -0.0576, -0.0565, -0.0577, -0.0536,\n",
       "                      -0.0613,  0.0353, -0.0371,  0.0491,  0.0670, -0.0656, -0.0453,  0.0618,\n",
       "                       0.0518, -0.0558,  0.0613,  0.0476,  0.0396, -0.0679, -0.0457,  0.0464,\n",
       "                      -0.0189, -0.0677, -0.0622, -0.0540,  0.0522, -0.0686, -0.0716,  0.0572,\n",
       "                       0.0533,  0.0528, -0.0074,  0.0636,  0.0639, -0.0332,  0.0609,  0.0462,\n",
       "                      -0.0661,  0.0565, -0.0353,  0.0526,  0.0504,  0.0599,  0.0146,  0.0572,\n",
       "                       0.0542,  0.0559, -0.0432,  0.0247, -0.0647, -0.0456, -0.0553, -0.0527,\n",
       "                       0.0610, -0.0602,  0.0602, -0.0464,  0.0592,  0.0555,  0.0483, -0.0561],\n",
       "                     device='cuda:0')),\n",
       "             ('linear.weight',\n",
       "              tensor([[ 0.0735,  0.0061, -0.0254,  ...,  0.0666,  0.0641, -0.0493],\n",
       "                      [-0.0350,  0.1070, -0.0877,  ...,  0.0234,  0.0095,  0.0349],\n",
       "                      [-0.0245,  0.0756, -0.0906,  ...,  0.0044, -0.0508,  0.0684],\n",
       "                      ...,\n",
       "                      [-0.0675,  0.0862, -0.0800,  ..., -0.0123,  0.0026,  0.0555],\n",
       "                      [-0.0190,  0.0260, -0.0015,  ..., -0.0051, -0.0375, -0.0247],\n",
       "                      [-0.0609, -0.0268, -0.0723,  ..., -0.0763, -0.0411,  0.0667]],\n",
       "                     device='cuda:0')),\n",
       "             ('linear.bias',\n",
       "              tensor([ 0.0121, -0.0007, -0.0463,  ...,  0.0311, -0.0223, -0.0158],\n",
       "                     device='cuda:0'))])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "228915a2-253f-4bc2-9ea2-5fba6a16f8f8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8355403e-afac-4682-9ed3-3c5e6db18b7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch['decoder_input'].to(device)\n",
    "batch['desired_output'].to(device)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Pytorch",
   "language": "python",
   "name": "env_torch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
