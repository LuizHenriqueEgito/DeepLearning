{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "e30ae4b0-880d-4c1b-a3aa-528c35f1845f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "f30a5af9-11cd-4ad7-9deb-75209b39c170",
   "metadata": {},
   "outputs": [],
   "source": [
    "from multi_head_attention import MultiHeadAttention\n",
    "from feed_forward import FeedForward\n",
    "from sinusoidal_positional_encoding import PositionalEncoding\n",
    "from embedding import EmbeddingModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "8f1444d4-7706-4c16-9d84-44f83d3b2dbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncoderBlock(nn.Module):\n",
    "    def __init__(\n",
    "        self, \n",
    "        d_model: int, \n",
    "        n_heads: int,\n",
    "        hidden_size: int,\n",
    "        dropout: float = 0.1\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.mha = MultiHeadAttention(d_model, n_heads)\n",
    "        self.feed_forward = FeedForward(d_model, hidden_size, dropout)\n",
    "\n",
    "        self.norm_mha = nn.LayerNorm(normalized_shape=d_model)\n",
    "        self.norm_feed_forward = nn.LayerNorm(normalized_shape=d_model)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.norm_mha(x + self.mha(x, x, x))  # add & norm\n",
    "        x = self.norm_feed_forward(x + self.feed_forward(x))  # add & norm\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "a141e030-a855-45ff-91d8-382ef02b36f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransformerEncoder(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        vocab_size: int,\n",
    "        seq_len: int,\n",
    "        d_model: int,\n",
    "        nx: int,\n",
    "        n_heads: int,\n",
    "        hidden_size: int,\n",
    "        dropout: float = 0.1\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.embedding = nn.Sequential(\n",
    "            EmbeddingModel(d_model, vocab_size),\n",
    "            PositionalEncoding(d_model, seq_len, dropout=0.0)\n",
    "        )\n",
    "        self.encoder_blocks = nn.ModuleList(\n",
    "            [\n",
    "                EncoderBlock(\n",
    "                    d_model,\n",
    "                    n_heads,\n",
    "                    hidden_size,\n",
    "                    dropout=dropout,\n",
    "                )\n",
    "                for _ in range(nx)\n",
    "            ]\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.embedding(x)\n",
    "        for block in self.encoder_blocks:\n",
    "            x = block(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "379ea6e0-6a5e-4897-836e-158607ccdf13",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.rand((2, 3)) * 100\n",
    "x = x.int()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "762ce0f7-bebc-43fb-bf7a-1d7d2d2ca7af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "entrada teste\n",
      "tensor([[90, 75, 94],\n",
      "        [88, 54, 68]], dtype=torch.int32)\n",
      "Shape entrada: torch.Size([2, 3])\n",
      "------------------------------\n"
     ]
    }
   ],
   "source": [
    "print(f\"entrada teste\")\n",
    "print(x)\n",
    "print(f\"Shape entrada: {x.shape}\")\n",
    "print(\"-\" * 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "582a06ec-f73a-49c7-9ed0-e1d87f02fba6",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = TransformerEncoder(\n",
    "    vocab_size=1000,\n",
    "    seq_len=10,\n",
    "    d_model=6,\n",
    "    nx=2,\n",
    "    n_heads=2,\n",
    "    hidden_size=2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "da0ddf21-3248-4c4f-8b60-4589c5178777",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_encoder = encoder(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "aa050764-359b-4e97-a3e6-2c2275010abe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape saida torch.Size([2, 3, 6])\n"
     ]
    }
   ],
   "source": [
    "print(f\"Shape saida {x_encoder.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "8f1de52b-7d53-4049-984f-b42c4f05e537",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0.8063,  0.0559, -1.1969,  1.6378, -1.0891, -0.2140],\n",
       "         [ 0.7452, -1.7216,  0.1039, -0.4154, -0.2128,  1.5007],\n",
       "         [ 1.1609, -1.5272,  0.4636,  0.6909, -1.2055,  0.4173]],\n",
       "\n",
       "        [[-1.1207, -0.4452, -0.0639,  1.4266, -1.0133,  1.2165],\n",
       "         [-0.7809, -1.0704,  1.7244, -0.2529, -0.5634,  0.9431],\n",
       "         [ 0.3675, -1.5602,  1.1221,  0.6448, -1.1790,  0.6048]]],\n",
       "       grad_fn=<NativeLayerNormBackward0>)"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_encoder"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5323c504-43a0-4be6-902b-9909f8d3e40d",
   "metadata": {},
   "source": [
    "# Criando o EncoderDataset para o pré treinamento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "746846b6-0a19-4106-a9f6-54dfaa5783a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tokenizer.Tokenizer import TokenizerImDB\n",
    "from tokenizer.Tokenizer import SpecialTokensInt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5cd3c9f4-f3ac-4302-af6b-24e90e97fd33",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['PAD', 'CLS', 'UNK', 'MASK', 'SOS', 'EOS']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SpecialTokensInt.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "922c8967-9502-4c34-8f14-d73c950e810b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "baa8900a-ca3f-48bf-a61e-032719d0ef21",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3cdb6fc5-bb73-47e4-85e3-fd747310940b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ebe451c2-03d6-4dff-8239-eac8e1e25de5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text_en</th>\n",
       "      <th>text_pt</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Once again Mr. Costner has dragged out a movie...</td>\n",
       "      <td>Mais uma vez, o Sr. Costner arrumou um filme p...</td>\n",
       "      <td>neg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>This is an example of why the majority of acti...</td>\n",
       "      <td>Este é um exemplo do motivo pelo qual a maiori...</td>\n",
       "      <td>neg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>First of all I hate those moronic rappers, who...</td>\n",
       "      <td>Primeiro de tudo eu odeio esses raps imbecis, ...</td>\n",
       "      <td>neg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Not even the Beatles could write songs everyon...</td>\n",
       "      <td>Nem mesmo os Beatles puderam escrever músicas ...</td>\n",
       "      <td>neg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Brass pictures movies is not a fitting word fo...</td>\n",
       "      <td>Filmes de fotos de latão não é uma palavra apr...</td>\n",
       "      <td>neg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49454</th>\n",
       "      <td>49456</td>\n",
       "      <td>Seeing as the vote average was pretty low, and...</td>\n",
       "      <td>Como a média de votos era muito baixa, e o fat...</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49455</th>\n",
       "      <td>49457</td>\n",
       "      <td>The plot had some wretched, unbelievable twist...</td>\n",
       "      <td>O enredo teve algumas reviravoltas infelizes e...</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49456</th>\n",
       "      <td>49458</td>\n",
       "      <td>I am amazed at how this movieand most others h...</td>\n",
       "      <td>Estou espantado com a forma como este filme e ...</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49457</th>\n",
       "      <td>49459</td>\n",
       "      <td>A Christmas Together actually came before my t...</td>\n",
       "      <td>A Christmas Together realmente veio antes do m...</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49458</th>\n",
       "      <td>49460</td>\n",
       "      <td>Working-class romantic drama from director Mar...</td>\n",
       "      <td>O drama romântico da classe trabalhadora do di...</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>49459 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          id                                            text_en  \\\n",
       "0          1  Once again Mr. Costner has dragged out a movie...   \n",
       "1          2  This is an example of why the majority of acti...   \n",
       "2          3  First of all I hate those moronic rappers, who...   \n",
       "3          4  Not even the Beatles could write songs everyon...   \n",
       "4          5  Brass pictures movies is not a fitting word fo...   \n",
       "...      ...                                                ...   \n",
       "49454  49456  Seeing as the vote average was pretty low, and...   \n",
       "49455  49457  The plot had some wretched, unbelievable twist...   \n",
       "49456  49458  I am amazed at how this movieand most others h...   \n",
       "49457  49459  A Christmas Together actually came before my t...   \n",
       "49458  49460  Working-class romantic drama from director Mar...   \n",
       "\n",
       "                                                 text_pt sentiment  \n",
       "0      Mais uma vez, o Sr. Costner arrumou um filme p...       neg  \n",
       "1      Este é um exemplo do motivo pelo qual a maiori...       neg  \n",
       "2      Primeiro de tudo eu odeio esses raps imbecis, ...       neg  \n",
       "3      Nem mesmo os Beatles puderam escrever músicas ...       neg  \n",
       "4      Filmes de fotos de latão não é uma palavra apr...       neg  \n",
       "...                                                  ...       ...  \n",
       "49454  Como a média de votos era muito baixa, e o fat...       pos  \n",
       "49455  O enredo teve algumas reviravoltas infelizes e...       pos  \n",
       "49456  Estou espantado com a forma como este filme e ...       pos  \n",
       "49457  A Christmas Together realmente veio antes do m...       pos  \n",
       "49458  O drama romântico da classe trabalhadora do di...       pos  \n",
       "\n",
       "[49459 rows x 4 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file = Path('../../data/imdb-reviews-pt-br.csv')\n",
    "pd.read_csv(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "c7ef5a30-e90c-4d27-8eef-529073a72f82",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[13344]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer_path_pt = Path('tokenizer/artifacts/tokenizer_pt.json')\n",
    "\n",
    "tokenizer_pt = TokenizerImDB(vocab_size=30_000, tokenizer_path=tokenizer_path_pt)\n",
    "\n",
    "tokenizer_pt.encoder('ola')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "db414b0c-3a0a-41c5-9bf8-bbf5e9d9c3c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncoderPreTrainDataset(Dataset):\n",
    "    def __init__(\n",
    "        self,\n",
    "        tokenizer: TokenizerImDB,\n",
    "        seq_len: int,\n",
    "        mask_prob: float,\n",
    "        file_dataset: Path,\n",
    "        language: str,\n",
    "        mask_token_id: int = SpecialTokensInt.MASK.value,\n",
    "        pad_token_id: int = SpecialTokensInt.PAD.value,\n",
    "        special_tokens: list[int] = SpecialTokensInt.tolist(),\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.tokenizer = tokenizer\n",
    "        self.seq_len = seq_len\n",
    "        self.mask_prob = mask_prob\n",
    "        self.mask_token_id = mask_token_id\n",
    "        self.pad_token_id = pad_token_id\n",
    "        self.special_tokens = special_tokens\n",
    "        self.vocab_size = tokenizer.vocab_size\n",
    "        self.dataset = pd.read_csv(file_dataset)[f'text_{language}']\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.dataset)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        text = self.dataset.iloc[index]\n",
    "        text_tokens = self.tokenizer.encoder(text)\n",
    "        if len(text_tokens) < self.seq_len:\n",
    "            diff = self.seq_len - len(text_tokens)\n",
    "            text_tokens += [self.pad_token_id for _ in range(diff)]\n",
    "        elif len(text_tokens) > self.seq_len:\n",
    "            text_tokens = text_tokens[: self.seq_len]\n",
    "\n",
    "        text_tokens = torch.tensor(text_tokens)\n",
    "        probs = torch.rand(text_tokens.shape)  # cria uma matriz de probas\n",
    "        mask = (probs < self.mask_prob) * (text_tokens != self.pad_token_id)  # [True * True = 1], [True * False = 0], [False, False = 0]\n",
    "        for special_token in self.special_tokens:\n",
    "            mask = mask * (text_tokens != special_token)\n",
    "\n",
    "        masked = torch.clone(text_tokens).type(torch.int)\n",
    "        masked_ids = torch.flatten(mask.nonzero())  # -> retorna os ids que foram mascarados\n",
    "        masked_ids_list = masked_ids.tolist()\n",
    "        original_masked_tokens = text_tokens[masked_ids_list]  # -> retorna os verdadeiroas ids antes de serem substituidos por MASK\n",
    "        replace_masked_tokens = self.generate_mlm_tokens(original_masked_tokens.tolist())\n",
    "        masked[masked_ids_list] = replace_masked_tokens\n",
    "        return masked, text_tokens, mask\n",
    "\n",
    "    def generate_mlm_tokens(self, original_tokens: list[int]):\n",
    "        len_original_tokens = len(original_tokens)\n",
    "        replace_tokens = torch.rand(len_original_tokens)\n",
    "        for i in range(len_original_tokens):\n",
    "            if replace_tokens[i] <= 0.8:  # se esses caras forem menores do que 80% vira MASK\n",
    "                replace_tokens[i] = self.mask_token_id\n",
    "            elif 0.8 < replace_tokens[i] <= 0.9:\n",
    "                replace_tokens[i] = np.random.randint(self.vocab_size)\n",
    "            else:\n",
    "                replace_tokens[i] = original_tokens[i]\n",
    "\n",
    "        return replace_tokens.type(torch.int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "2f97f5c6-75a0-4ba3-b6ab-de6d45c8f902",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = EncoderPreTrainDataset(\n",
    "    tokenizer=tokenizer_pt,\n",
    "    seq_len=124,\n",
    "    mask_prob=0.15,\n",
    "    file_dataset=Path('../../data/imdb-reviews-pt-br.csv'),\n",
    "    language='pt'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "c88680af-13f5-4f4d-af96-638998d8ee4e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "49459"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "54d9f5ff-6ca0-4a68-a72b-72dde1004f47",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([ 1336,   191,   376,    16,   140,     3,     3, 15555,  6777,  2437,\n",
       "           166,   176,   215,   265,   258,     3,   195,     3,   140,  2068,\n",
       "           125,   346,    18,   537,   125,    57,   476,   925,   125,   619,\n",
       "          2103,  1376,    49,   188,  1073,   132,  6898,   206,   682,     3,\n",
       "           476,  1906,   300,   125,   265,     3,    16,   199,   833,   164,\n",
       "             3,    59,   190, 10662,   167,   941,   295,   505,     3,   124,\n",
       "           935,   132,   206,   125,    63,   343,  4952,   206,  1868,   125,\n",
       "           346,     3,   122,   140,   617,  1470,  2366,   122,   125,  7490,\n",
       "          1934,   206,     3,   125,   333,    16,   122,   513,  4777,   456,\n",
       "           125,   265,   258,  1514,    16,   358,   199,   164,   143,    59,\n",
       "         23809,  6475,    18,   140,   617,   167,   140,   393,  9554,   125,\n",
       "          2528,   437,  4303,   122,   125,   265,  5765,   122, 17111,   434,\n",
       "           819,   149,    16, 18725], dtype=torch.int32),\n",
       " tensor([ 1336,   191,   376,    16,   140,  1821,    18, 15555,  6777,  2437,\n",
       "           166,   176,   215,   265,   258,   449,   195,   150,   140,  2068,\n",
       "           125,   346,    18,   537,   125,    57,   476,   925,   125,   619,\n",
       "          2103,  1376,    49,   188,  1073,   132,  6898,   206,   682,    16,\n",
       "           476,  1906,   300,   125,   265,  3339,    16,   199,   833,   164,\n",
       "           143,    59,   190, 10662,   167,   941,   295,   505,    18,   124,\n",
       "           935,   132,   206,   125,    63,   343,  4952,   206,  1868,   125,\n",
       "           346,    16,   122,   140,   617,  1470,  2366,   122,   125,  7490,\n",
       "          1934,   206,   947,   125,   333,    16,   122,   513,  4777,   456,\n",
       "           125,   265,   258,  1514,    16,   358,   199,   164,   143,    59,\n",
       "           190,  6475,    18,   140,   617,   167,   140,   393,  9554,   125,\n",
       "          2528,   437,  4303,   122,   125,   265,  5765,   122,  1103,   434,\n",
       "           819,   149,    16, 18725]),\n",
       " tensor([False, False, False, False, False,  True,  True, False, False, False,\n",
       "         False, False, False, False, False,  True, False,  True, False, False,\n",
       "         False, False, False, False, False, False, False, False, False, False,\n",
       "         False, False, False, False, False, False, False, False, False,  True,\n",
       "         False, False, False, False, False,  True, False, False, False, False,\n",
       "          True, False, False, False, False, False,  True, False,  True, False,\n",
       "         False, False, False, False, False, False, False, False, False, False,\n",
       "         False,  True, False, False, False, False, False, False, False, False,\n",
       "         False, False,  True, False, False, False, False, False, False, False,\n",
       "         False, False, False, False, False, False, False, False, False, False,\n",
       "          True, False, False, False, False, False, False, False, False, False,\n",
       "         False, False, False, False, False, False, False, False,  True, False,\n",
       "         False, False, False, False]))"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "ca6e671b-a422-43e5-9843-8ab0d72f5748",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncoderMLM(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        vocab_size: int,\n",
    "        seq_len: int,\n",
    "        d_model: int,\n",
    "        nx: int,\n",
    "        n_heads: int,\n",
    "        hidden_size: int,\n",
    "        dropout: float = 0.1\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.d_model = d_model\n",
    "        self.encoder = TransformerEncoder(\n",
    "            vocab_size=vocab_size,\n",
    "            seq_len=seq_len,\n",
    "            d_model=d_model,\n",
    "            nx=nx,\n",
    "            n_heads=n_heads,\n",
    "            hidden_size=hidden_size,\n",
    "            dropout=0.1\n",
    "        )\n",
    "\n",
    "        self.mlm_head = nn.Linear(d_model, vocab_size)\n",
    "\n",
    "    def forward(self, x, mask):\n",
    "        # Flattens the masked ID\n",
    "        masked_ids = torch.flatten(mask.reshape((-1,)).nonzero())\n",
    "        # Encoder output\n",
    "        last_hidden_states = self.encoder(x)\n",
    "        \n",
    "        # Validations\n",
    "        assert mask.numel() == last_hidden_states.shape[0] * last_hidden_states.shape[1], \\\n",
    "            f\"Mismatch: mask {mask.numel()} vs encoder {last_hidden_states.numel() // self.d_model}\"\n",
    "        \n",
    "        # Flatten the hidden states\n",
    "        all_hidden_states = last_hidden_states.reshape(-1, self.d_model)\n",
    "        \n",
    "        # Ensure valid indices\n",
    "        masked_ids = masked_ids[masked_ids < all_hidden_states.size(0)]\n",
    "        \n",
    "        # Get only the masked hidden states\n",
    "        masked_hidden_states = all_hidden_states[masked_ids, :]\n",
    "        \n",
    "        # Predicts only the masked tokens\n",
    "        logits = self.mlm_head(masked_hidden_states)\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "ab701960-0f84-40ad-967f-6577d53cd3f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "modelo = EncoderMLM(\n",
    "    vocab_size=tokenizer_pt.vocab_size,\n",
    "    seq_len=124,\n",
    "    d_model=16,\n",
    "    nx=3,\n",
    "    n_heads=4,\n",
    "    hidden_size=248,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "a64e1068-f43a-4a90-85d4-88db10bc5094",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-1.4128e+00,  1.3957e-01, -3.0033e-01, -8.1843e-02, -3.6328e-01,\n",
       "          -1.2655e+00,  1.9240e+00, -4.2766e-01,  1.6582e-01,  1.4895e+00,\n",
       "          -4.3955e-01,  1.4440e+00, -1.3942e+00, -1.5491e-01, -5.4119e-01,\n",
       "           1.2183e+00],\n",
       "         [-1.3192e+00,  1.0264e+00,  2.3589e-01,  2.0151e+00,  3.6934e-01,\n",
       "           1.1888e+00, -2.1329e+00, -4.6241e-01, -1.1260e-01, -1.2224e+00,\n",
       "           2.4236e-01,  1.3585e-01, -1.8543e-01,  6.6822e-01,  3.2967e-01,\n",
       "          -7.7669e-01],\n",
       "         [-3.9279e-01, -2.1078e+00,  1.1043e-01, -4.1354e-01, -6.4120e-01,\n",
       "           2.3036e+00,  2.7222e-01,  1.0344e+00,  6.0608e-01, -3.2543e-01,\n",
       "          -8.3260e-01,  1.5305e+00, -3.2007e-01,  1.0080e-01, -8.5521e-01,\n",
       "          -6.9399e-02]],\n",
       "\n",
       "        [[ 5.2024e-01, -5.6726e-02,  3.2182e-01,  9.3862e-01, -1.3859e+00,\n",
       "           1.6053e-02, -1.4036e-01,  9.6060e-01, -1.2677e+00,  1.0706e+00,\n",
       "           1.1306e+00,  8.1581e-01, -2.2246e+00,  3.2285e-01,  3.8517e-01,\n",
       "          -1.4070e+00],\n",
       "         [-5.0584e-01,  3.4595e-01,  1.9025e+00,  9.9651e-01,  6.6152e-01,\n",
       "          -1.3811e+00, -2.2290e+00,  5.6613e-02, -7.6092e-01, -3.5748e-01,\n",
       "          -1.2158e+00,  7.3134e-01,  5.6217e-01,  1.2660e-01,  7.2552e-01,\n",
       "           3.4140e-01],\n",
       "         [-1.6367e+00,  2.3440e-01,  3.7139e-01,  1.4642e+00,  6.9628e-01,\n",
       "          -5.1142e-04,  4.2685e-01,  6.4136e-01,  3.6871e-01, -1.3134e-01,\n",
       "          -1.9157e+00,  1.6309e+00, -5.4091e-01,  4.7508e-01, -1.6474e+00,\n",
       "          -4.3666e-01]]], grad_fn=<NativeLayerNormBackward0>)"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modelo.encoder(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "1ef084fc-ee21-4d47-8855-75103b8c493d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pq o adamW\n",
    "optimizer = torch.optim.AdamW(modelo.parameters(), lr=5e-5, weight_decay=1e-5)\n",
    "dataloader = torch.utils.data.DataLoader(\n",
    "    dataset, num_workers=8, shuffle=True, batch_size=4\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "ef07bdf0-0e9a-4e66-aed3-7c22787e2997",
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "Mismatch: mask 496 vs encoder 6",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[121], line 4\u001b[0m\n\u001b[1;32m      2\u001b[0m masked_ids \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mflatten(masked_mask\u001b[38;5;241m.\u001b[39mreshape((\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m,))\u001b[38;5;241m.\u001b[39mnonzero())\n\u001b[1;32m      3\u001b[0m labels \u001b[38;5;241m=\u001b[39m y\u001b[38;5;241m.\u001b[39mreshape((\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m,))[masked_ids]\n\u001b[0;32m----> 4\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[43mmodelo\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmasked_mask\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      5\u001b[0m loss \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mnn\u001b[38;5;241m.\u001b[39mfunctional\u001b[38;5;241m.\u001b[39mcross_entropy(out, labels)\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28mprint\u001b[39m(loss\u001b[38;5;241m.\u001b[39mitems())\n",
      "File \u001b[0;32m/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[117], line 33\u001b[0m, in \u001b[0;36mEncoderMLM.forward\u001b[0;34m(self, x, mask)\u001b[0m\n\u001b[1;32m     30\u001b[0m last_hidden_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mencoder(x)\n\u001b[1;32m     32\u001b[0m \u001b[38;5;66;03m# Validations\u001b[39;00m\n\u001b[0;32m---> 33\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m mask\u001b[38;5;241m.\u001b[39mnumel() \u001b[38;5;241m==\u001b[39m last_hidden_states\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m*\u001b[39m last_hidden_states\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m], \\\n\u001b[1;32m     34\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMismatch: mask \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmask\u001b[38;5;241m.\u001b[39mnumel()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m vs encoder \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlast_hidden_states\u001b[38;5;241m.\u001b[39mnumel()\u001b[38;5;250m \u001b[39m\u001b[38;5;241m/\u001b[39m\u001b[38;5;241m/\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39md_model\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     36\u001b[0m \u001b[38;5;66;03m# Flatten the hidden states\u001b[39;00m\n\u001b[1;32m     37\u001b[0m all_hidden_states \u001b[38;5;241m=\u001b[39m last_hidden_states\u001b[38;5;241m.\u001b[39mreshape(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39md_model)\n",
      "\u001b[0;31mAssertionError\u001b[0m: Mismatch: mask 496 vs encoder 6"
     ]
    }
   ],
   "source": [
    "for X, y, masked_mask in dataloader:\n",
    "    masked_ids = torch.flatten(masked_mask.reshape((-1,)).nonzero())\n",
    "    labels = y.reshape((-1,))[masked_ids]\n",
    "    out = modelo(x, masked_mask)\n",
    "    loss = torch.nn.functional.cross_entropy(out, labels)\n",
    "    print(loss.items())\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    optimizer.zero_grad(set_to_none=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2cc55f0-2ccb-4037-b411-834264a5b309",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
