{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "43cedfce-4d22-4ec0-9bcf-c7cf0d33e958",
   "metadata": {},
   "source": [
    "# Classic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fc081ef4-53eb-4b3a-846f-ab7970a0b087",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch import Tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1c094225-8134-40ab-ab20-ec5893cb6c6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class QKVMatrices(nn.Module):\n",
    "    def __init__(self, d_model: int):\n",
    "        super().__init__()\n",
    "        self.w_q = nn.Linear(d_model, d_model)\n",
    "        self.w_k = nn.Linear(d_model, d_model)\n",
    "        self.w_v = nn.Linear(d_model, d_model)\n",
    "\n",
    "    def forward(self, x) -> Tensor:\n",
    "        q = self.w_q(x)\n",
    "        k = self.w_k(x)\n",
    "        v = self.w_v(x)\n",
    "        return q, k, v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "f3a7c6bd-8f6b-4a51-9a15-963fe17870a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def attention(q, k, v) -> Tensor:\n",
    "    d_model = q.shape[-1]\n",
    "    k_t = k.transpose(-1, -2)\n",
    "    scores = (q @ k_t) / math.sqrt(d_model)\n",
    "    attention_weights = F.softmax(scores, dim=-1) @ v\n",
    "    return attention_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "b457077f-90c7-4580-8c7f-afc8cd9834ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.rand(2, 4, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "e16ee8b3-5fef-43a9-9b36-bdbc2e45ce1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "q, k, v = QKVMatrices(2)(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "c46c263c-d1a2-422c-9874-328f483f4b93",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-0.8103,  0.1402],\n",
       "         [-0.8005, -0.0514],\n",
       "         [-0.8954,  0.1716],\n",
       "         [-0.8005,  0.0955]],\n",
       "\n",
       "        [[-0.8227,  0.2479],\n",
       "         [-0.7278,  0.0112],\n",
       "         [-0.7923,  0.1930],\n",
       "         [-0.8169,  0.0800]]], grad_fn=<ViewBackward0>)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "adc97106-254d-4efe-bc73-68235abc7ae1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0.1049, -0.1987],\n",
       "         [ 0.1564, -0.4886],\n",
       "         [ 0.0665, -0.1348],\n",
       "         [ 0.1196, -0.2679]],\n",
       "\n",
       "        [[ 0.0735, -0.0345],\n",
       "         [ 0.1669, -0.4089],\n",
       "         [ 0.0982, -0.1229],\n",
       "         [ 0.1176, -0.2879]]], grad_fn=<ViewBackward0>)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "d0c52b21-5199-46a2-b522-b847d350474c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0.6289, 1.0547],\n",
       "         [0.6324, 0.9571],\n",
       "         [0.6069, 1.2646],\n",
       "         [0.6316, 1.0144]],\n",
       "\n",
       "        [[0.6251, 1.1256],\n",
       "         [0.6507, 0.8126],\n",
       "         [0.6332, 1.0336],\n",
       "         [0.6275, 1.0464]]], grad_fn=<ViewBackward0>)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "a3dc8301-bd83-40d1-93b7-f68d01cd014a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0.6247, 1.0760],\n",
       "         [0.6248, 1.0743],\n",
       "         [0.6247, 1.0765],\n",
       "         [0.6247, 1.0755]],\n",
       "\n",
       "        [[0.6338, 1.0093],\n",
       "         [0.6340, 1.0066],\n",
       "         [0.6338, 1.0087],\n",
       "         [0.6339, 1.0076]]], grad_fn=<UnsafeViewBackward0>)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attention(q, k, v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "9a361618-05a7-4838-a793-048119a1cc91",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class Attention(nn.Module): \n",
    "    \n",
    "    def __init__(self, d_model=2):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.d_model=d_model\n",
    "        self.W_q = nn.Linear(d_model, d_model, bias=False)\n",
    "        self.W_k = nn.Linear(d_model, d_model, bias=False)\n",
    "        self.W_v = nn.Linear(d_model, d_model, bias=False)\n",
    "        \n",
    "    def forward(self, encodings_for_q, encodings_for_k, encodings_for_v, mask=None):\n",
    "        q = self.W_q(encodings_for_q)\n",
    "        k = self.W_k(encodings_for_k)\n",
    "        v = self.W_v(encodings_for_v)\n",
    "        sims = torch.matmul(q, k.transpose(-1, -2))\n",
    "\n",
    "        scaled_sims = sims / torch.tensor(k.size(-1)**0.5)\n",
    "\n",
    "        if mask is not None:\n",
    "            scaled_sims = scaled_sims.masked_fill(mask=mask, value=-1e9)\n",
    "        attention_percents = F.softmax(scaled_sims, dim=-2)\n",
    "        attention_scores = torch.matmul(attention_percents, v)\n",
    "        \n",
    "        return attention_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "ebfdde44-3465-408a-bcb2-61176bf0e8b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.rand(1, 4, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "86815bb8-97c8-4b77-a3f5-4213bf8c3eaa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0.1266, -0.4618],\n",
       "         [ 0.1191, -0.4335],\n",
       "         [ 0.1269, -0.4630],\n",
       "         [ 0.1529, -0.5620]]], grad_fn=<UnsafeViewBackward0>)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Attention()(x, x, x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "9cbb9ff1-9600-4cde-8ab5-caf5ba1ca61b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiHeadAttention(nn.Module): \n",
    "    \n",
    "    def __init__(self, d_model: int =2, n_heads: int = 2):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.d_model = d_model\n",
    "        self.n_heads = n_heads\n",
    "        self.d_heads = d_model // n_heads\n",
    "\n",
    "        self.W_q = nn.Linear(d_model, d_model, bias=False)\n",
    "        self.W_k = nn.Linear(d_model, d_model, bias=False)\n",
    "        self.W_v = nn.Linear(d_model, d_model, bias=False)\n",
    "\n",
    "        self.W_z = nn.Linear(d_model, d_model, bias=False)\n",
    "\n",
    "    def pre_attention_reshape(self, x):\n",
    "        # [B, L, E] -> [B, H, L, HD]\n",
    "        B, L, E = x.shape  # B: batch size, L: SEQ_LEN, E: D_MODEL\n",
    "        x = x.contiguous().view(B, L, self.n_heads, self.d_heads)\n",
    "        x = x.transpose(1, 2)\n",
    "        return x\n",
    "\n",
    "    def post_attention_reshape(self, x):\n",
    "        # [B, H, L, HD] -> [B, L, E]\n",
    "        B, H, L, HD = x.shape  # B: batch size, H: N_HEADS, L: SEQ_LEN, HD: D_HEADS\n",
    "        x = x.transpose(2, 1)\n",
    "        x = x.contiguous().view((B, L, self.d_model))\n",
    "        return x\n",
    "        \n",
    "    def forward(self, encodings_for_q, encodings_for_k, encodings_for_v, mask=None):\n",
    "        q = self.pre_attention_reshape(self.W_q(encodings_for_q))\n",
    "        k = self.pre_attention_reshape(self.W_k(encodings_for_k))\n",
    "        v = self.pre_attention_reshape(self.W_v(encodings_for_v))\n",
    "        sims = torch.matmul(q, k.transpose(-1, -2))\n",
    "\n",
    "        scaled_sims = sims / torch.tensor(k.size(-1)**0.5)\n",
    "\n",
    "        if mask is not None:\n",
    "            scaled_sims = scaled_sims.masked_fill(mask=mask, value=-1e9)\n",
    "        attention_percents = F.softmax(scaled_sims, dim=-2)\n",
    "        attention_scores = torch.matmul(attention_percents, v)\n",
    "        \n",
    "        attention_scores = self.post_attention_reshape(attention_scores)\n",
    "        z = self.W_z(attention_scores)\n",
    "        \n",
    "        return z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "75671e17-014d-4812-8952-f430b95b224d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0.7326, 0.3260, 0.2582, 0.9637],\n",
       "         [0.7328, 0.7659, 0.9104, 0.0196],\n",
       "         [0.2067, 0.9213, 0.2886, 0.7394],\n",
       "         [0.9466, 0.4678, 0.6391, 0.6604],\n",
       "         [0.4453, 0.9252, 0.7580, 0.3311],\n",
       "         [0.0724, 0.2072, 0.4537, 0.7393]],\n",
       "\n",
       "        [[0.5149, 0.1084, 0.3849, 0.0651],\n",
       "         [0.0261, 0.0598, 0.7980, 0.2159],\n",
       "         [0.9039, 0.2390, 0.5307, 0.4736],\n",
       "         [0.2737, 0.7136, 0.5887, 0.8175],\n",
       "         [0.6334, 0.8573, 0.1050, 0.0070],\n",
       "         [0.7399, 0.5876, 0.6764, 0.0661]]])"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.rand(2, 6, 4)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "247e566b-0169-4cd1-81fd-6747a65e6f45",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-0.1354,  0.1081,  0.1995, -0.3149],\n",
       "         [-0.1302,  0.1288,  0.2171, -0.3159],\n",
       "         [-0.1260,  0.1251,  0.2106, -0.3118],\n",
       "         [-0.1329,  0.1156,  0.2055, -0.3146],\n",
       "         [-0.1253,  0.1319,  0.2172, -0.3136],\n",
       "         [-0.1312,  0.1200,  0.2094, -0.3177]],\n",
       "\n",
       "        [[-0.1202,  0.0118,  0.1015, -0.2252],\n",
       "         [-0.1168,  0.0184,  0.1064, -0.2240],\n",
       "         [-0.1188,  0.0105,  0.0991, -0.2229],\n",
       "         [-0.1125,  0.0177,  0.1026, -0.2176],\n",
       "         [-0.1164,  0.0141,  0.1009, -0.2195],\n",
       "         [-0.1156,  0.0170,  0.1038, -0.2205]]], grad_fn=<UnsafeViewBackward0>)"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MultiHeadAttention(d_model=4, n_heads=2)(x, x, x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65456b62-57b3-44e4-9d40-14d8155507a6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
